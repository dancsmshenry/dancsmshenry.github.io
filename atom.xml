<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dancsmshenry&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://dancsmshenry.github.io/"/>
  <updated>2025-08-03T15:56:51.291Z</updated>
  <id>https://dancsmshenry.github.io/</id>
  
  <author>
    <name>dancsmshenry</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Doip 协议详解</title>
    <link href="https://dancsmshenry.github.io/2025/08/03/doip-xie-yi-xiang-jie/"/>
    <id>https://dancsmshenry.github.io/2025/08/03/doip-xie-yi-xiang-jie/</id>
    <published>2025-08-03T15:46:27.000Z</published>
    <updated>2025-08-03T15:56:51.291Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Header"><a href="#Header" class="headerlink" title="Header"></a>Header</h1><p>1 字节的版本号，1 字节的版本号取反，2 字节的报文类型，4 字节的报文长度。</p><p>其中报文类型为 0000 的诊断报文，是通用 doip 报文头否定响应，所有类型都需要实现的。</p><br><br><h1 id="Tcp-type"><a href="#Tcp-type" class="headerlink" title="Tcp type"></a>Tcp type</h1><h2 id="0x0005-路由激活请求"><a href="#0x0005-路由激活请求" class="headerlink" title="0x0005 路由激活请求"></a>0x0005 路由激活请求</h2><p>2 字节的 source address，1 字节的 activation type，4 字节的 0000 0000</p><p>4 字节的 vm specific，一般是通过配置决定</p><br><h2 id="0x0006-路由激活响应"><a href="#0x0006-路由激活响应" class="headerlink" title="0x0006 路由激活响应"></a>0x0006 路由激活响应</h2><p>2 字节的 target address（一般是指 ecu 的地址），2 字节的 source address（一般是指上位机的诊断地址）</p><p>1 字节的 routing activation response code，表示当前路由激活的状态</p><p>4 字节的 future standardization use，被标准保留的值，一般为 0000 0000</p><br><h2 id="0x0007-在线检查请求"><a href="#0x0007-在线检查请求" class="headerlink" title="0x0007 在线检查请求"></a>0x0007 在线检查请求</h2><p>不携带任何数据</p><br><h2 id="0x0008-在线检查响应"><a href="#0x0008-在线检查响应" class="headerlink" title="0x0008 在线检查响应"></a>0x0008 在线检查响应</h2><p>2 字节的 diagnostic address</p><br><h2 id="0x8001-诊断报文"><a href="#0x8001-诊断报文" class="headerlink" title="0x8001 诊断报文"></a>0x8001 诊断报文</h2><p>2 字节的 source address，2 字节的 target address，一定字节数量的 uds 报文</p><br><h2 id="0x8002-诊断肯定响应"><a href="#0x8002-诊断肯定响应" class="headerlink" title="0x8002 诊断肯定响应"></a>0x8002 诊断肯定响应</h2><p>2 字节的 source address，2 字节的 target address，1 字节的 ack code</p><p>后面可以携带一定字节数量的诊断报文，长度可以通过配置来决定</p><br><h2 id="0x8003-诊断消极响应"><a href="#0x8003-诊断消极响应" class="headerlink" title="0x8003 诊断消极响应"></a>0x8003 诊断消极响应</h2><p>2 字节的 source address，2 字节的 target address，1 字节的 nack code</p><p>后面可以携带一定字节数量的诊断报文，长度可以通过配置来决定</p><br><br><h1 id="Udp-type"><a href="#Udp-type" class="headerlink" title="Udp type"></a>Udp type</h1><h2 id="0x4001-实体状态请求"><a href="#0x4001-实体状态请求" class="headerlink" title="0x4001 实体状态请求"></a>0x4001 实体状态请求</h2><p>不携带任何数据</p><br><h2 id="0x4002-实体状态响应"><a href="#0x4002-实体状态响应" class="headerlink" title="0x4002 实体状态响应"></a>0x4002 实体状态响应</h2><p>1 字节的 node type，1 字节的 最多允许 tcp 连接数量，1 字节的 tcp socket 数量（是指 socket 数，不是已经激活的 router 数量）</p><br><h2 id="0x4003-诊断电传模式请求"><a href="#0x4003-诊断电传模式请求" class="headerlink" title="0x4003 诊断电传模式请求"></a>0x4003 诊断电传模式请求</h2><p>不携带任何数据</p><br><h2 id="0x4004-诊断电源模式响应"><a href="#0x4004-诊断电源模式响应" class="headerlink" title="0x4004 诊断电源模式响应"></a>0x4004 诊断电源模式响应</h2><p>1 字节的 diagnostic power mode</p><br><h2 id="0x0001-车辆识别请求"><a href="#0x0001-车辆识别请求" class="headerlink" title="0x0001 车辆识别请求"></a>0x0001 车辆识别请求</h2><p>不携带任何数据</p><br><h2 id="0x0002-车辆识别请求（携带-eid）"><a href="#0x0002-车辆识别请求（携带-eid）" class="headerlink" title="0x0002 车辆识别请求（携带 eid）"></a>0x0002 车辆识别请求（携带 eid）</h2><p>6 字节的 eid</p><p>如果和 ecu 的 eid 不一样，需要回复 nack</p><br><h2 id="0x0003-车辆识别请求（携带-vin）"><a href="#0x0003-车辆识别请求（携带-vin）" class="headerlink" title="0x0003 车辆识别请求（携带 vin）"></a>0x0003 车辆识别请求（携带 vin）</h2><p>17 字节的 vin</p><p>如果和 ecu 的 vin 不一样，需要回复 nack</p><br><h2 id="0x0004-车辆识别响应-车辆声明"><a href="#0x0004-车辆识别响应-车辆声明" class="headerlink" title="0x0004 车辆识别响应/车辆声明"></a>0x0004 车辆识别响应/车辆声明</h2><p>17 字节的 vin 码，2 字节的逻辑地址，6 字节的 eid，6 字节的 gid，1 字节的 further action required（都是必选项）</p><p>vin/gid sync status 可选，一般是通过配置决定</p><br><h1 id="Header-check-handler"><a href="#Header-check-handler" class="headerlink" title="Header check handler"></a>Header check handler</h1><p><img src="doip_header_check.png" alt></p><p>对应的错误码：</p><p><img src="doip_header_code.png" alt></p><h1 id="Diagnostic-message-check-handler"><a href="#Diagnostic-message-check-handler" class="headerlink" title="Diagnostic message check handler"></a>Diagnostic message check handler</h1><p><img src="doip_diagnostic_message_check.png" alt></p><p>对应的错误码：</p><p><img src="doip_diagnostic_message_code.png" alt></p><br><br><h1 id="Routing-activation-check-handler"><a href="#Routing-activation-check-handler" class="headerlink" title="Routing activation check handler"></a>Routing activation check handler</h1><p><img src="doip_routing_activation_check.png" alt></p><p>对应的错误码：</p><p><img src="doip_routing_code.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Header&quot;&gt;&lt;a href=&quot;#Header&quot; class=&quot;headerlink&quot; title=&quot;Header&quot;&gt;&lt;/a&gt;Header&lt;/h1&gt;&lt;p&gt;1 字节的版本号，1 字节的版本号取反，2 字节的报文类型，4 字节的报文长度。&lt;/p&gt;
&lt;p&gt;其中报文类型
      
    
    </summary>
    
    
      <category term="AutomotiveElectronic" scheme="https://dancsmshenry.github.io/tags/AutomotiveElectronic/"/>
    
  </entry>
  
  <entry>
    <title>开发工具使用之 Gdb</title>
    <link href="https://dancsmshenry.github.io/2025/02/12/kai-fa-gong-ju-shi-yong-zhi-gdb/"/>
    <id>https://dancsmshenry.github.io/2025/02/12/kai-fa-gong-ju-shi-yong-zhi-gdb/</id>
    <published>2025-02-11T16:00:11.000Z</published>
    <updated>2025-05-02T17:21:58.585Z</updated>
    
    <content type="html"><![CDATA[<h1 id="多线程调试"><a href="#多线程调试" class="headerlink" title="多线程调试"></a>多线程调试</h1><pre class="line-numbers language-shell"><code class="language-shell"># 查看所有线程的堆栈thread apply all bt# 切换到指定线程的堆栈t 线程号# 进入正在运行的程序查看堆栈（一般用于排查死锁或者进程卡死的问题）gdb attach 进程号# 查看当前所有线程的调用栈info threads<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="调试堆栈"><a href="#调试堆栈" class="headerlink" title="调试堆栈"></a>调试堆栈</h1><pre class="line-numbers language-shell"><code class="language-shell"># 查看的堆栈bt# 查看具体第几个帧栈f 1/2/3/4# 查看具体某个变量p 变量名字# 打印变量的数据，以十六进制的形式打印（默认的是 8 进制）print/x 变量名字 # 清理 gdb 的控制台shell clear<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="如何生成-coredump"><a href="#如何生成-coredump" class="headerlink" title="如何生成 coredump"></a>如何生成 coredump</h1><ol><li>在 shell 中输入 <code>ulimit -c</code>，查看当前允许的生成 coredump 文件的大小</li><li>在 shell 中输入 <code>ulimit -c unlimited</code>，允许生成无限大小的 coredump 文件</li><li>在 shell 中输入 <code>echo &quot;kernel.core_pattern=/tmp/core-%e-%p-%t&quot; | sudo dd of=/proc/sys/kernel/core_pattern</code><ol><li>用于指定 coredump 文件的生成路径（有些场景可能会无法写入，需要强行用 dd 写进去）</li></ol></li><li>coredump 会生成到指定路径下，然后 <code>gdb 可执行文件 coredump文件</code></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;多线程调试&quot;&gt;&lt;a href=&quot;#多线程调试&quot; class=&quot;headerlink&quot; title=&quot;多线程调试&quot;&gt;&lt;/a&gt;多线程调试&lt;/h1&gt;&lt;pre class=&quot;line-numbers language-shell&quot;&gt;&lt;code class=&quot;languag
      
    
    </summary>
    
    
      <category term="Tool" scheme="https://dancsmshenry.github.io/tags/Tool/"/>
    
  </entry>
  
  <entry>
    <title>UDS 协议详解</title>
    <link href="https://dancsmshenry.github.io/2024/07/21/uds-xie-yi-xiang-jie/"/>
    <id>https://dancsmshenry.github.io/2024/07/21/uds-xie-yi-xiang-jie/</id>
    <published>2024-07-21T06:59:47.000Z</published>
    <updated>2025-08-03T15:08:30.263Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>对于 <code>UDS</code> 协议，没法剥离出一个完全原子的概念出来理解，很多概念之间是相互穿插着的。</p><p>所以私以为一种比较好的理解思路便是，一股脑的介绍完所有的概念，</p><p>然后再通过一个简单的服务请求，或是 <code>DTC</code> 的报告，将这些概念逐个逐个的进行穿插和联系。</p><p>（TODO：后续可以画两个图，分别将  <code>DCM</code> 和 <code>DEM</code> 的概念串联起来；实名 diss 一下公司的某讲师，一上来就把各种服务的参数怼新人的脸上，不知道的以为是在期末考试划重点。。。）</p><br><h2 id="子服务"><a href="#子服务" class="headerlink" title="子服务"></a>子服务</h2><p>一个 Bit 有 8 个 b，其中的后 7 个 b 表示子服务的 id，而第 8 个 b 表示是否抑制肯定响应位。</p><p>抑制肯定响应位的含义有两层，第一层是如果当前需要回复的是消极响应，那么无论如何都需要回复出去；</p><p>第二层是，只有需要回复的是积极响应，并且没有发送过 0x78 的报文（也就是 p2 没有超时），那么则不需要回复该积极响应，否则都要回复。</p><br><h2 id="积极响应与消极响应"><a href="#积极响应与消极响应" class="headerlink" title="积极响应与消极响应"></a>积极响应与消极响应</h2><br><h2 id="常见的定时器"><a href="#常见的定时器" class="headerlink" title="常见的定时器"></a>常见的定时器</h2><p>主要分为 p2、p2* 以及 s3。</p><br><h2 id="DataIdentifier"><a href="#DataIdentifier" class="headerlink" title="DataIdentifier"></a>DataIdentifier</h2><br><h2 id="RoutineIdentifier"><a href="#RoutineIdentifier" class="headerlink" title="RoutineIdentifier"></a>RoutineIdentifier</h2><br><h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><br><h2 id="SecurityLevel"><a href="#SecurityLevel" class="headerlink" title="SecurityLevel"></a>SecurityLevel</h2><br><h2 id="DiagnosticTroubleCode"><a href="#DiagnosticTroubleCode" class="headerlink" title="DiagnosticTroubleCode"></a>DiagnosticTroubleCode</h2><br><h2 id="DiagnosticTroubleCodeStatus"><a href="#DiagnosticTroubleCodeStatus" class="headerlink" title="DiagnosticTroubleCodeStatus"></a>DiagnosticTroubleCodeStatus</h2><table><thead><tr><th>Bit</th><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>Bit0</td><td>TestFailed</td><td>表示 DTC 最近一次报告的结果是否为 Failed。<br>当最近一次报告的结果为 Failed 时，需要将当前 Bit 置为 1；<br>当最近一次报告的结果为 Passed、DEM 模块首次初始化、或者 <code>ClearDiagnosticInformation</code> 时，需要将当前 Bit 置为 0（老化成功并不会将当前 Bit 置为 0）</td></tr><tr><td>Bit1</td><td>TestFailedThisOperationCycle</td><td>表示 DTC 在当前的操作循环中，是否报告过 Failed。<br>在当前操作循环中，只要报告了 Failed，就需要将当前 Bit 置为 1；<br>当重启操作循环、DEM 模块初始化，或者 <code>ClearDiagnosticInformation</code> 时，需要将当前 Bit 置为 0</td></tr><tr><td>Bit2</td><td>PendingDTC</td><td>表示 DTC 在当前的操作循环，以及上一个操作循环中，是否报告过 Failed。<br>当报告 Failed 时，需要将当前 Bit 置为 1；<br>当此时的操作循环结束，并且在这个操作循环中没有报告过 Failed（Bit1 和 Bit6 都为 0）、或者 DEM 首次初始化、或者 <code>ClearDiagnosticInformation</code> 时，需要将当前 Bit 置为 0</td></tr><tr><td>Bit3</td><td>ConfirmedDTC</td><td>表示 DTC 经历了一定次数的操作循环，并且在这些操作循环中都报告过 Failed 时，需要将当前 Bit 置为 1<br>当 DTC 老化完成，或是 DEM 模块首次初始化，或是当前的数据因为存储的 overflow 而被移除，或是 <code>ClearDiagnosticInformation</code> 时，需要将当前 Bit 置为 0</td></tr><tr><td>Bit4</td><td>TestnotCompletedSinceLastClear</td><td>表示自从上一次 clear 之后，是否有报告过 Passed 或者 Failed。<br>当报告 Failed 或者 Passed 时，需要将当前 Bit 置为 0；<br>当 <code>ClearDiagnosticInformation</code> 或者 DEM 模块初始化时，需要将当前 Bit 置为 1；<br>需要注意的是，下游 dtc 报告的 preFailed 或者 prePassed 并不算是一次完整的报告</td></tr><tr><td>Bit5</td><td>TestFailedSinceLastClear</td><td>表示自从上一次 clear，当前的 DTC 是否有报告过 Failed。<br>当报告 Failed 时，需要将当前 Bit 置为 1；<br>当 <code>ClearDiagnosticInformation</code> 或者 DEM 模块初始化，或者老化成功，或者因为 overflow 将数据删除了，需要将当前 Bit 置为 0</td></tr><tr><td>Bit6</td><td>TestNotCompletedThisOperationCycle</td><td>表示在当前的操作循环中，是否没报告过 Failed 或者 Passed。<br>当报告 Failed 或者 Passed 时，需要将当前 Bit 置为 0；<br>当重启操作循环、DEM 模块初始化，或者 <code>clearDiagnosticInformation</code> 时，需要将当前 Bit 置为 1</td></tr><tr><td>Bit7</td><td>WarningIndicator</td><td>初始值为 0；当配置了 indicator，Bit3 变为 1（此时 Bit0 也一定为 1），并且也符合主机厂或者供应商的需求时，将当前 Bit 置为 1<br>当 healing 结束，0x14 服务，或者一些主机厂自定义的条件满足时，将当前 Bit 置为 0</td></tr></tbody></table><br><p>对于有 dtc，当报告 failed 时需要将 bit7 置为 0 的 dtc 而言，有以下的状态位变化：</p><table><thead><tr><th></th><th>bit7</th><th>bit6</th><th>bit5</th><th>bit4</th><th>bit3</th><th>bit2</th><th>bit1</th><th>bit0</th><th>Result</th></tr></thead><tbody><tr><td>初始状态</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0x50</td></tr><tr><td>初始化-&gt;failed</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0x2F</td></tr><tr><td>failed-&gt;重启操作循环</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0x6D</td></tr><tr><td>failed-&gt;重启操作循环</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0x69</td></tr></tbody></table><br><p>对于有 dtc，当报告 failed 时需要将 bit7 置为 1 的 dtc 而言，有以下的状态位变化：</p><table><thead><tr><th></th><th>bit7</th><th>bit6</th><th>bit5</th><th>bit4</th><th>bit3</th><th>bit2</th><th>bit1</th><th>bit0</th><th>Result</th></tr></thead><tbody><tr><td>初始状态</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0x50</td></tr><tr><td>初始化-&gt;failed</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0xAF</td></tr><tr><td>failed-&gt;重启操作循环</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0xED</td></tr><tr><td>failed-&gt;重启操作循环</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0xE9</td></tr></tbody></table><br><br><br><h2 id="Aging-与-Healing"><a href="#Aging-与-Healing" class="headerlink" title="Aging 与 Healing"></a>Aging 与 Healing</h2><p>二者的区别就在于，对于一些 dtc 而言，需要在报告 failed 之后，将 bit7 置位为 1，并在一定的操作循环之后，才将其置为 0。</p><p>（注：此处先不考虑 dtc 在这期间报告 passed 的情况，因为存在一些厂商要求报告 passed 之后，将 bit7 置为 0）</p><p>因此，将上述流程，描述为 healing，也就是愈合。</p><br><p>而在经过了 healing 之后，距离能够自主的通过操作循环的重启，将相关的故障信息清楚的流程，称之为 aging，也就是老化。</p><p>（注：此处先不考虑 dtc 在这期间报告 failed 的情况）</p><br><br><br><h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><p>在发生了故障时，存储一些重要的信息。</p><p>从实现上来看，就是读取某些 did 的信息，并存储在非易失性存储介质中。</p><br><br><br><h2 id="ExtendedData"><a href="#ExtendedData" class="headerlink" title="ExtendedData"></a>ExtendedData</h2><p>所有的数据都是 uint8 类型的（除了 FDC10），达到 255 之后都不会继续增加</p><table><thead><tr><th>名称</th><th>介绍</th></tr></thead><tbody><tr><td>OCC1</td><td>+1 的条件：报告 failed 之后的<strong>每次</strong>操作循环重启都 +1 <br>清零的条件：报告 failed 之后；0x14 服务清除 dtc 之后，老化成功之后<br>实现细节：<br>每次操作循环重启的时候，如果此时的 bit1 为一并且 occ1 为零，<br>或者 occ1 不为零并且 bit1 为零，则加一<br>每次报告 failed 、14 服务清除 dtc 时，或者老化成功清零时，清零<br>和老化计数的关系：假设老化计数配的为 10，那么当 occ1 变为 11 的那一刻，才会彻底清除故障信息</td></tr><tr><td>OCC3</td><td>+1 的条件：<strong>首次</strong>报告 failed 之后的<strong>每次</strong>操作循环重启都 +1<br>清零的条件：0x14 服务清除 dtc 之后，老化成功之后<br>实现细节：<br>每次操作循环重启的时候，如果此时的 bit1 为一，或者 occ3 不为零，则加一<br>14 服务清除 dtc 时，或者老化成功清零时，清零</td></tr><tr><td>OCC4</td><td>+1 的条件：当前操作循环<strong>首次</strong>报告 failed 之后，就 +1<br>清零的条件：0x14 服务清除 dtc 之后，老化成功之后<br>实现细节：<br>每次报告 failed 的时候，记录是否是第一次报告，如果是才 +1<br>14 服务清除 dtc 时，或者老化成功清零时，清零</td></tr><tr><td>FDC10</td><td>等价于当前 dtc 的 fdc 值<br>达到 127 的条件：当报告 failed 之后，值变为 127<br>达到 -128 的条件：当报告 passed 之后，值变为 128<br>达到 0 的条件：当 14 服务清除 dtc、老化成功、或者操作循环重启时</td></tr></tbody></table><br><p>注：实际上存在一些内置 dataelement 来做拓展数据的，但目前没有看到厂商用过（或许是因为本质上，是可以归纳为快照数据的）</p><br><br><br><h1 id="0x10"><a href="#0x10" class="headerlink" title="0x10"></a>0x10</h1><p>在 UDS 的规范中，定义了会话状态的概念。会话状态可以简单的理解为是当前的 ECU 处于某种会话模式下。</p><p>会话模式的作用，主要是为了限制服务的使用。比如说在做诊断应用的设计的时候，可以指定某个服务必须要在某些指定的会话状态下执行。</p><p>而会话状态如何进行切换呢？0x10 服务便是用来切换会话的。</p><p>根据 14229 的规范，0x10 的 request message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x10</td><td>是</td></tr><tr><td>#2,#3</td><td>会话 id</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><p>会话可由用户自行在工具中配置，但规范规定了一些固有的会话类型</p><table><thead><tr><th>会话 id</th><th>会话名</th></tr></thead><tbody><tr><td>0x01</td><td>defaultSession</td></tr><tr><td>0x02</td><td>ProgrammingSession</td></tr><tr><td>0x03</td><td>extendedDiagnosticSession</td></tr><tr><td>0x04</td><td>safetySystemDiagnosticSession</td></tr></tbody></table><p>关于会话模式，有以下几点是需要注意了解的：</p><ol><li>在一般的情况下， ECU 一上电，都是处于<strong>默认会话</strong></li><li>在 ECU 中会维护一个名为 S3 的定时器，假如当前 ECU 的会话状态不是默认会话，那么就会启用该定时器。一旦有新的请求，便会刷新该定时器。如果在定时器到时的时候，依旧没有新的请求，那么 ECU 就会自动将会话切换到默认会话下</li><li>在 UDS 的概念中定义了定时器 <code>p2</code> 和 <code>p2 *</code>。当一条服务从刚开始处理，到 p2 定时器超时，这个期间，如果服务还没有处理完，则需要给外部的诊断仪或者脚本发送 0x78 的报文，告知对方当前的服务超时了，后续还会将响应发来。紧接着就会启动 <code>p2*</code>的定时器，在 <code>p2*</code> 的定时器超时后，又会接着发送 0x78 的报文 （其中 p2 定时器的单位是 <strong>1ms</strong>，<code>p2*</code> 定时器的单位是 <strong>10ms</strong>）</li></ol><br><p>根据 14229 的规范，0x10 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x50</td><td>是</td></tr><tr><td>#2,#3</td><td>会话 id</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#4,#5</td><td>p2 server 定时器</td><td>0x0000-0xFFFF</td><td>是</td></tr><tr><td>#6,#7</td><td>p2* server 定时器</td><td>0x0000-0xFFFF</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x11"><a href="#0x11" class="headerlink" title="0x11"></a>0x11</h1><p>该服务从字面意思上理解，就是用来重启 ECU 的。而重启有不同的类型，具体的重启类型可以参见子服务。</p><p>规范中并没有定义在发送了 0x11 的 positive response 之后，到真正重启之间，ECU 的行为。但推荐在这个期间 ECU 不要解说任何的 request 或是发送任何的 response。</p><p>根据 14229 的规范，0x11 的 request message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x11</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><p>而其中具体的子服务，在 14229 的规范中，有定为以下几种：</p><table><thead><tr><th>子服务 id</th><th>含义</th></tr></thead><tbody><tr><td>0x01</td><td>HardReset，硬件复位，模拟通常在服务器与其电源断开后执行的通电/启动顺序。简单的理解为就是整个 ECU 重启了。有可能会导致易失性存储和非易失性存储失效</td></tr><tr><td>0x02</td><td>keyOffOnReset，点火循环复位，模拟关机顺序（即中断开关电源）。有点类似于驾驶员用钥匙给汽车关闭后又重新点火的过程。其中非易失性存储将会被保存，易失性存储会被重置</td></tr><tr><td>0x03</td><td>softReset，软复位，简单理解就是将应用程序重启</td></tr><tr><td>0x04</td><td>enableRapidPowerShutDown，适用于非点火供电而仅为电池供电的ECU。因此，关机会迫使睡眠模式关闭，而不是关闭电源。睡眠意味着关闭电源，但仍准备唤醒（电池供电）。子功能的目的是减少在点火开关进入关闭位置后的ECU的备用时间。</td></tr><tr><td>0x05</td><td>disableRapidPowerShutDown，关闭 0x04 服务</td></tr></tbody></table><br><p>根据 14229 的规范，0x11 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x51</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00-0x7F</td><td>是</td></tr><tr><td>#3</td><td>powerDownTime</td><td>0x00-0xFF</td><td>当子服务为 0x04 的时候才会有该项</td></tr></tbody></table><br><br><br><h1 id="0x27"><a href="#0x27" class="headerlink" title="0x27"></a>0x27</h1><p>该服务是用来解锁安全等级的。安全等级和会话等级是类似的概念，都是用来限制服务需要在指定的环境下执行。但与会话等级不同的是，会话等级一问一答便可以切换会话，而安全等级则需要先请求安全种子，计算key，比较key，之后再判断是否可以解锁安全等级。</p><p>0x27 是带有子服务的 UDS 服务，其中子服务为 0x01-0x41 之间的奇数的，都是 requestSeed 请求种子的服务；子服务为 0x02-0x42 之间的偶数的，都是 sendKey 发送 key 值。</p><p>其实，这里的子服务是一一对应的。比如说 子服务id 为 0x01 的 requestSeed 服务，那么就需要对应子服务id 为 0x02 的 sendkey 服务，即 requestSeed 的子服务 id，是其对应的</p><br><p>根据 14229 的规范，0x27 的 request message ，其中子服务为 requestSeed 的报文结构</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x27</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x01,0x03,0x05,0x07-0x7D</td><td>是</td></tr><tr><td>#3…#n</td><td>具体数据</td><td>0x00-0xFF</td><td>否</td></tr></tbody></table><br><p>根据 14229 的规范，0x27 的 request message ，其中子服务为 sendKey 的报文结构</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x27</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x02,0x04,0x06,0x08-0x7E</td><td>是</td></tr><tr><td>#3…#n</td><td>securityKey</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><br><p>根据 14229 的规范，0x27 的子服务 requestSeed 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x67</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x01,0x03,0x05,0x07-0x7D</td><td>是</td></tr><tr><td>#3…#n</td><td>securitySeed</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><br><p>根据 14229 的规范，0x27 的子服务 sendKey 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x67</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x02,0x04,0x06,0x08-0x7E</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x28"><a href="#0x28" class="headerlink" title="0x28"></a>0x28</h1><p>0x28 服务是用来打开或者关闭某类报文信息的发送和接收功能。</p><p>根据 14229 的规范，0x28 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x28</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3</td><td>communicationType，消息类型</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#4</td><td>nodeIdentificationNumber</td><td>0x00-0xFF</td><td>否，当 communicationType 是 04 或者 05 的失火，才需要填写该参数</td></tr><tr><td>#5</td><td>nodeIdentificationNumber</td><td>0x00-0xFF</td><td>否，当 communicationType 是 04 或者 05 的失火，才需要填写该参数</td></tr></tbody></table><p>根据 14229 的规范，目前支持的 subfunction 有</p><table><thead><tr><th>子服务 id</th><th>含义</th></tr></thead><tbody><tr><td>0x00</td><td>enableRxAndTx，启用对某种消息的发送和接收</td></tr><tr><td>0x01</td><td>enableRxAndDisableTx，启用对某种消息的接受，禁用对某种消息的发送</td></tr><tr><td>0x02</td><td>disableRxAndEnableTx，禁用对某种消息的接收，启用对某种消息的发送</td></tr><tr><td>0x03</td><td>disableRxAndTx，禁用对某种消息的接收和发送</td></tr><tr><td>0x04</td><td>enableRxAndDisableTxWithEnhancedAddressInformation，表示寻址总选需要切换到诊断调度模式</td></tr><tr><td>0x05</td><td>enableRxAndTxWithEnhancedAddressInformation，表示寻址总线需要切换到应用程序调度模式</td></tr></tbody></table><p>而对于 communicationType，具体在 14229 中表 B.1 中有详细的赘述，更多细节可以关注 ISO 14229 的规范</p><br><p>根据 14229 的规范，0x28 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x68</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00-0x7F</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x29"><a href="#0x29" class="headerlink" title="0x29"></a>0x29</h1><p>认证主要分为 APCE 和 ACR，a 核上的协议栈一般只支持 APCE。而其中 APCE 又分为单向认证和双向认证</p><p>APCE 的全称 Authentication with PKI Certificate Exchange</p><p>ACR 的全称 Authentication with Challenge-Response</p><br><p>按照 14229 的规范，支持的子服务如下所示：</p><table><thead><tr><th>子服务名称</th><th>作用</th></tr></thead><tbody><tr><td>0x00 deAuthenticate</td><td>主动结束认证状态</td></tr><tr><td>0x01 verifyCertificateUnidirectional</td><td>单向认证（为 APCE 下的子服务）</td></tr><tr><td>0x02 verifyCertificateBidirectional</td><td>双向认证（为 APCE 下的子服务）</td></tr><tr><td>0x03 proofOfOwnership</td><td>所有权证明（为 APCE 下的子服务）</td></tr><tr><td>0x04 transmitCertificate</td><td>传输证书（为 APCE 下的子服务）</td></tr><tr><td>0x05 requestChallengeForAuthentication</td><td>（为 ACR 下的子服务）</td></tr><tr><td>0x06 verifyProofOfOwnershipUnidirectional</td><td>（为 ACR 下的子服务）</td></tr><tr><td>0x07 verifyProofOfOwnershipBidirectional</td><td>（为 ACR 下的子服务）</td></tr><tr><td>0x08 authenticationConfiguration</td><td>表示当前协议栈支持的认证，是 APCE 还是 ACR</td></tr></tbody></table><p>单向认证：</p><p>0x01 服务，传递 client certificate 和 client challenge；server 回复 server challenge 和 server ephemeral public key</p><p>再使用 0x03 服务，传递 client proofOfOwnershipClient 和 client ephemeral public key；server 回复 SessionKeyInfo</p><br><br><br><h1 id="0x3E"><a href="#0x3E" class="headerlink" title="0x3E"></a>0x3E</h1><p>该服务适用于保持外部的 client（上位机或是诊断脚本）与诊断 server 之间的活跃状态。而在实际的作用中，更多的是为了保持当前诊断会话的状态。（因为我们知道 s3 timer 如果在这个时间内都没有新的连接进入，那么就会导致会话切换回默认会话状态）</p><p>根据 14229 的规范，0x3E 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x3E</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00/0x80</td><td>是</td></tr></tbody></table><p>注：在子服务 id 中，其中的 Bit7，也就是第八位，当为 0 的时候，表示为需要发送肯定响应，而为1的时候，则需要抑制肯定响应</p><p>根据 14229 的规范，目前支持的 subfunction 有</p><table><thead><tr><th>子服务 id</th><th>含义</th></tr></thead><tbody><tr><td>0x00</td><td>zeroSubFunction</td></tr></tbody></table><br><p>根据 14229 的规范，0x3E 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x7E</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x00</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x85"><a href="#0x85" class="headerlink" title="0x85"></a>0x85</h1><p>该服务用于表示是否开启 DEM 模块的报告。需要注意的是，按照 14229 的规范，如果切换到了默认会话，是需要开启 DEM 模块的报告的</p><p>根据 14229 的规范，0x85 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x85</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x01/0x02</td><td>是</td></tr></tbody></table><br><p>根据 14229 的规范，0x85 的 positive response message 格式为：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0xC5</td><td>是</td></tr><tr><td>#2</td><td>子服务 id</td><td>0x01/0x02</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x86"><a href="#0x86" class="headerlink" title="0x86"></a>0x86</h1><p>Todo：很少看到有客户使用这个服务，后续需要用到的时候，再进行深入的了解。</p><br><br><br><h1 id="0x22"><a href="#0x22" class="headerlink" title="0x22"></a>0x22</h1><p>该服务是用来读取一个或者多个 did 对应的数据的。did 的全程是 dataIdentifier，它是由一个 <code>uint16</code> 和一连串二进制数据组成的，可以简单的理解为键值对的关系。此处的 <code>uint16</code> 为 did 号。</p><p>而读取 did 的这个服务，可以理解是，外部的诊断仪传入 did 号，诊断 server 便根据报文中的 did 号，返回对应的数据。</p><p>根据 14229 的规范，0x22 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x22</td><td>是</td></tr><tr><td>#2,#3</td><td>did</td><td>0x00-0xFF</td><td>是（每次 22 服务的请求中，至少要有一个 did）</td></tr><tr><td>.. #n-1，#n</td><td>did</td><td>0x00-0xFF</td><td>否</td></tr></tbody></table><br><p>根据 14229 的规范，0x22 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x62</td><td>是</td></tr><tr><td>#2,#3</td><td>did</td><td>0x00-0xFF</td><td>是（每次 22 服务的请求中，至少要有一个 did）</td></tr><tr><td>#4..#(k-1)+4</td><td>Did record，为 did 对应的数据</td><td>0x00-0xFF</td><td>是（did 对应的数据至少为一个字节）</td></tr><tr><td>#n-(0-1)-2,#n-(o-1)-1</td><td>did</td><td>0x00-0xFF</td><td>否（至少有一个 did 可读就可以了）</td></tr><tr><td>#n-(o-1)..#n</td><td>Did record，为did对应的数据</td><td>0x00-0xFF</td><td>否（至少有一个 did 可读就可以了）</td></tr></tbody></table><br><br><br><h1 id="0x2A"><a href="#0x2A" class="headerlink" title="0x2A"></a>0x2A</h1><p>该服务允许外部的诊断仪发送周期性读取一个或是多个 did 的请求。</p><p>在 14229 的规范中，每次 2A 服务传入的 did 数据只包含低两位。其中的高两位固定为 0xF2。</p><p>根据 14229 的规范，0x2A 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x2A</td><td>是</td></tr><tr><td>#2</td><td>transmissionMode，表示传输的速率</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3</td><td>periodicDataIdentifier</td><td>0x00-0xFF</td><td>否（可以传入任意数量的 did；如果 transmissionMode 为 stopSending，且后续没有 did 存在时，则表示 client 需要将所有的定时读取的 did 都给取消）</td></tr></tbody></table><br><p>根据 14229 的规范，0x2A 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x6A</td><td>是</td></tr></tbody></table><p>而周期性返回数据的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>periodicDataIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#2..#k+2</td><td>Did record，为 did 对应的数据</td><td>0x00-0xFF</td><td>是（did 对应的数据至少为一个字节）</td></tr></tbody></table><br><br><br><h1 id="0x2C"><a href="#0x2C" class="headerlink" title="0x2C"></a>0x2C</h1><p>对于 did 而言，在工具界面配置了当前支持哪些 did，但是存在一种名为 dynamic define by identifier 的 did。这种 did 在工具界面配置，说当前支持这种类型的 did，但是它具体的组成需要由 0x2c 服务来定义。</p><p>比如说，已有 did1，did2，did3。其中 did3 是动态 did，那么通过 2c 服务指定，did3 是由 did1 的前四位，加上 did2 的中间四位组成的。</p><p>注：在 autosar ap 的规范中，仅支持子服务 id 为 0x01 和 0x03 这两个子服务</p><p>根据 14229 的规范，0x2C 的 request message ，子服务为 0x01 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x2C</td><td>是</td></tr><tr><td>#2</td><td>SubFunction</td><td>0x01(defineByIdentifier)</td><td>是</td></tr><tr><td>#3,#4</td><td>dynamicallyDefinedDataIdentifier</td><td>0xF2/0xF3，0x00-0xFF</td><td>是</td></tr><tr><td>#5,#6</td><td>sourceDataIdentifier，表示源 did</td><td>0x00-0xFF</td><td>是（至少要由一个 did 组成）</td></tr><tr><td>#7</td><td>positionInSourceDataRecord，表示在源头 did 上的偏移量</td><td>0x01-0xFF</td><td>是（至少要由一个 did 组成）</td></tr><tr><td>#8</td><td>memorySize</td><td>0x01-0xFF</td><td>是（至少要由一个 did 组成）</td></tr><tr><td>#n-3,#n-2</td><td>sourceDataIdentifier，表示源 did</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#n-1</td><td>positionInSourceDataRecord，表示在源头 did 上的偏移量</td><td>0x01-0xFF</td><td>否</td></tr><tr><td>#n</td><td>memorySize</td><td>0x01-0xFF</td><td>否</td></tr></tbody></table><p>根据 14229 的规范，0x2C 的 request message ，子服务为 0x03 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x2C</td><td>是</td></tr><tr><td>#2</td><td>SubFunction</td><td>0x03(clearDynamicallyDefinedDataIdentifier)</td><td>是</td></tr><tr><td>#3,#4</td><td>dynamicallyDefinedDataIdentifier</td><td>0xF2/0xF3，0x00-0xFF</td><td>否（如果没有该项，则表示需要清除所有的 ddid；否则则表示删除某个具体的 ddid）</td></tr></tbody></table><br><p>根据 14229 的规范，0x2C 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x6C</td><td>是</td></tr><tr><td>#2</td><td>subfunction</td><td>0x00-0x7F</td><td>是</td></tr><tr><td>#3,#4</td><td>dynamicallyDefinedDataIdentifier</td><td>0xF2/0xF3，0x00-0xFF</td><td>否（如果 request 中有 ddid，那么就需要填写此参数，否则则不需要）</td></tr></tbody></table><br><br><br><h1 id="0x2E"><a href="#0x2E" class="headerlink" title="0x2E"></a>0x2E</h1><p>该服务是用来写 did 对应的数据的。而对于动态定义的 did 来说，是不能够写入的。</p><p>根据 14229 的规范，0x2E 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x2E</td><td>是</td></tr><tr><td>#2,#3</td><td>dataIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#4..#m+3</td><td>dataRecord</td><td>0x00-0xFF</td><td>是，最少应为一个字节</td></tr></tbody></table><br><p>根据 14229 的规范，0x2E 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x6E</td><td>是</td></tr><tr><td>#2,#3</td><td>dataIdentifier</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x14"><a href="#0x14" class="headerlink" title="0x14"></a>0x14</h1><p>clearDiagnosticInformation，该服务是用于删除一个或者多个 DTC 对应的数据。当完全删除 DTC 对应的数据，或者不存在对应 DTC 时，需要返回积极响应，如果在 server 中存在多份 DTC 的数据（比如说可能存在备份的情况），那么同样也要将其删除。</p><p>根据 14229 的规范，0x14 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x14</td><td>是</td></tr><tr><td>#2,#3,#4</td><td>groupOfDTC</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#5</td><td>Memory selection</td><td>0x00-0xFF</td><td>否（为用户自定义的内存序）</td></tr></tbody></table><br><p>根据 14229 的规范，0x14 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x54</td><td>是</td></tr></tbody></table><br><br><br><h1 id="0x19"><a href="#0x19" class="headerlink" title="0x19"></a>0x19</h1><p>readDTCInformation，该服务是用于读取处于某个状态的所有 DTC 对应的数据。</p><p>根据 14229 的规范以及 autosar ap 的规范，目前支持的 subfunction 有</p><table><thead><tr><th>子服务 id</th><th>含义</th></tr></thead><tbody><tr><td><strong>0x01</strong></td><td>reportNumberOfDTCByStatusMask，需要传入 statusMask（一个字节），返回处于当前状态的 DTC 的数量</td></tr><tr><td><strong>0x02</strong></td><td>reportDTCByStatusMask，需要传入 statusMask（一个字节），返回处于当前状态的 DTC 的列表</td></tr><tr><td>0x03</td><td>reportDTCSnapshotIdentification，不需要传入数据，返回所有 DTC 的所有快照号（即冻结帧的 recordnumber）（具体的格式应该是 dtc 号,freeze.recordNumber + dtc ）</td></tr><tr><td><strong>0x04</strong></td><td>reportDTCSnapshotRecordByDTCNumber，需要传入 DTC 码以及其对应的快照信息的 recordNumber，然后去读对应快照信息的数据（如果此处的 recordNumber 是 FF，就会读取所有的数据）</td></tr><tr><td><strong>0x06</strong></td><td>reportDTCExtDataRecordByDTCNumber，需要传入 DTC 码以及其对应的拓展数据的 recordNumber，然后返回数据（如果此处的 recordNumber 是 FE 或者 FF，就会读取所有的数据）</td></tr><tr><td>0x07</td><td>reportNumberOfDTCByServerityMaskRecord，需要传入状态码和严重程度，然后返回对应 DTC 的数量</td></tr><tr><td><strong>0x0A</strong></td><td>reportSupportedDTC，不需要传入数据，返回当前支持的所有的 DTC 及其状态</td></tr><tr><td>0x14</td><td>reportDTCFaultDetectionCounter，不需要传入数据，返回当前所有处于 preFailed 的 DTC</td></tr><tr><td>0x17</td><td>reportUserDefMemoryByStatusMask</td></tr><tr><td>0x18</td><td>reportUserDefMemoryDTCSnapshotRecordByDTCNumber</td></tr><tr><td>0x19</td><td>reportUserDefMemoryDTCExtDataRecordByDTCNumber</td></tr></tbody></table><br><br><br><h1 id="0x31"><a href="#0x31" class="headerlink" title="0x31"></a>0x31</h1><p>该服务的全称为 routineControl。在介绍这个服务之前需要介绍 routineIdentifier，为一个 uint16 的值，表示某一个 routine。</p><p>而服务 routineControl 表示的是外部的诊断仪或是脚本，想让诊断 server（或是 ECU）执行一段此前已经定义好了的代码逻辑，比如常见的擦除内存，重置或是修改某个参数等。</p><p>如果从常见的网络模型上看，可以简单的立即为 routine 就是某个函数，当传入 0x31 0x01 的时候，就是让程序执行某段代码；当传入 0x31 0x02 的时候，就是让程序停止执行某段代码；当传入 0x31 0x03 的时候，就是获取这段代码执行结果的返回值。</p><p>根据 14229 的规范，0x31 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x31</td><td>是</td></tr><tr><td>#2</td><td>subFuntcion</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3,#4</td><td>routineIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#5..#n</td><td>routineControlOptionRecord</td><td>0x00-0xFF</td><td>否（该部分的内容由用户自行定义）</td></tr></tbody></table><p>根据 14229 的规范，目前支持的 subfunction 有</p><table><thead><tr><th>子服务 id</th><th>含义</th></tr></thead><tbody><tr><td>0x01</td><td>startRoutine，该服务是用于启动某个 routine</td></tr><tr><td>0x02</td><td>stopRoutine，该服务是用于停止某个 routine</td></tr><tr><td>0x03</td><td>requestRoutineResults，该服务是用于获取某个 routine 运行得到的结果</td></tr></tbody></table><br><p>根据 14229 的规范，0x31 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x71</td><td>是</td></tr><tr><td>#2</td><td>routineControlType，为对应的子服务</td><td>0x00-0x7F</td><td>是</td></tr><tr><td>#3,#4</td><td>routineIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#5</td><td>routineInfo</td><td>0x00-0xFF</td><td>否（该参数由不同的协议及车厂共同实现）</td></tr><tr><td>#6…#n</td><td>routineStatusRecord</td><td>0x00-0xFF</td><td>否</td></tr></tbody></table><br><br><br><h1 id="0x34"><a href="#0x34" class="headerlink" title="0x34"></a>0x34</h1><p>服务名为 requestDownload。此处需要注意的是，UDS 提供了服务用于数据的传输，而在具体数据的传输上，是需要先告知当前的数据流走向的。</p><p>requestDownload 表示数据是从 client 传输到 server 上，即上位机传输给 ECU。</p><p>根据 14229 的规范，0x34 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x34</td><td>是</td></tr><tr><td>#2</td><td>dataFormatIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3</td><td>addressAndLengthFormatIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#4..#(m-1)+4</td><td>memoryAddress</td><td>0x00-0xFF</td><td>是（最少需要有一个字节）</td></tr><tr><td>#n-(k-1)..#n</td><td>memorySize</td><td>0x00-0xFF</td><td>是（最少需要有一个字节）</td></tr></tbody></table><p><strong>dataFormatIdentifier</strong> 需要分为两部分理解：</p><ul><li><p>Bit7-4 表示数据的压缩方法</p></li><li><p>Bit3-0 表示数据的加密方法</p></li></ul><p>如果为 0x00，则表示传输的数据既不需要加密，也不需要压缩。具体的压缩和加密方法，由主机厂自行定义。</p><br><p><strong>adderssAndLengthFormatIdentifier</strong> 也需要分两部分来理解：</p><ul><li><p>Bit7-4 表示的是 memorySize 所需的字节数</p></li><li><p>Bit3-0 表示的是 memoryAddress 所需的字节数</p></li></ul><br><p><strong>memoryAddress</strong> 表示的是当前的数据具体要写在哪一个内存地址开始的位置。</p><br><p><strong>memorySize</strong> 表示传输数据块的大小。</p><p>ECU 需要使用该参数进行判断，最后返回给用户每次可以传输数据的最大大小，如果用户使用了数据压缩，那么此处的大小是压缩前还是压缩后的，需要厂商自行决定。</p><br><p>根据 14229 的规范，0x34 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x74</td><td>是</td></tr><tr><td>#2</td><td>lengthFormatIdentifier</td><td>0x00-0xF0</td><td>是</td></tr><tr><td>#3,#n</td><td>maxNumberOfBlockLength</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><p><strong>lengthFormatIdentifier</strong> 需要分为两部分理解：</p><ul><li><p>Bit7-4 表示后续 maxNumberOfBlockLength 的长度</p></li><li><p>Bit3-0 为 0，具体的内容为 ISO 保留</p></li></ul><br><p><strong>maxNumberOfBlockLength</strong> 表示后续的 0x36（transferData）需要传输数据内容的大小最大为多少。</p><br><br><br><h1 id="0x35"><a href="#0x35" class="headerlink" title="0x35"></a>0x35</h1><p>服务名为 requestUpload。此处需要注意的是，UDS 提供了服务用于数据的传输，而在具体数据的传输上，是需要先告知当前的数据流走向的。</p><p>requestUpload 表示数据是从 server 传输到 client 上，即从 ECU 传输给上位机。</p><p>根据 14229 的规范，0x35 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x35</td><td>是</td></tr><tr><td>#2</td><td>dataFormatIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3</td><td>addressAndLengthFormatIdentifier</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#4..#(m-1)+4</td><td>memoryAddress</td><td>0x00-0xFF</td><td>是（最少需要有一个字节）</td></tr><tr><td>#n-(k-1)..#n</td><td>memorySize</td><td>0x00-0xFF</td><td>是（最少需要有一个字节）</td></tr></tbody></table><p>其中关于 <code>dataFormatIdentifier</code>，<code>addressAndLengthFormatIdentifier</code>，<code>memoryAddress</code>，<code>memorySize</code> 的描述，</p><p>可以完全参见<code>0x34</code>中的描述。</p><br><p>根据 14229 的规范，0x35 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x75</td><td>是</td></tr><tr><td>#2</td><td>lengthFormatIdentifier</td><td>0x00-0xF0</td><td>是</td></tr><tr><td>#3,#n</td><td>maxNumberOfBlockLength</td><td>0x00-0xFF</td><td>是</td></tr></tbody></table><p>lengthFormatIdentifier 需要分为两部分理解：</p><ul><li><p>Bit7-4 表示后续 maxNumberOfBlockLength 的长度</p></li><li><p>Bit3-0 为 0，具体的内容为 ISO 保留</p></li></ul><p>而 maxNumberOfBlockLength 则表示后续的 0x36（transferData）需要传输数据内容的大小最大为多少。</p><br><br><br><h1 id="0x36"><a href="#0x36" class="headerlink" title="0x36"></a>0x36</h1><p>在介绍完了 0x34 和 0x35 这两个服务之后，可以发现这两个服务都是用来表示后续具体传输数据流的走向，而具体数据的传输，就是用服务 0x36 进行传输的</p><p>根据 14229 的规范，0x36 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x36</td><td>是</td></tr><tr><td>#2</td><td>blockSequenceCounter</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3..#n</td><td>transferRequestParameterRecord</td><td>0x00-0xFF</td><td>否（如果此时是 0x34 对应的数据传输，就必须要有该参数）</td></tr></tbody></table><p>blockSequenceCounter 是从 01 开始计数的，是用来计算当前已经传输数据的大小的。该值是为了保证数据的顺序及完整性传输。</p><p>如果循环至 0xFF，则会回到 0x00。</p><br><p>根据 14229 的规范，0x36 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x76</td><td>是</td></tr><tr><td>#2</td><td>blockSequenceCounter</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#3,#n</td><td>transferResponseParameterRecord</td><td>0x00-0xFF</td><td>否（如果此时是 0x35 对应的数据传输，就必须要有该参数）</td></tr></tbody></table><br><br><br><h1 id="0x37"><a href="#0x37" class="headerlink" title="0x37"></a>0x37</h1><p>requestTransferExit 是用于表示当前数据传输的终止的。</p><p>根据 14229 的规范，0x37 的 request message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x37</td><td>是</td></tr><tr><td>#2..#n</td><td>transferRequestParameterRecord</td><td>0x00-0xFF</td><td>否（为用户自定义数据）</td></tr></tbody></table><br><p>根据 14229 的规范，0x37 的 response message 的报文结构如下所示。</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x77</td><td>是</td></tr><tr><td>#2..#n</td><td>transferResponseParameterRecord</td><td>0x00-0xFF</td><td>否（为用户自定义数据）</td></tr></tbody></table><br><br><br><h1 id="0x38"><a href="#0x38" class="headerlink" title="0x38"></a>0x38</h1><p>RequestFileTransfer，该服务是用来传输文件或者文件夹。</p><p>根据 14229 的规范，0x38 的 request message 的报文结构如下所示：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id</td><td>0x38</td><td>是</td></tr><tr><td>#2</td><td>modeOfOperation</td><td>0x01-0x06</td><td>是（表示当前对文件处理的操作）</td></tr><tr><td>#3,#4</td><td>filePathAndNameLength</td><td>0x00-0xFF</td><td>是</td></tr><tr><td>#5…#5+n-1</td><td>filePathAndName</td><td>0x00-0xFF</td><td>是（文件路径和名字至少为一个字节）</td></tr><tr><td>#5+n</td><td>dataFormatIdentifier</td><td>0x00-0xFF</td><td>否（与具体的 modeOfOperation 有关）</td></tr><tr><td>#5+n+1</td><td>fileSizeParameterLength</td><td>0x00-0xFF</td><td>否（与具体的 modeOfOperation 有关）</td></tr><tr><td>#5+n+2..#5+n+2+k-1</td><td>fileSizeUnCompressed</td><td>0x00-0xFF</td><td>否（与具体的 modeOfOperation 有关）</td></tr><tr><td>#5+n+2+k..#5+n+1+2k</td><td>fileSizeCompressed</td><td>0x00-0xFF</td><td>否（与具体的 modeOfOperation 有关）</td></tr></tbody></table><br><br><p>根据 14229 的规范，0x38 的 request message 的报文结构如下所示：</p><table><thead><tr><th>数值位</th><th>参数名字</th><th>可选值</th><th>是否为必选项</th></tr></thead><tbody><tr><td>#1</td><td>服务 id + positive 偏移量</td><td>0x78</td><td>是</td></tr><tr><td>#2</td><td>modeOfOperation</td><td>0x01-0x06</td><td>是（表示当前对文件处理的操作）</td></tr><tr><td>#3</td><td>lengthFormatIdentifier</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#4…#4+m-1</td><td>maxNumberOfBlockLength</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#4+m</td><td>dataFormatIdentifier</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#4+m+1..#4+m+2</td><td>fileSizeOrDirInfoParameterlength</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#4+m+3..#4+m+3+k-1</td><td>fileSizeUncompressedOrDirInfoLength</td><td>0x00-0xFF</td><td>否</td></tr><tr><td>#4+m+3+k..#4+m+3+2k-1</td><td>fileSizeCompressed</td><td>0x00-0xFF</td><td>否</td></tr></tbody></table><p><strong>filePathAndNameLength</strong> 表示的是后续文件路径及名字的长度</p><br><p><strong>filePathAndName</strong> 表示后续的文件路径和名字（如果当前的 modeOfOperation 是 0x05 readDir，那么此处就应该是文件夹）</p><br><p><strong>dataFormatIdentifier</strong> 的具体功能，需参考此前的赘述（如果当前的 modeOfOperation 是 0x02 或者 0x05，那么则不应该有该参数）</p><br><p><strong>fileSizeParameterLength</strong>（或者 <strong>fileSizeOrDirInfoParameterlength</strong>） 记录了后续 <code>fileSizeUncompressed</code>（<code>fileSizeCompressed</code> 的大小也一样） 的大小（如果当前的 modeOfOperation 是 0x02，0x04，0x05，则不应该有该参数）</p><br><p><strong>fileSizeUncompressed</strong> 表示当前文件未压缩的长度（如果当前的 modeOfOperation 是 0x02，0x04，0x05，则不应该有该参数）</p><br><p><strong>fileSizeCompressed</strong> 表示当前文件被压缩的长度（如果当前的 modeOfOperation 是 0x02，0x04，0x05，则不应该有该参数），如果传输的文件未被压缩，那么值应该和 fileSizeUncompressed 相等</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;对于 &lt;code&gt;UDS&lt;/code&gt; 协议，没法剥离出一个完全原子的概念出来理解，很多概念之间是相互穿插着的。&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
      <category term="AutomotiveElectronic" scheme="https://dancsmshenry.github.io/tags/AutomotiveElectronic/"/>
    
  </entry>
  
  <entry>
    <title>开发工具使用之 Catch2</title>
    <link href="https://dancsmshenry.github.io/2024/05/04/kai-fa-gong-ju-shi-yong-zhi-catch2/"/>
    <id>https://dancsmshenry.github.io/2024/05/04/kai-fa-gong-ju-shi-yong-zhi-catch2/</id>
    <published>2024-05-04T05:53:24.000Z</published>
    <updated>2025-05-02T17:21:51.121Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>目前使用的测试框架，好处就是只有头文件，方便无论是新人还是老人进行开发（gtest 需要编译成 静态库，使用上有点难度）</p><h1 id="CHECK-和-REQUIRE"><a href="#CHECK-和-REQUIRE" class="headerlink" title="CHECK 和 REQUIRE"></a>CHECK 和 REQUIRE</h1><p><code>CHECK</code> 和 <code>REQUIRE</code> 用于检测当前括号中的表达式是否为真，常用于校验函数的结果是否符合预期，从而达到测试函数逻辑的目的</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token function">TEST_CASE</span><span class="token punctuation">(</span><span class="token string">"TEST"</span><span class="token punctuation">,</span> <span class="token string">"[test1]"</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//    CHECK 在检查项错误的时候，不会导致程序停下来</span>    <span class="token function">REQUIRE</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//    REQUIRE 在检查项错误的时候，会停下程序</span>    <span class="token function">CHECK_FALSE</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//    等价于 CHECK(1 != 0);</span>    <span class="token function">REQUIRE_FALSE</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//  等价于 REQUIRE(1 != 0);</span>    <span class="token comment" spellcheck="true">// 检测当前表达式中是否没有异常</span>    <span class="token function">REQUIRE_NOTHROW</span><span class="token punctuation">(</span>expression<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">CHECK_NOTHROW</span><span class="token punctuation">(</span>expression<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//    检测当前表达式是否有异常</span>    <span class="token function">REQUIRE_THROWS</span><span class="token punctuation">(</span>expression<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">CHECK_THROWS</span><span class="token punctuation">(</span>expression<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>但是 CHECK 这种，在宏展开的时候会有些问题：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token comment" spellcheck="true">//    error</span><span class="token function">CHECK</span><span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">1</span> <span class="token operator">&amp;&amp;</span> b <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">CHECK</span><span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">||</span> b <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//    right</span><span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">1</span> <span class="token operator">&amp;&amp;</span> b <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">||</span> b <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h1 id="SECTION"><a href="#SECTION" class="headerlink" title="SECTION"></a>SECTION</h1><p><code>SECTION</code> 主要用于测试某个类的多个函数。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token function">TEST_CASE</span><span class="token punctuation">(</span> <span class="token string">"vectors can be sized and resized"</span><span class="token punctuation">,</span> <span class="token string">"[vector]"</span> <span class="token punctuation">)</span> <span class="token punctuation">{</span>    std<span class="token operator">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">v</span><span class="token punctuation">(</span> <span class="token number">5</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">5</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">capacity</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">5</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">SECTION</span><span class="token punctuation">(</span> <span class="token string">"resizing bigger changes size and capacity"</span> <span class="token punctuation">)</span> <span class="token punctuation">{</span>        v<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span> <span class="token number">10</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">10</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">capacity</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">10</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token function">SECTION</span><span class="token punctuation">(</span> <span class="token string">"resizing smaller changes size but not capacity"</span> <span class="token punctuation">)</span> <span class="token punctuation">{</span>        v<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">REQUIRE</span><span class="token punctuation">(</span> v<span class="token punctuation">.</span><span class="token function">capacity</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">5</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h1 id="Matchers"><a href="#Matchers" class="headerlink" title="Matchers"></a>Matchers</h1><p>当前的表达式在 matcher 中是否成立</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token function">REQUIRE_THAT</span><span class="token punctuation">(</span>expression<span class="token punctuation">,</span> matchers<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>验证某个 string 是否以某个 string 结束：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">using</span> Catch<span class="token operator">::</span>Matchers<span class="token operator">::</span>EndsWith<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// or Catch::EndsWith</span>std<span class="token operator">::</span>string str <span class="token operator">=</span> <span class="token function">getStringFromSomewhere</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">REQUIRE_THAT</span><span class="token punctuation">(</span>str<span class="token punctuation">,</span> <span class="token function">EndsWith</span><span class="token punctuation">(</span><span class="token string">"as a service"</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>验证某个 string 是否以某个 string 开始：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">using</span> Catch<span class="token operator">::</span>Matchers<span class="token operator">::</span>StartsWith<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// or Catch::EndsWith</span>std<span class="token operator">::</span>string str <span class="token operator">=</span> <span class="token function">getStringFromSomewhere</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">REQUIRE_THAT</span><span class="token punctuation">(</span>str<span class="token punctuation">,</span> <span class="token function">StartsWith</span><span class="token punctuation">(</span><span class="token string">"as a service"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>验证某个 string 是否包含某个 string：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">using</span> Catch<span class="token operator">::</span>Matchers<span class="token operator">::</span>StartsWith<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// or Catch::EndsWith</span>std<span class="token operator">::</span>string str <span class="token operator">=</span> <span class="token function">getStringFromSomewhere</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">REQUIRE_THAT</span><span class="token punctuation">(</span>str<span class="token punctuation">,</span> <span class="token function">Contains</span><span class="token punctuation">(</span><span class="token string">"as a service"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;目前使用的测试框架，好处就是只有头文件，方便无论是新人还是老人进行开发（gtest 需要编译成 静态库，使用上有点难度）&lt;/p&gt;
&lt;h1 i
      
    
    </summary>
    
    
      <category term="Test" scheme="https://dancsmshenry.github.io/tags/Test/"/>
    
  </entry>
  
  <entry>
    <title>开发工具使用之 Git</title>
    <link href="https://dancsmshenry.github.io/2024/05/04/kai-fa-gong-ju-shi-yong-zhi-git/"/>
    <id>https://dancsmshenry.github.io/2024/05/04/kai-fa-gong-ju-shi-yong-zhi-git/</id>
    <published>2024-05-04T05:51:54.000Z</published>
    <updated>2024-09-17T06:10:19.605Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Git-常用指令"><a href="#Git-常用指令" class="headerlink" title="Git 常用指令"></a>Git 常用指令</h1><h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><pre class="line-numbers language-shell"><code class="language-shell"># 将某个文件的修改提交到暂存区git add filename# 将所有发生过修改的，以及新增的文件都添加到暂存区中git add .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h2 id="branch"><a href="#branch" class="headerlink" title="branch"></a>branch</h2><pre class="line-numbers language-shell"><code class="language-shell"># 创建分支git branch branch_name# 删除分支git branch -d branch_namegit branch -D branch_name # 强制删除该分支# 查看分支git branch # 查看本地所有分支（其中带有星号的是当前分支）git branch -a # 查看本地和远程的所有分支# 重命名分支git branch -m old_name new_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h2 id="checkout"><a href="#checkout" class="headerlink" title="checkout"></a>checkout</h2><pre class="line-numbers language-shell"><code class="language-shell"># 切换到指定分支git checkout branch_name# 创建分支并切换到该分支上git checkout -b branch_name# 以某次 commitid 的代码创建新的分支，并切换到该分支上git checkout -b branch_name commit_id# 将工作区的代码恢复至暂存区的状态git checkout .# 以某个 commitid 的代码创建一条临时的分支，并切换到这条临时分支上# 此时的 HEAD 处于游离状态，并不指向任何分支，如果切到其他的分支上，该临时分支就会消失git checkout commit_id# 将某个文件的内容，恢复至暂存区的状态git checkout file_name# 将某个文件夹的内容，恢复至暂存区的状态git checkout file_folder<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>假设当前是在分支的最新的一次提交上</p><p><code>git checkout commit_id</code> 可以获取某次 commitid 时的代码，并替换至工作区</p><p>如果希望回到最新的一次提交上，就 <code>git checkout master</code></p><br><p>记录一次关于 git checkout 的问题</p><p>因为我最开始没有在本地创建分支（之前的开发都是在本地修改提交，所以不需要创建分支；此时的 HEAD 就是游离状态 detached）</p><p>而当我使用了 <code>git checkout commit_id</code> 后，此时 HEAD 依然是游离的（HEAD detached at 09cb312）</p><p>如果想要回到最开始的状态（即刚拉下代码的那个版本），使用 <code>git checkout master</code> 必然是回不去的</p><p>所以此时需要先<code>git checkout origin/master</code> 同步到远程的 master 分支上</p><p>（这里可以用 <code>git branch -a</code> 查看远程主机的名字，接着再 checkout）</p><p>注：不能删除当前所在的分支；<code>git checkout origin/master</code> 会使得 HEAD 变为游离状态</p><br><br><h2 id="cherry-pick"><a href="#cherry-pick" class="headerlink" title="cherry-pick"></a>cherry-pick</h2><pre class="line-numbers language-shell"><code class="language-shell"># 将某次提交的 commit 摘取到当前的分支上（可能会出现冲突）git cherry-pick commitId<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br><br><h2 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h2><pre class="line-numbers language-shell"><code class="language-shell"># 提交 commit，并添加 commit 信息git commit -m "message"# 等价于 git add -a 和 git commit -m "message"git commit -am "message"# 会在提交的后面加上签名git commit -s -m "message"# 在不增加一次新 commit 的情况下将新修改的代码追加到上一次的 commit 中（会弹出一个编辑器界面重新编辑 message 信息）# 一般用于代码 review 后出现问题，修改后再提交git commit --amend# 在不增加一个新 commit 的情况下将新修改的代码追加到前一次的 commit 中（不需要再修改 message 信息）git commit --amend --no-edit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>-s</code> 后，在 commit message 里面会多一行 <code>Signed-off-by: xxx</code> 的内容</p><br><br><h2 id="log"><a href="#log" class="headerlink" title="log"></a>log</h2><pre class="line-numbers language-shell"><code class="language-shell"># 显示当前仓库的提交 commit 记录（从远到近）git log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br><br><h2 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h2><pre class="line-numbers language-shell"><code class="language-shell"># 合并分支（将指定分支合并到当前分支中），但是会多出一次合并的记录git merge branch_name# 退出 merge 过程git merge --abort# 继续 merge 过程git merge --continue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>个人感觉 merge 有些不好用，因为它会导致提交链上会存在多条的分支，并且会将其他提交链的多次 commit 合并为一条 merge branch “backup00” into backup01 的 commit，导致提交链不清晰（虽然 rebase 会导致时间上错乱，但是至少提交顺序上是清晰的）</p><br><br><h2 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h2><pre class="line-numbers language-shell"><code class="language-shell"># 拉取远程仓库指定分支上最新的代码# 等价于 fetch + mergegit pull remote_name branch_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><br><h2 id="push"><a href="#push" class="headerlink" title="push"></a>push</h2><pre class="line-numbers language-shell"><code class="language-shell"># 推送代码到远程仓库的指定分支上# 向远程仓库推送指定分支git push remote_name branch_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><br><h2 id="rebase"><a href="#rebase" class="headerlink" title="rebase"></a>rebase</h2><pre class="line-numbers language-shell"><code class="language-shell"># 对过去的 n 次提交进行相应的操作，其中 reword 表示只修改 commit message；edit 表示修改内容git rebase -i HEAD~n# 变基某个分支，将当前分支基于相同父节点的提交，移植到某条分支上git rebase branch_name# 退出 rebase 过程，常在处理冲突出错时使用git rebase --abort# 继续 rebase 过程，常在处理完冲突时使用git rebase --continue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>rebase 合并此前的 n 次提交：</p><p>例如说要将前 4 次提交全部都合并在一起</p><p><code>git rebase -i commit_id</code> 这里的 commit_id 应该是前五次的 commit_id（这里也可以 <code>git rebase -i HEAD~4</code>）</p><p>进入界面后，将前四次的 commit 前的字母单词全部改为 squash ，然后保存，ctrl + x 退出</p><p>接着再进入界面修改 commit message，保存，ctrl + x 退出</p><p>最后 git push origin master</p><br><p>squash 会将当前提交和上一次提交合在一起，然后会把 commit message 合在一起（当然也可以直接在页面上把这个 message 给删掉）</p><p>fixup 和 squash 一样，但是不会保留 commit message</p><p>drop 直接删除某次提交（如果有依赖，就需要解决冲突）</p><br><p>假设当前在 feature 分支上，git rebase master 本质上其实是将当前的 feature 和 master 上的内容，共用同一个基点。</p><p>什么意思呢？</p><p>就是说，如果 master 没有动，没有修改，然后 feature 在 master 的基础上修改了很多的内容</p><p>然后再进行上面的操作的话，在 git 的眼里，master 和 feature 是共用同一个基点的，而 master 上面后续又没有提交，所以 git 是不会把提交摘到 master 上面的（这种情况下就需要用 cherry-pick）</p><br><p>而，如果 master 上面还有提交，那么这个时候，rebase 才会将提交给移过去</p><br><p>注：在 git rebase master 之后，master 分支的指针还是会指向原来的位置，而 feature 分支的指针会指向最新合并后得到的 commit 上</p><p>例如说，在上述 git rebase 起了冲突之后，首先会将 feature 分支上的提交显示出来，然后通过 git add + git rebase –continue 的操作，进行合并（cherry-pick 也是一样，如果摘过去后出现了冲突，那么就会解决冲突，然后 <code>git cherry-pick continue</code>）</p><p>存疑：这个指令 <code>git cherry-pick continue</code> 是不是在某个 git 的版本之后才有的？</p><br><br><h2 id="reset"><a href="#reset" class="headerlink" title="reset"></a>reset</h2><pre class="line-numbers language-shell"><code class="language-shell"># 常用的三个参数： --hard，--soft，--mixed，不加参数的时候默认是 --soft# 将当前仓库的版本，回退到过去某次 commit 的时候# 此处的 HEAD^ （回退多少个版本，就加几个^）可以换成 commitid（可以只写 id 的前几位）git reset --hard HEAD^ # 回退到某个版本，并将当时 commit 提交的内容以及当前工作区和暂存区的内容全部删掉git reset --soft HEAD^ # 回退到某个版本，并将当时 commit 提交的内容保存至暂存区，且不会破坏当前工作区和暂存区                       # （一般用于撤销本地仓库中未提交（到远程仓库）的 commit）# 将某个文件在暂存区的修改撤销至工作区git reset filename# 撤销所有暂存区的修改撤销至工作区git reset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h2 id="reflog"><a href="#reflog" class="headerlink" title="reflog"></a>reflog</h2><pre class="line-numbers language-shell"><code class="language-shell"># 查看过去执行的 git 指令git reflog<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br><br><h2 id="status"><a href="#status" class="headerlink" title="status"></a>status</h2><pre class="line-numbers language-shell"><code class="language-shell"># 显示文件和文件夹在工作区和暂存区的状态git status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br><br><h2 id="stash"><a href="#stash" class="headerlink" title="stash"></a>stash</h2><pre class="line-numbers language-shell"><code class="language-shell"># 将当前的工作进度保存到栈里面，并将工作区和暂存区恢复到本次修改之前# stash 命令默认不包含未跟踪的文件（新建的文件需要被 add 之后，才能被跟踪）git stashgit stash -u # 可以保存未被 git 跟踪的文件，例如新创建的文件# 删除所有保存的工作进度git stash clear# 显示保存的工作进度列表，编号越小代表保存进度的时间越近git stash list# 恢复已保存的工作进度，顺序是先进后出git stash pop # 不带选项，则默认恢复到最近的一次工作进度中git stash pop stash@{0} # 带选项，则表示恢复到指定进度上# 删除已保存的工作进度git stash drop # 不带选项，则删除最近保存的工作进度中git stash drop stash@{0} # 带选项，则表示删除指定的工作进度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h2 id="show"><a href="#show" class="headerlink" title="show"></a>show</h2><pre class="line-numbers language-shell"><code class="language-shell"># 依次显示每次 commit 的具体提交信息和数据变更信息git show# 显示某次具体的 commitid 对应的提交信息和数据变更信息git show commit_id# 显示某条分支对应的提交信息和数据变更信息git show branch_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="Git-commit-message-规范"><a href="#Git-commit-message-规范" class="headerlink" title="Git commit message 规范"></a>Git commit message 规范</h1><p>参考：<a href="https://www.conventionalcommits.org/zh-hans/v1.0.0-beta.4/" target="_blank" rel="noopener">https://www.conventionalcommits.org/zh-hans/v1.0.0-beta.4/</a></p><p><code>&lt;type&gt;[(&lt;scope&gt;)]: &lt;subject&gt;</code></p><h2 id="type"><a href="#type" class="headerlink" title="type"></a>type</h2><p>用于声明本次代码提交的类型（建议英文，<strong>必填项</strong>）</p><p>build：编译工具的变动，更倾向于 cmakeLists 或是 maven 的配置文件等</p><p>chroe：工具的变动，倾向于 .jenkins 文件等的修改</p><p>doc：文档变动</p><p>feat：新功能特性</p><p>fix：bug 修复</p><p>merge：代码分支合并</p><p>perf：功能优化，包括性能优化、体验优化等</p><p>refactor：代码重构（大范围的代码结构重构，不涉及代码功能）</p><p>revert：代码版本回滚</p><p>style：格式调整（小范围的代码格式调整，不涉及代码功能）</p><p>test：测试代码变动，例如添加测试用例</p><br><br><h2 id="scope"><a href="#scope" class="headerlink" title="scope"></a>scope</h2><p>用于声明本次代码提交的影响范围（建议英文，<strong>选填项</strong>）</p><p>如 Model 层、Dao 层、Service 层、Controller 层、View 层等等</p><p>如果涉及多个 scope，可以置空或用 * 代替</p><br><p>在目前的项目中暂时是没有用到的，当然也可能是因为我们将多个组件拆分为了不同的仓库，用 repo 对这些仓库进行管理</p><br><br><h2 id="subject"><a href="#subject" class="headerlink" title="subject"></a>subject</h2><p>用于声明本次代码提交的描述信息（建议英文，<strong>必填项</strong>）。通常控制在 50 个字符内，且省略句末标点符号</p><br><p>着重需要注意的是 fix 的 message，需要表明当前修复了什么问题，亦或是说当前做了什么解决了什么问题</p><p>然后在后面的描述中描述问题出现的场景以及修复的具体操作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Git-常用指令&quot;&gt;&lt;a href=&quot;#Git-常用指令&quot; class=&quot;headerlink&quot; title=&quot;Git 常用指令&quot;&gt;&lt;/a&gt;Git 常用指令&lt;/h1&gt;&lt;h2 id=&quot;add&quot;&gt;&lt;a href=&quot;#add&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
      <category term="Tool" scheme="https://dancsmshenry.github.io/tags/Tool/"/>
    
  </entry>
  
  <entry>
    <title>一些 cpp 的编码规范</title>
    <link href="https://dancsmshenry.github.io/2024/03/17/yi-xie-cpp-de-bian-ma-gui-fan/"/>
    <id>https://dancsmshenry.github.io/2024/03/17/yi-xie-cpp-de-bian-ma-gui-fan/</id>
    <published>2024-03-17T08:11:58.000Z</published>
    <updated>2024-09-17T06:10:19.604Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么时候使用前置声明"><a href="#什么时候使用前置声明" class="headerlink" title="什么时候使用前置声明"></a>什么时候使用前置声明</h2><p>为了防止循环引用的情况发生</p><p>避免头文件的使用者引入过多的无用的头文件（希望屏蔽底层的实现细节）</p><br><br><br><h2 id="是否需要有-assert"><a href="#是否需要有-assert" class="headerlink" title="是否需要有 assert"></a>是否需要有 assert</h2><p>assert 只在 debug 的模式下才会生效，而 debug 模式并不会是生产模式下使用的，因此最好只在调试阶段使用</p><p>可以使用 static_assert，主要是给模板用的 </p><br><br><br><h2 id="函数的命名规范"><a href="#函数的命名规范" class="headerlink" title="函数的命名规范"></a>函数的命名规范</h2><p>当 socket 收到具体的数据的时候，使用 Onxxx，例如 onTcpMessage，onUdpMessage</p><br><br><br><h2 id="关于-auto-的使用规范"><a href="#关于-auto-的使用规范" class="headerlink" title="关于 auto 的使用规范"></a>关于 auto 的使用规范</h2><p>在标准库的迭代器里面使用，或者标准库函数里面放 lambda 表达式时，（入参可以为 auto，14之后是可以的）</p><p>在返回值确定的情况下（例如说 <code>make_shared_&lt;int&gt;</code>，又或者说是 <code>xxx.get_future()</code>）</p><p>或者说变量的命名清楚确定的情况下（例如 afterResult 等）</p><br><br><br><h2 id="关于-log-的打印和等级"><a href="#关于-log-的打印和等级" class="headerlink" title="关于 log 的打印和等级"></a>关于 log 的打印和等级</h2><p>使用 error 的情况：解析数据的过程中出现了问题，或者数据中有意料之外的情况（比如说2012的版本，是没有 tls 的接口的）；读取数据发生错误，或者长度不符合预期</p><p>使用 debug 的情况：正式的代码中是不能有 debug 的代码的，debug仅在调试和测试的时候使用</p><p>使用 info 的情况：代码执行某个流程开始或者结束</p><p>使用 warn 的情况：当收到了报文，但在校验的时候发生了错误</p><br><br><br><h2 id="shared-ptr，unique-ptr-还是-raw-point-的使用规范"><a href="#shared-ptr，unique-ptr-还是-raw-point-的使用规范" class="headerlink" title="shared_ptr，unique_ptr 还是 raw point 的使用规范"></a>shared_ptr，unique_ptr 还是 raw point 的使用规范</h2><p>对于智能指针 std::unique_ptr/std::shared_ptr 到底是传入 引用还是值就目前的场景来看，感觉更多的时候需要传入的是值</p><br><br><br><h2 id="对于-function-和-lambda-的区别分析"><a href="#对于-function-和-lambda-的区别分析" class="headerlink" title="对于 function 和 lambda 的区别分析"></a>对于 function 和 lambda 的区别分析</h2><p>对于 funciton，传递 引用 值 右值 那个效率更高</p><p>lambda 转 std::function&lt;void()&gt;&amp; 为什么不行？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么时候使用前置声明&quot;&gt;&lt;a href=&quot;#什么时候使用前置声明&quot; class=&quot;headerlink&quot; title=&quot;什么时候使用前置声明&quot;&gt;&lt;/a&gt;什么时候使用前置声明&lt;/h2&gt;&lt;p&gt;为了防止循环引用的情况发生&lt;/p&gt;
&lt;p&gt;避免头文件的使用者引入过多的无用的
      
    
    </summary>
    
    
      <category term="CPP" scheme="https://dancsmshenry.github.io/tags/CPP/"/>
    
  </entry>
  
  <entry>
    <title>开发工具使用之 Cmake</title>
    <link href="https://dancsmshenry.github.io/2023/11/21/kai-fa-gong-ju-shi-yong-zhi-cmake/"/>
    <id>https://dancsmshenry.github.io/2023/11/21/kai-fa-gong-ju-shi-yong-zhi-cmake/</id>
    <published>2023-11-21T15:25:05.000Z</published>
    <updated>2025-03-19T16:40:50.737Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h1><p>常用的编译脚本和 CmakeLists.txt</p><h2 id="build-sh"><a href="#build-sh" class="headerlink" title="build.sh"></a>build.sh</h2><pre class="line-numbers language-shell"><code class="language-shell">#!bin/sh#    Create makefilecmake -B build \-DCMAKE_BUILD_TYPE=Release \-DCMAKE_INSTALL_PREFIX=./build/release \-DCMAKE_EXPORT_COMPILE_COMMANDS=ON# Compilecmake --build build --parallel 96# Installcmake --build build --target install# Compile and installcmake --build build \--parallel 96 \--target install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><h2 id="CMakeLists-txt"><a href="#CMakeLists-txt" class="headerlink" title="CMakeLists.txt"></a>CMakeLists.txt</h2><pre class="line-numbers language-cmake"><code class="language-cmake">cmake_minimum_required(VERSION 3.16)project(learning_cmake LANGUAGES C CXX)if (PROJECT_BINARY_DIR STREQUAL PROJECT_SOURCE_DIR)    message(WARNING "The binary directory of CMake cannot be the same as source directory!")endif()add_executable(main)aux_source_directory(. SOURCES)aux_source_directory(src SOURCES)target_sources(main PUBLIC ${SOURCES})####################### Begin build dog shared library #######################add_library(dog SHARED dog/src/dog.cc)target_include_directories(dog    PUBLIC    ${CMAKE_CURRENT_SOURCE_DIR}/dog/include)set_target_properties(dog    PROPERTIES        CXX_STANDARD 17        CXX_STANDARD_REQUIRED ON        CXX_EXTENSIONS OFF)####################### End build dog shared library #######################set_target_properties(main    PROPERTIES        CXX_STANDARD 17        CXX_STANDARD_REQUIRED ON        CXX_EXTENSIONS OFF)target_link_libraries(main PUBLIC dog)target_include_directories(main  PUBLIC        ${CMAKE_CURRENT_SOURCE_DIR}/include)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="编译的两阶段"><a href="#编译的两阶段" class="headerlink" title="编译的两阶段"></a>编译的两阶段</h1><p>第一阶段是 <code>cmake -B build</code>，称为<strong>配置阶段</strong>（configure），这时只检测环境并生成构建规则，会在 build 目录下生成本地构建系统能识别的项目文件（Makefile 或是 .sln）。</p><ul><li>在配置阶段，可以利用 -D 指定配置变量（即一些缓存变量），这些变量会被在本地缓存，即使后续只是 cmake -B build ，前面的缓存也会被使用到</li><li><strong>注意</strong>：在一些场景下，可能存在修改了CMakeLists 文件，但是无论如何编译，修改的变量都没有生效，这个时候需要删除 CMakeCache.txt 文件</li></ul><br><p>第二阶段是 <code>cmake --build build</code>，称为<strong>构建阶段</strong>（build），这时才实际调用编译器来编译代码。</p><br><br><br><h2 id="常见的编译参数"><a href="#常见的编译参数" class="headerlink" title="常见的编译参数"></a>常见的编译参数</h2><ul><li><code>-DCMAKE_EXPORT_COMPILE_COMMANDS</code> 用于生成 json 数据库文件，以便第三方插件进行代码跳转</li><li><code>-DCMAKE_INSTALL_PREFIX</code> 指定安装路径，同时也用于寻找依赖的第三方库</li><li><code>-DCMAKE_BUILD_TYPE</code> 指定编译的版本，可选值有 release，debug 和 profile</li><li><code>-DCMAKE_TOOLCHAINS_FILE</code> 指定交叉编译工具链的 .cmake 文件</li></ul><br><br><br><h1 id="生成可执行文件"><a href="#生成可执行文件" class="headerlink" title="生成可执行文件"></a>生成可执行文件</h1><p>实际上有非常多的方法，将 .cc/.cpp 文件编译成可执行，这里只推荐两种</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 第一种# 先设置最终得到的可执行文件，再用一个变量存储源文件，# 最后使用 target_sources 将源文件添加到可执行中add_executable(main)set(sources main.cc other.cc)target_sources(main PUBLIC ${sources})# 第二种# 使用 aux_source_directory 自动搜集需要文件的后缀名add_executable(main)aux_source_directory(. sources)aux_source_directory(src sources)target_sources(main PUBLIC ${sources})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="生成动态-静态-对象库"><a href="#生成动态-静态-对象库" class="headerlink" title="生成动态/静态/对象库"></a>生成动态/静态/对象库</h1><p>其中对象库类似于静态库，但不生成 .a 文件，只由 CMake 记住该库生成了哪些对象文件</p><p>对象库不生成 .a 文件，只由 CMake 记住该库生成了哪些对象文件，因此就有人推荐用对象库代替静态库，避免跨平台的麻烦</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 第一个是库的名字# 第二个表示要将当前库编译成静态、动态还是对象库# 最后是要编译的文件add_library(mylib STATIC mylib.cc)add_library(mylib SHARED mylib.cc)add_library(mylib OBJECT mylib.cc)add_executable(main main.cc)target_link_libraries(main PUBLIC mylib)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><p>一个比较坑的问题，动态库无法连接静态库，解决办法就是设置 <code>set(CMAKE_POSITION_INDEPENDENT_CODE ON)</code></p><pre class="line-numbers language-cmake"><code class="language-cmake"># 设置全体库为 PICset(CMAKE_POSITION_INDEPENDENT_CODE ON)add_library(otherlib STATIC otherlib.cc)add_library(mylib SHARED mylib.cc)target_link_libraries(mylib PUBLIC otherlib)add_executable(main main.cc)target_link_libraries(main PUBLIC mylib)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="设置头文件的搜索路径"><a href="#设置头文件的搜索路径" class="headerlink" title="设置头文件的搜索路径"></a>设置头文件的搜索路径</h1><p>个人非常建议以 target 的形式，管理头文件。</p><p>只有在非常非常少见的场景或是需求，才需要用 include_directories 来指定目录。</p><p>一般有两种方式来设置头文件的检索路径：</p><ul><li>第一种是使用 <code>include_directories</code> 指定目录</li></ul><p><code>include_directories</code>用于将给定的目录添加到编译器，便于搜索包含文件的目录</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 将当前目录下的 include 目录添加到后续 .h 文件的搜索路径中include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>也就是说，后续在 .cc 文件中填写的如果是相对路径，那么就会被解释为在当前这个源目录下的路径</p><p>比如说我们想要引入 include 文件夹下的 test.h 文件，文件真实路径为 <code>include/test.h</code></p><p>那么在主目录中的 main.cc 就只需要 <code>#include &quot;test.h&quot;</code>即可引入</p><br><br><p><code>target_link_directories</code>则更加细粒度的规定了头文件的引用范围，作用和<code>include_directories</code>相同</p><br><p><strong>PRIVATE</strong></p><p>被设定为 PRIVATE 的目录，下属的文件不能对项目外暴露，也不对项目内设为 PUBLIC 的文件暴露</p><p>举例： include 下有两个目录：private 和 public，二者都存放 .h 文件，src 目录存放 .cc 文件</p><p>其中目录 private 被设为 PRIVATE，目录 public 被设为 PUBLIC</p><p>则，src 下的 .cc 文件可以使用 private 的文件，include/public 下的头文件和项目外的文件不可以使用 private 的文件</p><br><p>从两种目录结构的角度进行理解：</p><p>角度一：项目目录的结构是，将 .h 文件统一放到 include 中，再在 include 中拆分出 private 和 public</p><ul><li>则 PRIVATE 表示该目录下的头文件，只能给本目录下的 .cc 文件使用，不对外提供接口（例如一些辅助性的类）</li></ul><br><p>角度二：项目目录的结构是，将 .h 文件和 .cc 文件都放在一起，按照库或模块对文件进行分类</p><ul><li>设库 B 为该项目对外提供的库，库 B 依赖于库 A，库 A 的代码在库 B 的代码结构中，而将库 A 设为 PRIVATE 后，则表示库 A 只会提供给库 B 使用，而不会传导给库 B 的使用者，即没有传递性</li></ul><pre class="line-numbers language-cmake"><code class="language-cmake">target_include_directories(dog PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}/include/private)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><p><strong>INTERFACE</strong></p><p>被设定为 INTERFACE 的目录，下属的文件对项目外的文件以及项目内被设为 PUBLIC 的文件暴露，不对项目内的可执行文件暴露</p><p>举例： include 下有两个目录：interface 和 public，二者都存放 .h 文件，src 目录存放 .cc 文件</p><p>其中目录 interface 被设为 INTERFACE，目录 public 被设为 PUBLIC</p><p>则，src 下的 .cc 文件不可以使用 interface 的文件，include/public 下的头文件和项目外的文件可以使用 interface 的文件</p><br><p>从两种目录结构的角度进行理解：</p><p>角度一：项目目录的结构是，将 .h 文件统一放到 include 中，再在 include 中拆分出 interface 和 public</p><ul><li>则 INTERFACE 表示该目录下的头文件，是对外提供接口的（因此可以被设为 PUBLIC 的头文件使用），但是不能对当前目录下 .cc 文件暴露</li></ul><p>角度二：项目目录的结构是，将 .h 文件和 .cc 文件都放在一起，按照库或模块对文件进行分类</p><ul><li>设库 B 为该项目对外提供的库，库 B 不依赖于库 A，库 A 的代码在库 B 的代码结构中，而将库 A 设为 INTERFACE  后，则表示库 A 不会提供给库 B 使用，而是会直接给使用者用户，也不算有传递性</li></ul><pre class="line-numbers language-cmake"><code class="language-cmake">target_include_directories(dog INTERFACE ${CMAKE_CURRENT_SOURCE_DIR}/include/public)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><p><strong>PUBLIC</strong></p><p>被设定为 PUBLIC 的目录，谁都可以使用</p><br><p>从两种目录结构的角度进行理解：</p><p>角度一：项目目录的结构是，将 .h 文件统一放到 include 中，再在 include 中拆分出 interface 和 public</p><ul><li>则 PUBLIC 表示该目录下的头文件，谁都可以使用</li></ul><p>角度二：项目目录的结构是，将 .h 文件和 .cc 文件都放在一起，按照库或模块对文件进行分类</p><ul><li>设库 B 为该项目对外提供的库，库 A 的代码在库 B 的代码结构中，无论库 B 是否依赖于库 A，只要将库 A 设为 PUBLIC 后，则库 B 和用户使用者都可以使用，即有传递性</li></ul><pre class="line-numbers language-cmake"><code class="language-cmake">target_include_directories(dog PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}/include/public)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><br><br><h1 id="添加构建子模块"><a href="#添加构建子模块" class="headerlink" title="添加构建子模块"></a>添加构建子模块</h1><pre class="line-numbers language-cmake"><code class="language-cmake">add_subdirectory(dog)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>具体格式：<code>add_subdirectory (source_dir [binary_dir] [EXCLUDE_FROM_ALL])</code></p><p>必选参数：<code>source_dir</code> 指定一个子目录，子目录下应该包含 CMakeLists.txt 文件和代码文件（可以是相对路径或绝对路径）</p><p>可选参数：binary_dir 指定一个子目录，用于存放子目录的二进制文件（如果不指明的话，那么生成的二进制文件和 makefile 就会和主目录是在同一个路径下），也可以写相对路径（比如是在主目录下的 cmakelists.txt 中写的，那么相对路径就可以写为 ../demo-apps/build）</p><br><br><br><h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><p>DIRECTORY，例如 <code>include(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include ESTINATION${CMAKE_INSTALL_INCLUDEIR})</code></p><p>就是将指定目录下的文件（include 下的文件），全部移动到指定文件目录下</p><p>FILE，用法同上，就是将指定文件，移动到指定目录下</p><p>TARGET，安装指定的目标文件</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 将二进制可执行文件 myrun 安装到目录 ${PROJECT_SOURCE_DIR}/build/bininstall(TARGETS myrun    RUNTIME DESTINATION ${PROJECT_SOURCE_DIR}/build/bin # 二进制可执行文件    LIBRARY DESTINATION ${PROJECT_SOURCE_DIR}/build/lib # 动态库    ARCHIVE DESTINATION ${PROJECT_SOURCE_DIR}/build/lib # 静态库)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><h1 id="常用语法"><a href="#常用语法" class="headerlink" title="常用语法"></a>常用语法</h1><h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><p>向指定的 list 进行操作</p><pre class="line-numbers language-cmake"><code class="language-cmake">list(APPEND <list><element> [<element>...])list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_LIST_DIR}/cmake")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>向 list 中添加数据 element</p><p>PS：这里给 .cmake 模块指定了文件夹以后，后续的子模块可以直接 include 对应的 .cmake 文件并使用，而不需要重新指定路径</p><br><br><h2 id="option"><a href="#option" class="headerlink" title="option"></a>option</h2><pre class="line-numbers language-cmake"><code class="language-cmake">option(ARA_CXX_STANDARD_EXTENSIONS "Description" OFF)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>一般用于控制编译流程，可以理解为 c 语言里面的宏，即条件编译</p><p><code>option(&lt;variable&gt; &quot;&lt;help_text&gt;&quot; [value])</code></p><ul><li><code>variable</code>：定义选项名称</li><li><code>help_text</code>：说明选项的含义</li><li><code>value</code>:定义选项默认状态，一般是 OFF 或者 ON，除去 ON 之外，其他所有值都为认为是 OFF</li><li>PS：如果主目录的 cmakelists 和子目录的 cmakelists 中定义的变量值不同，比如主目录中定义为 ON，子目录中定义为 OFF，那么遵循主目录中的内容</li></ul><p>这里看到主目录定义了 ARA_CXX_STANDARD_EXTENSIONS ，后面的子目录就会用这个宏，来判断是否要加上 c++ 的编译拓展</p><br><br><h2 id="if"><a href="#if" class="headerlink" title="if"></a>if</h2><pre class="line-numbers language-cmake"><code class="language-cmake">if (CMAKE_BINARY_DIR STREQUAL CMAKE_CURRENT_SOURCE_DIR)    #    如果 CMAKE_BINARY_DIR 等于 CMAKE_CURRENT_SOURCE_DIR，则__endif()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><br><h2 id="message"><a href="#message" class="headerlink" title="message"></a>message</h2><p>message 一般用于输出日志，可以分为不同的等级</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 输出字符串内容message("hello world!")# STATUS 输出状态信息，会带有 -- 前缀message(STATUS "hello world!")# FATAL_ERROR 输出错误信息，终止程序执行message(FATAL_ERROR "Test1")# WARNING 输出警告信息，继续执行message(WARNING "test in warning")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><br><br><br><p>cmake 的基本配置</p><pre class="line-numbers language-cmake"><code class="language-cmake"># 指定最低所需的 cmake 版本，当用户使用的 cmake 小于这个版本的时候，就会报错cmake_minimum_required(VERSION 3.16 FATAL_ERROR) # 在2.6以后的版本会被接受但是忽略cmake_minimum_required(VERSION 3.15...3.20) # 指定使用 cmake 的版本范围# project 初始化项目信息，并把当前 cmakelists.txt 所在位置作为根目录# 第一个 slot （NAME）用于指定项目的名称# 第二个 slot （VERSION）用于指定项目的版本号（可以把当前项目的版本号设定为 x.y.z；再通过一些宏可以获得具体的版本号）# 第三个 slot （DESCRIPTION）用于补充项目的具体信息# 第四个 slot （LANGUAGES）用于指定项目使用的语言（可以同时写多种语言）project(LearningCpp VERSION 1.0.0 LANGUAGES CXX)project(LearningC    VERSION 1.0.0    DESCRIPTION "a free open-source"    HOMEPAGE_URL http://www.baidu.com    LANGUAGES CXX C    )# 一些常用的宏# CMAKE_CURRENT_SOURCE_DIR 表示当前源码目录的位置，例如 ~/hellocmake# CMAKE_CURRENT_BINARY_DIR 表示当前输出目录的位置，例如 ~/hellocmake/build# PROJECT_SOURCE_DIR 表示最近一次调用 project 的 CMakeLists.txt 所在的源码目录（我理解为就是根目录的路径）# CMAKE_CURRENT_SOURCE_DIR 表示当前 CMakeLists.txt 所在的源码目录# CMAKE_SOURCE_DIR 表示最为外层 CMakeLists.txt 的源码根目录# CMAKE_BINARY_DIR 指的是存放二进制文件的文件夹# 设置 cpp 的编译选项set(CMAKE_CXX_STANDARD 17) # 选择 cpp 的编译版本；因此不要用 -std=17 指定版本，因为这样跨平台就会出问题；不过这里配置的一般是当前主项目的编译版本，其中子项目，例如编译成的相关静态库则需要用 set_target_properties 来表示set(CMAKE_CXX_STANDARD_REQUIRED ON) # bool 类型，表示是否一定要支持上述指定的 cpp 标准，off 表示 CMake 检测到编译器不支持 C++17 时不报错，而是默默调低到 C++14 给你用；on 则发现不支持报错，更安全set(CMAKE_CXX_EXTENSIONS ON) # 设为 ON 表示启用 GCC 特有的一些扩展功能；OFF 则关闭 GCC 的扩展功能，只使用标准的 C++；要兼容其他编译器（如 MSVC）的项目，都会设为 OFF 防止不小心用了 GCC 才有的特性；此外，最好是在 project 指令前设置 CMAKE_CXX_STANDARD 这一系列变量，这样 CMake 可以在 project 函数里对编译器进行一些检测，看看他能不能支持 C++17 的特性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><br><br><p>TODO</p><p>记录一个之前遇到的小bug：</p><p><code>set(CMAKE_EXPORT_COMPILE_COMMANDS ON)</code> 这句话不起作用，感觉是版本的原因</p><p>需要修改为<code>set(CMAKE_EXPORT_COMPILE_COMMANDS ON CACHE INTERNAL &quot;&quot;)</code>，这样才能生成 json 文件，以便 clang 实现代码跳转</p><p>2025.03,16 怀疑是 CMakeCache 文件没有删除</p><p>cmake中的 public，interface 和 private 大体思路上都是一样的，表示传递的依赖性：</p><p>public表示自己可以使用指定的头文件或是链接的库</p><p>interface表示自己不可以使用指定的头文件或是链接的库，但是当别的编译单元 target 指定当前单元时，可以使用 interface 标记的头文件和链接的库</p><p>private表示自己可以使用指定的头文件或是链接的库，但是别的编译单元使用当前单元时，就无法使用指定的头文件和链接的库</p><p><a href="https://blog.csdn.net/sinat_37231928/article/details/121684722" target="_blank" rel="noopener">https://blog.csdn.net/sinat_37231928/article/details/121684722</a></p><p><a href="https://zhuanlan.zhihu.com/p/82244559" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/82244559</a></p><p>需要学习如何使用 ninja 进行编译，cmake -g 指定编译工具？</p><p>关于 .cmake 文件</p><p>背景：为了防止 cmakelists.txt 文件过长，因此将其分为几个模块，同时也方便平台的组件共用该 cmake 文件，cmake 模块文件一般是后缀名为 .cmake</p><p><code>CMAKE_CURRENT_LIST_DIR</code> 是用分号分隔的目录列表（是一个 list ，也就是说可以有多个路径），cmake 使用该路径检查附带的 .cmake 文件模块；默认为空</p><p>如何在 windows 下使用 cmake</p><p>先去官网上下载 msi 安装包，然后安装</p><p>接着在 vscode 中安装插件 cmake 和 cmake tools</p><p>接着，cmake 有 makefile 和 ninja，所以需要把他们的可执行程序 exe 放到 cmake/bin 的目录下（当然，这个目录是被加入到系统变量中的）</p><ul><li>ninja 可以直接在官网的 github 上下载二进制程序</li><li>cmake 则需要先下载 mingw32 （我这里是和 llvm 一起下载了），然后把其中 llvm/bin 的可执行程序 mingw32-make 放到 cmake/bin 的目录下，再改名为 make</li></ul><p>最后是配置插件，cmake generator 将其配置为 Unix makefiles</p><p>注意：这个插件每次一打开目录，就会将 cmakelists 中的内容编译一遍，而上面则是用于修改 cmake 的默认生成构造器</p><br><p>记录一次灵异事件：在 windows 上构建 cmake 项目，始终出现找不到编译器的情况</p><pre class="line-numbers language-shell"><code class="language-shell">-- Building for: NMake Makefiles-- The C compiler identification is unknown-- The CXX compiler identification is unknownCMake Error at CMakeLists.txt:11 (project):  The CMAKE_C_COMPILER:    cl  is not a full path and was not found in the PATH.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>后续使用了指令 cmake -G”Unix Makefiles”  -B build ，才恢复正常</p><p>而且，必须要最开始执行这条指令，指定了 makefile 作为构造器，才能够正常运行</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Example&quot;&gt;&lt;a href=&quot;#Example&quot; class=&quot;headerlink&quot; title=&quot;Example&quot;&gt;&lt;/a&gt;Example&lt;/h1&gt;&lt;p&gt;常用的编译脚本和 CmakeLists.txt&lt;/p&gt;
&lt;h2 id=&quot;build-sh&quot;&gt;&lt;a h
      
    
    </summary>
    
    
      <category term="Tool" scheme="https://dancsmshenry.github.io/tags/Tool/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 08-Index Concurrency</title>
    <link href="https://dancsmshenry.github.io/2023/02/12/cmu-15-445-08-index-concurrency/"/>
    <id>https://dancsmshenry.github.io/2023/02/12/cmu-15-445-08-index-concurrency/</id>
    <published>2023-02-12T13:23:52.000Z</published>
    <updated>2024-09-17T06:10:19.530Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h1><p>前面的操作中，都假设只有一个线程去操作数据结构，但实际操作中是有多个线程同时操作数据库的</p><p>因此需要研究多线程如何安全的执行查询</p><p>并且在实现线程安全的同时，也要注意如何优化磁盘IO</p><br><p>存在一些只支持单线程的数据库（比如redis，只支持单线程去操作，一个用户操作完，别的用户才能进去）</p><ul><li>但redis还是比较高效的，有一部分是因为不需要考虑多线程并发的问题</li></ul><br><br><br><h1 id="Concurrency-control"><a href="#Concurrency-control" class="headerlink" title="Concurrency control"></a>Concurrency control</h1><p>并发控制协议需要保证对数据的操作后，得到的是正确的结果</p><br><p>并发控制分为两种：</p><ul><li>logical correctness：一个线程能够看到它应该看到的数据（事务并发设计的概念）</li><li>physical correctness：物理上的，数据的内部表示是否正确稳定的（本节课的重点）</li></ul><br><p>事务中的锁，是基于不同的数据结构的上锁流程的</p><ul><li>比如说在B+tree的结构中，从事务的角度来看，好像只是拿了当前数据位置的锁</li><li>而实际上，B+tree的并发协议会要求它不仅要拿当前数据位置的锁，上一层数据的锁也有可能要拿到</li><li>所以，我理解的是事务级别的锁实际上是将底层的锁进行了封装</li></ul><br><br><br><h1 id="Latches-overview"><a href="#Latches-overview" class="headerlink" title="Latches overview"></a>Latches overview</h1><img src="locks vs latches.png" style="zoom:150%;"><br><h2 id="Locks"><a href="#Locks" class="headerlink" title="Locks"></a>Locks</h2><p>指代逻辑上（宏观上）的锁，保护的是数据库中某个具体的数据（逻辑上的数据）</p><p>一般是被事务持有（事务上说的拿锁、释放锁都是指这个）</p><p>被修改的数据可以被回滚</p><p>同时，针对死锁有检测和预防</p><br><br><h2 id="Latches"><a href="#Latches" class="headerlink" title="Latches"></a>Latches</h2><p>指代数据结构上（微观上）的锁，保护的是数据库中某个具体的数据结构</p><ul><li><p>比如说上面说要锁一行数据，那么就会在那个数据结点上给一个latch</p></li><li><p>再或者说在B+树插入或删除数据的过程中，沿途也会加上很多的锁</p></li></ul><p>数据不需要回滚</p><p>是被某个操作过程所持有的</p><p>对于死锁，没有具体的解决方案</p><br><br><h2 id="Latch-modes"><a href="#Latch-modes" class="headerlink" title="Latch modes"></a>Latch modes</h2><p>锁的两种形式：读锁和写锁</p><img src="latch modes.png" style="zoom: 150%;"><br><h3 id="Read-mode"><a href="#Read-mode" class="headerlink" title="Read mode"></a>Read mode</h3><p>读锁（共享锁，S锁）；可以多个线程持有读锁</p><br><br><h3 id="Write-mode"><a href="#Write-mode" class="headerlink" title="Write mode"></a>Write mode</h3><p>写锁（独占锁，X锁）；只能一个线程持有写锁</p><br><br><h2 id="Latch-implementations"><a href="#Latch-implementations" class="headerlink" title="Latch implementations"></a>Latch implementations</h2><p>锁（latch，也就是mutex）的实现方式</p><br><h3 id="Blocking-OS-Mutex"><a href="#Blocking-OS-Mutex" class="headerlink" title="Blocking OS Mutex"></a>Blocking OS Mutex</h3><p>优点：简单方便（操作系统原生支持）</p><p>缺点：不能用于大规模竞争并发的场面（拓展性低）</p><p>比如cpp中的<code>std::mutex</code></p><pre class="line-numbers language-cpp"><code class="language-cpp">std<span class="token operator">::</span>mutex m<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 底层实现是pthread_mutex_t</span>m<span class="token punctuation">.</span><span class="token function">lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>m<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><p><code>pthread_mutex_t</code>的实现：</p><p>Linux接口中的pthread_mutex_t，底层实现是<strong>futex</strong></p><p>在用户态有一个flag，如果能够拿锁，就标记这个变量flag</p><p>如果此时有新的线程来拿锁，发现变量被标记了，线程就直接陷入内核态（类似让线程sleep，可以有效的降低锁的竞争，减少系统资源的消耗）</p><p>如果上面的线程又把锁释放了，那么OS就会唤醒上面进入内核态的线程</p><img src="futex.png" style="zoom:150%;"><p>缺点：把线程睡眠又唤醒，这种开销是比较大的</p><br><br><h3 id="Test-and-set-spin-latch"><a href="#Test-and-set-spin-latch" class="headerlink" title="Test and set spin latch"></a>Test and set spin latch</h3><p>自旋锁（Spin lock）</p><p>优点：非常高效（单个硬件指令就可以支持加解锁）</p><p>缺点：没办法应用于大规模的竞争，对缓存和OS不友好</p><img src="tas.png" style="zoom:150%;"><br><p>自旋锁的实现：<strong>TAS</strong></p><p>标志位latch，锁上的时候设置为1，解锁的时候设置为0</p><p>上锁的过程，是调用test_and_set函数</p><p>并用while检测函数返回的结果，在用户态不断地循环</p><br><p>因此这里对数据的操作都是原子操作（操作系统底层支持原子操作，即修改数据的过程中，别的线程是不能参与的）</p><p>而这里spin latch的实现方式<strong>test and set</strong>，是由硬件指令支持的原子操作，执行期间不会被打断</p><ul><li>包含了两个步骤：把给定的内存地址设置为1，然后返回之前的旧值</li><li>如果执行成功就会返回1，否则返回0</li></ul><br><p>建议：不要在用户态使用自旋锁，除非你真的知道它的实现</p><ul><li>因为其他的线程如果一直不释放锁，就会导致竞争的线程极度的浪费资源（多个线程会不断的检测这个锁有没有被解开）</li></ul><br><p>java给的一个思路就是：锁先疯狂的自旋，如果超过一定的时间，才会陷入内核态</p><br><br><h3 id="Read-write-latches"><a href="#Read-write-latches" class="headerlink" title="Read-write latches"></a>Read-write latches</h3><p>读写锁，但是不能作为锁的一种实现</p><ul><li>读写锁只是类型不同，但是锁的实现方式还是只有上面两种</li></ul><p>比如说此时有两个人加了读锁，那么后面第三个人如果想要加写锁，就要等前面两个人放掉读锁后才能继续写锁</p><p>再比如说如果此时还有人想加读锁，就不能加了，因为这里的加锁是要讲究<strong>顺序</strong>的，必须等上面的人把写锁加了，才能继续加读锁</p><br><br><br><h1 id="Hash-table-latching"><a href="#Hash-table-latching" class="headerlink" title="Hash table latching"></a>Hash table latching</h1><p>hash table是比较好加锁的</p><p>比如说开放地址hash，如果找不到slot就会往下找，因为查找的方向永远是从上往下的，不会有死锁（B+树可能会死锁）</p><p>当需要扩容的时候，就要加一个全局的写锁（global lock），因为扩容后数据结构会全部改变（不在扩容阶段，可以加局部锁）</p><br><br><h2 id="Page-latches"><a href="#Page-latches" class="headerlink" title="Page latches"></a>Page latches</h2><p><strong>以page为单位</strong>加读写锁</p><p>比如说要查找一个数据D，那么就要给slot所在的page加上一个读锁，如果当前page没有，就往下一个page去找，同时也要释放当前页面的latch</p><br><p>java里面的<code>ConcurrentHashMap</code>底层就是分段hash，并发控制用的就是page latches</p><p>锁的粒度不细（不需要维护太多的锁），也保证了一定的并发性</p><br><br><h2 id="Slot-latches"><a href="#Slot-latches" class="headerlink" title="Slot latches"></a>Slot latches</h2><p><strong>以slot（槽）为单位</strong>加读写锁</p><p>粒度变得更加的细致了，更加能够避免并发冲突</p><p>缺点：要维护的latch数量太多，大多数的场景是无法承受的</p><br><p>go里面的map是不支持并发的，但sync.map才是支持并发的</p><p>读写分离，主的hashtable是只读的，副的hashtable是用来写的</p><p>数据写完后定期将副hashtable的数据写到主hashtable中</p><p>优点：读的时候是无锁的</p><br><br><h2 id="Compare-and-swap"><a href="#Compare-and-swap" class="headerlink" title="Compare and swap"></a>Compare and swap</h2><p>构造无锁的hashtable的一种方法（实现无锁的一种解决方案）</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token function">__sync_bool_compare_and_swap</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>M<span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//    M是操作的变量的地址，20是原来这个变量上的值，30是我想要改为后得到的值</span><span class="token comment" spellcheck="true">//    语义就是把M变量的值改为30</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><p>实现：</p><ul><li>先让OS看看当前的M是不是20，如果是20的话就要把它锁住，然后把它改为30</li><li>通过先比较、再交换数据，借此解决并发问题</li><li>由OS保证它是原子操作</li><li>给定原值就保证了线程之间是没有冲突的</li><li>返回的是true或false</li></ul><p>CAS也是原子指令，由硬件支持的，和TAS相比，TAS是在单个内存word（或字节）上实现的</p><img src="compare and swap.png" style="zoom:150%;"><p>缺点：只会告诉你是否失败，但如果失败了的话就要继续自旋操作</p><p>hashtable插入值的时候可以这样做</p><br><br><br><h1 id="B-tree-latching"><a href="#B-tree-latching" class="headerlink" title="B+tree latching"></a>B+tree latching</h1><p>为何要研究b+ tree的并发：实现多线程的读写B+树</p><p>需求：</p><ul><li>要保护结点内部的数据，不能让多线程同时的修改数据</li><li>结点和结点之间会有合并的操作，page之间的合并，也不能让多线程同时去操作</li></ul><br><p>比如说要删除数据44，此时发现数据删除后需要合并页</p><p>而如果有人要查询41，去到原本41的位置的时候，发现没有（因为此时页数发生了合并，数据跑到另一页了）</p><p>这就造成了并发上的错乱</p><br><br><h2 id="Latch-crabbing-coupling"><a href="#Latch-crabbing-coupling" class="headerlink" title="Latch crabbing/coupling"></a>Latch crabbing/coupling</h2><p>螃蟹协议</p><br><p>具体步骤：</p><ul><li>先获取根节点的锁，如果发现数据在左子树，再把左子树结点的数据上锁</li><li>然后判断锁上了左子树后，根节点能不能解锁，如果能解锁就解锁</li><li>然后再从左子树找它的子树，依次循环这个流程</li></ul><br><p>能解锁的条件（safe node）</p><ul><li>当发生数据更新（或插入删除）的时候，不会造成节点的split（分裂）或merge（合并）</li></ul><br><p>find/insert/delete</p><ul><li><p>从根节点开始往下找，获取根结点的锁</p></li><li><p>再获取孩子结点的锁</p></li><li><p>然后判断孩子结点是不是一个安全的结点，如果不安全就不能放锁；安全的话就可以解锁</p></li></ul><br><p>思考：发现每次操作都要先锁根节点，导致根节点就变为了瓶颈</p><ul><li>这是一种悲观的思路</li><li>而绝大部分的操作其实是不会引起根节点的变化，所以不一定一上来就加锁</li></ul><br><br><h2 id="better-latching-algorithm"><a href="#better-latching-algorithm" class="headerlink" title="better latching algorithm"></a>better latching algorithm</h2><p>发现此前的的加锁方式，都是预先假设后续的操作会修改当前节点的数据，因此需要给数据加写锁</p><p>而这种思路是一种悲观的想法，这里提供一种乐观加锁的方式</p><ul><li><p>search过程不变，加的依然是读锁</p></li><li><p>insert/delete的时候，加的却是读锁（如果这里加了写锁，其他线程读写数据的时候就会阻塞）</p></li><li><p>一路读锁，发现子节点 not safe的时候，释放所有的锁，然后再从头给每一步加写锁</p></li></ul><br><p>不过这种方法也有缺点：比如说children结点会导致parent结点发生了修改，那么只能推导重来，从根节点重新给它加写锁</p><p>这种方案，本质上是认为绝大部分的操作是不会对上层的索引有修改</p><ul><li><p>即大部分的操作只会修改叶子结点，不会修改上层的结点</p></li><li><p>一旦发生了修改上层结点，就回滚</p></li></ul><br><br><p>不管悲观还是乐观的加锁方式，锁都是从头往尾加的</p><ul><li>所以说，如果你加锁的过程中，给children加锁的时候发现加不了锁，就只能等待锁被其他事务操作释放</li></ul><br><p>而B+树更加优秀的一方面，是它不仅可以支持从上往下的加锁，还支持横向的遍历加锁</p><br><br><br><h1 id="Leaf-node-scans"><a href="#Leaf-node-scans" class="headerlink" title="Leaf node scans"></a>Leaf node scans</h1><p>因为B+树是可以支持范围搜索的，那么在多线程加锁的过程中，就有可能造成死锁的情况</p><br><p>比如说有两个事务，事务一find keys &lt; 4，事务二find keys &gt; 1</p><img src="leaf node scan example.png" style="zoom:150%;"><p>那么事务一就直接找到4的位置，然后用下面的链表从右往左开始遍历，一边遍历一遍加读锁</p><p>而事务二就找到1的位置，然后从左往右的开始遍历，加读锁</p><p>这样就可能造成死锁的情况</p><br><br><p>再比如说有一个update keys &lt; 10，那么就可能会先锁住key为9的数据</p><p>那么就会出现，find keys &gt; 4 拿着key为5的锁，要争夺key为9的锁</p><p>update keys &lt; 10拿着key为9的锁，要争夺key为5的锁</p><p>由此引发死锁</p><br><p>B+树的latch天生不支持死锁检测</p><p>一个解决办法：<strong>只允许往一个方向操作</strong>，比如说只允许find keys &gt; 4这个方向（从左往右加锁），不能反方向查询</p><ul><li>类似哈希表一样，只能往同一个方向加锁</li></ul><p>但如果又想要倒序的遍历，一个解决办法就是倒序索引，就反方向的构建一遍索引</p><p>所以对于B+树的索引，要添加一些规则进去</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>让一个数据结构实现线程安全，是<strong>非常困难</strong>的</p><p>在B+树上用的技巧，也可以用在其他的数据结构上的，例如skip list</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Observation&quot;&gt;&lt;a href=&quot;#Observation&quot; class=&quot;headerlink&quot; title=&quot;Observation&quot;&gt;&lt;/a&gt;Observation&lt;/h1&gt;&lt;p&gt;前面的操作中，都假设只有一个线程去操作数据结构，但实际操作中是有多个
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 14-Query Planning Optimization Part II</title>
    <link href="https://dancsmshenry.github.io/2023/01/19/cmu-15-445-14-query-planning-optimization-part-ii/"/>
    <id>https://dancsmshenry.github.io/2023/01/19/cmu-15-445-14-query-planning-optimization-part-ii/</id>
    <published>2023-01-19T15:15:59.000Z</published>
    <updated>2024-09-17T06:10:19.552Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Backround"><a href="#Backround" class="headerlink" title="Backround"></a>Backround</h1><p>上节课说的是基于规则的优化器，而本节课要说的就是<strong>基于代价模型的优化器</strong></p><p>基于代价模型，估计每个计划的好坏</p><p>然后从众多执行计划中，选取一个性价比最高的执行计划</p><br><br><br><h1 id="Cost-model-components"><a href="#Cost-model-components" class="headerlink" title="Cost model components"></a>Cost model components</h1><p>代价估算的三个方向：</p><br><h2 id="Choice-1：Physical-costs"><a href="#Choice-1：Physical-costs" class="headerlink" title="Choice 1：Physical costs"></a>Choice 1：Physical costs</h2><p>物理代价（例如：需要多少CPU的计算，多少次IO，多少次miss cache，读取内存的开销，预取数据的开销）</p><p>极度依赖于硬件的性能（更换硬件环境，估算的代价标准都会有变动）</p><p>这种估值方案经常出现在数据库一体机上（例如：Oracle，因为硬件是不变的）</p><p>或者SQL Server上，主要是Windows对硬件的性能有较深的把控</p><p>一般是商用的会做的比较细，开源的一般不会</p><br><br><h2 id="Choice-2：Logical-costs"><a href="#Choice-2：Logical-costs" class="headerlink" title="Choice 2：Logical costs"></a>Choice 2：Logical costs</h2><p>逻辑开销，估算每个算子的开销</p><p>开销的计算和每个算子之间是独立的</p><p>需要数据的统计信息（比如分布之类的），以便知道算子处理多少数据，从而估计开销</p><br><br><h2 id="Choice-3：Algorithmic-costs"><a href="#Choice-3：Algorithmic-costs" class="headerlink" title="Choice 3：Algorithmic costs"></a>Choice 3：Algorithmic costs</h2><p>比较细的估计算子的开销，从算法的层次去估计开销</p><p>例如：join，具体分为几个步骤、每个步骤的时间复杂度是多少</p><br><br><br><h1 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h1><p>而上述的三个方面，则非常依赖于DBMS中数据的<strong>统计信息</strong></p><p>因为针对不同的算子，只有知道该算子需要处理多少条数据，才能够准确的算出它的开销是多少</p><br><p>不同数据库更新其统计信息的方法，是不同的：</p><img src="statistics.png" style="zoom:150%;"><br><br><h2 id="NR，V（A-R），SC（A-R）"><a href="#NR，V（A-R），SC（A-R）" class="headerlink" title="NR，V（A,R），SC（A,R）"></a>NR，V（A,R），SC（A,R）</h2><p>R：数据表的表名</p><p>A：数据表的某一列的列名</p><p>NR：当前的数据表中有多少条数据</p><p>V（A,R）：在当前数据表R的某一列A中，有多少个不同类型的值（比如性别一列，就只有男或女，这两种值）</p><p>SC（A,R）（全称：selection cardinality）：对于当前的选取方式，选取的基数是多少</p><ul><li><p>计算公式：NR/V（A,R）（计算的前提：是数据为平均、均匀分布的）</p></li><li><p>在当前的选取方法中，平均每次选取能够得到多少个值</p></li><li><p>对于这一列每一个单独的值，如果选取这个值，平均每次能获取到多少个值</p></li><li><p>比如在性别一列中，总共有50个男性和50个女性，那么此时选取出男性的基数就是50个</p></li></ul><br><br><h2 id="Logical-costs"><a href="#Logical-costs" class="headerlink" title="Logical costs"></a>Logical costs</h2><p>基于以下几种不同的情况，来分析SC（A,R）</p><br><p><strong>情况一</strong></p><p>针对数据表中的某一主键列，列上的数据都是唯一的</p><p>在这种情况下，选取基数（SC（A,R））要么是1（存在且只存在一个），要么是0（不存在）</p><img src="logical costs_01.png" style="zoom:150%;"><br><br><p><strong>情况二</strong></p><p>但如果是范围的选取，比如说要选取某一列中&lt;1000的数据，或是多谓词选取，那么这个时候就无法用SC（A,R）进行衡量</p><p>由此需要引入<strong>选择率</strong>的新概念</p><img src="logical costs_02.png" style="zoom:150%;"><br><br><br><h1 id="Complex-predicates"><a href="#Complex-predicates" class="headerlink" title="Complex predicates"></a>Complex predicates</h1><p>针对复合谓词的选择，提出新的概念：选择率</p><p><strong>选择率</strong>，对于当前的谓词，在总数据中能够选取出多少个数据，这个概率就是选择率</p><p>然后可以根据每个谓词的选择率，计算当前这种方案下总体的选择率</p><br><p>以下的例子都假设总共有五个数据，分别是0、1、2、3、4</p><p>并且，都假设数据是均匀分布的</p><br><br><h2 id="Equality-predicates"><a href="#Equality-predicates" class="headerlink" title="Equality predicates"></a>Equality predicates</h2><p>针对相等谓词，此时的计算公式是SC（P）/NR</p><ul><li>针对当前给定的谓词组合P，在当前数据表中平均能够找到SC（P）个</li><li>而总共有NR个数据，因此相等谓词的选择率便是SC（P）/NR</li></ul><img src="equality predicate.png" style="zoom:150%;"><br><br><h2 id="Range-predicates"><a href="#Range-predicates" class="headerlink" title="Range predicates"></a>Range predicates</h2><p>范围谓词的查找</p><p>PS：下图中Amax是指当前列数据中的最大值，Amin是当前列数据中的最小值</p><img src="range predicate.png" style="zoom:150%;"><br><br><h2 id="Negation-query"><a href="#Negation-query" class="headerlink" title="Negation query"></a>Negation query</h2><p>不等于谓词的查询</p><img src="negation query.png" style="zoom:150%;"><br><br><h2 id="Conjunction"><a href="#Conjunction" class="headerlink" title="Conjunction"></a>Conjunction</h2><p>这里，可以将数据的选择率和概率作为替换</p><p>因此。针对多谓词并联（<strong>求并集</strong>）的复合查询，就可以用概率的相乘获得选择率（因为二者的概率是互不干扰，独立的）</p><p>PS：使用这种计算方法的前提：两个查询谓词之间，是互不干扰，相互独立的</p><img src="conjunction.png" style="zoom:150%;"><br><br><h2 id="Disjunction"><a href="#Disjunction" class="headerlink" title="Disjunction"></a>Disjunction</h2><p>而如果是要求谓词筛选后的并集，可以参考离散数学的做法</p><p>PS：使用这种计算方法的前提：两个查询谓词之间，是互不干扰，相互独立的</p><img src="disjunction.png" style="zoom:150%;"><br><br><br><h1 id="Result-size-estimation-for-joins"><a href="#Result-size-estimation-for-joins" class="headerlink" title="Result size estimation for joins"></a>Result size estimation for joins</h1><p>前面说的主要是基于谓词的查询，而如果涉及到两个表的join，情况会更加麻烦</p><p>比如说，我们很难知道两个表join后得到的数据有多大</p><ul><li>因为可能没有（join后发现数据都不匹配）、可能很小、也可能很大、无法估计大小</li></ul><br><p>因此，为了研究这个问题，假设内表中所有的数据都能够和外表进行匹配</p><p>为了两个表join后得到的数据量是多少，给出以下的计算模型：</p><p>NR是指R表的数据量</p><p>NS/V（A,S）其实就是SC（A,S），即针对每个取值，平均能够给出多少个数据</p><p>二者相乘，就代表对于NR来说，每个数据都能在S表中匹配上，而每个匹配上的数据，在S表中有SC（A,S）条</p><p>二者相乘之后，得到的结果就是两表join后的总结果的数量</p><br><p>而，因为join是符合交换律的，所以可以交换两边表的位置，因此在选取最终在选取结果的时候</p><p>往往是选择总开销较小的那个，也就是被除数较大的那个</p><img src="result size estimation for joins.png" style="zoom:150%;"><br><br><br><h1 id="Selection-cardinality"><a href="#Selection-cardinality" class="headerlink" title="Selection cardinality"></a>Selection cardinality</h1><p>此前的推断过程，都是基于以下假设进行推断的：</p><br><h2 id="Assumption-01-uniform-data"><a href="#Assumption-01-uniform-data" class="headerlink" title="Assumption 01:uniform data"></a>Assumption 01:uniform data</h2><p>假设数据的分布都是<strong>均匀</strong>的</p><br><br><h2 id="Assumption-02-independent-predicates"><a href="#Assumption-02-independent-predicates" class="headerlink" title="Assumption 02:independent predicates"></a>Assumption 02:independent predicates</h2><p>假设在查询的过程中，每个谓词的查询之间，是<strong>相互独立</strong>的</p><ul><li>因此此前在并联谓词查询的时候，可以简单的用概率相乘得到结果</li></ul><br><br><h2 id="Assumption-03-inclusion-principle"><a href="#Assumption-03-inclusion-principle" class="headerlink" title="Assumption 03:inclusion principle"></a>Assumption 03:inclusion principle</h2><p>此前在join中的假设，假设A表中的每个数据都能够在B表中找到</p><br><br><br><h1 id="Correlated-attributes"><a href="#Correlated-attributes" class="headerlink" title="Correlated attributes"></a>Correlated attributes</h1><p>实际上，此前做出的很多分析都是基于上述三个假设</p><p>而如果没有三个假设，在估算代价上，就会有很多出入</p><br><img src="correlated attributes.png" style="zoom:150%;"><p>比如这里，针对makes和models两条列，希望找到make=“honda”和model=“accord”的数据</p><p>如果基于此前的三个假设，那么1/10 * 1/100 = 0.001即答案</p><p>而只要稍微对数据加以了解，就会发现，model=“accord”的，就只能是make=“honda”的</p><p>也就是说这二者，是一一对应的关系</p><p>那么实际上的概率应该就是1/100 = 0.01</p><p>也就是此时的推断出现了问题（问题出在，两个谓词的查询之间，从数据的角度来说是不独立的）</p><br><br><p>因此，需要一些其他的方式，在不遵守上述三个假设的情况下，对数据进行预估</p><br><br><h2 id="Cost-estimations"><a href="#Cost-estimations" class="headerlink" title="Cost estimations"></a>Cost estimations</h2><p>基于数据不均衡的情况，需要新的方法或是指标，来衡量当数据不均衡的情况</p><br><p>最开始的思路，最简单粗暴的想法，在统计信息中，对于一列的数据，记录不同种类的数据的具体情况</p><img src="non-uniform approximation.png" style="zoom:150%;"><br><p>但是，这种方法的问题是，可能会花费大量的空间来存储数据</p><p>因此需要对统计信息的存储进行优化，即用<strong>直方图</strong>来存储数据信息</p><br><br><h3 id="Equi-width-histogram"><a href="#Equi-width-histogram" class="headerlink" title="Equi-width histogram"></a>Equi-width histogram</h3><p><strong>等宽直方图</strong>，把相等宽度的值域打包成一块（比如说每三个坐标列打包在一起）</p><p>这样记录的就不是每一块的数据量，而是以bucket为单位的记录一个范围内的数据量</p><br><p>但是，这种等宽直方图的缺点就是，信息丢失率比较高</p><ul><li>比如说10、11、12这一块，当数据进行打包处理以后，可能总值很高，但11的位置其实只有少量的数据</li><li>而当使用这种方法的时候，很可能会误判在11的位置上有大量的数据</li><li>也就是说，在块内的数据范围会因此被掩盖，从而造成误差</li><li>因此需要引入<strong>等高直方图</strong></li></ul><img src="equi-width histogram.png" style="zoom:150%;"><br><img src="equi-width histogram_01.png" style="zoom:150%;"><br><br><h3 id="Equi-depth-histogram"><a href="#Equi-depth-histogram" class="headerlink" title="Equi-depth histogram"></a>Equi-depth histogram</h3><p>要求每个bucket里面的数据总量是相同的</p><ul><li>比如说要求每个bucket里面要有15个数据，那么第一个bucket可能包含1-5的数据，第二个bucket包含6-8的数据</li></ul><img src="equi-depth histogram.png" style="zoom: 150%;"><br><p>一方面，可以节约内存；另一方面，可以解决数据缺失、数据误差的问题，从而提高精确度</p><img src="equi-depth histogram_01.png" style="zoom:150%;"><br><br><h2 id="Sketches"><a href="#Sketches" class="headerlink" title="Sketches"></a>Sketches</h2><p>并不记录该数据是否存在，而是从概率的角度来估计该数据是否出现以及出现的数量</p><ul><li>即，从概率的角度来分析数据出现的数量以及概率</li></ul><p>主要有以下两个方法：</p><img src="sketches.png" style="zoom:150%;"><p>PS：Redis使用的是hyperloglog（记录当前数据的hash值中第一个1的位置，通过这种方式来记录数据在数据表中有多少个）</p><br><br><h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>另一种思路：<strong>采样</strong></p><p>主要思路就是，先从原有的数据表中采样一部分数据出来（简称为小标），然后将选出来的执行计划在这个小表里面执行一遍</p><p>从而推断该执行计划，在原有的大表里面可能会执行多久</p><p>优点：是基于真实的数据进行估计的，不会有太大偏差</p><img src="sampling.png" style="zoom:150%;"><br><p>缺点：</p><ul><li>不光要维护原有的数据表，还要额外的空间来维护小表</li><li>如果采样得到的数据被删除了，那么小表还需要维护数据</li><li>同一条SQL需要在大表和小表上同时执行，浪费资源</li></ul><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>有了直方图，概率统计以及采样估算等方法，便可以轻松的估计数据的分布，从而了解谓词的实际代价消耗</p><p>而在了解了执行计划的具体代价之后，那么就需要列举不同的执行计划，估算不同执行计划的消耗，从而选出最优的方案</p><br><br><br><h1 id="Query-optimization"><a href="#Query-optimization" class="headerlink" title="Query optimization"></a>Query optimization</h1><p>对于一些只涉及一个表的查询，只需要基于规则的启发手段便可以实现</p><p>而针对多表查询，涉及查询循环的嵌套，是基于规则的优化器无法实现的</p><br><br><h2 id="Single-relation-query-planning"><a href="#Single-relation-query-planning" class="headerlink" title="Single-relation query planning"></a>Single-relation query planning</h2><p>针对单表的查询，可以直接根据基于规则的去选取最优的方案</p><p>比如说数据表的扫描，是选择顺序的读取数据页，还是二分查找，还是走索引（可以直接写一些规则，有索引走索引，没索引就二分）</p><p>这种简单的启发式的方案，对于大多数的OLTP的业务，都是比较适用的</p><ul><li>在单表的查询中，可以无视基于代价开销的优化，有索引就走索引就行了</li></ul><br><br><h2 id="OLTP-query-planning"><a href="#OLTP-query-planning" class="headerlink" title="OLTP query planning"></a>OLTP query planning</h2><p>在OLTP的查询优化中：</p><ul><li>使用启发式的手段，选择一个最佳的索引就好了</li><li>在join的操作过程中，往往只需要从A表中获取少量数据，然后把数据连接到B表中就可以了</li></ul><img src="OLTP query planning.png" style="zoom:150%;"><br><br><h2 id="Multi-relation-query-planning"><a href="#Multi-relation-query-planning" class="headerlink" title="Multi-relation query planning"></a>Multi-relation query planning</h2><p>多表连表查询</p><ul><li>join是符合交换律和结合律的，因此如果有多个表进行join，那么就会有很多种不同的执行计划</li><li>也就是有很多的计划排列组合，那么就需要对其进行剪枝</li></ul><br><p>此前的System R只研究left-deep tree，即只研究左深树</p><ul><li>join的左子树可以是表，也可以是join</li><li>但，join的右子树必须是一个表</li></ul><p>并且，这种左深树还有优点，能够很好的适应执行模型中的火山模型</p><ul><li>A表和B表join完了以后，可以向上吐出一条数据，这条数据再和C表进行join，又可以向上吐出一条数据（而其他不是左深树的情况，则需要用额外的空间存储中间结果）</li><li>也就是可以将模型做成流式模型，极大的降低结果集的大小</li></ul><img src="left-deepth tree.png" style="zoom:150%;"><br><br><p>然后，需要做一些计划列举的方式：</p><p>比如说通过排列组合，比较不同的左深树的方案</p><p>或者说，比较不同的算子实现方式（hash join，nested loop join等）</p><p>再或者说读取数据的方式，比如说是全表扫描，还是索引扫描</p><p>而，如何列举出这些方案的优劣，一般使用的是动态规划的算法来实现的</p><img src="multi-relation query planning.png" style="zoom:150%;"><br><br><h3 id="Dynamic-programming"><a href="#Dynamic-programming" class="headerlink" title="Dynamic programming"></a>Dynamic programming</h3><p>在join中，不同的join方案，对应的开销是不一样的</p><p>如果需要找到最佳的方案，常用的方法便是动态规划算法</p><br><p>比如这里有两种不同的join方案，而每个方案，又分为hash join和sortmerge join两种方法</p><p>如果使用动态规划算法，那么就需要两种方法都走一遍，最后得到的结果进行比较</p><p>而在每种方法内部，每次都是“贪心算法”，取最小开销的那个方法</p><img src="dynamic programming_01.png" style="zoom:150%;"><img src="dynamic programming_02.png" style="zoom:150%;"><img src="dynamic programming_03.png" style="zoom:150%;"><br><br><br><h2 id="Candidate-plan-example"><a href="#Candidate-plan-example" class="headerlink" title="Candidate plan example"></a>Candidate plan example</h2><p>举例说明如何对不同的执行计划进行剪枝比较</p><h3 id="Step-1-Enumerate-relation-orderings"><a href="#Step-1-Enumerate-relation-orderings" class="headerlink" title="Step 1: Enumerate relation orderings"></a>Step 1: Enumerate relation orderings</h3><p>排列组合出多个不同的左深树</p><img src="candidate plans_01.png" style="zoom:150%;"><br><h3 id="Step-2-Enumerate-join-algorithm-choices"><a href="#Step-2-Enumerate-join-algorithm-choices" class="headerlink" title="Step 2: Enumerate join algorithm choices"></a>Step 2: Enumerate join algorithm choices</h3><p>列举算子join不同的实现方案</p><img src="candidate plans_02.png" style="zoom:150%;"><br><h3 id="Step-3-Enumerate-access-method-choices"><a href="#Step-3-Enumerate-access-method-choices" class="headerlink" title="Step 3: Enumerate access method choices"></a>Step 3: Enumerate access method choices</h3><p>再列举不同的读表方式（顺序读表还是索引读表）</p><img src="candidate plans_03.png" style="zoom:150%;"><br><p>最后，再列举所有方案的开销，选出开销最小的方案</p><br><br><h2 id="Postgres-optimizer"><a href="#Postgres-optimizer" class="headerlink" title="Postgres optimizer"></a>Postgres optimizer</h2><p>在PG里面的优化是如何实现的：</p><ul><li>不仅有左深树，还有右深树，以及二者混合的类型</li><li>在评估方案的好坏上有两种实现方法：动态规划（如果连表的数量小于12就用DP）和基因遗传算法（如果连表的数量大于12就用GEQO）</li></ul><br><br><p>PG中的遗传算法的主要思路：</p><ul><li><p>先预设几个组合方案</p></li><li><p>删除此时效果最差的方案</p></li><li><p>然后将当前最好的方案分裂（变异）出一个新的方案（繁衍）</p></li><li><p>接着不断地轮询上面的两个步骤，直到轮询次数达到上限</p></li></ul><img src="postgres genetic optimizer.png" style="zoom:150%;"><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>在看了那么多的基于开销的优化模型，一个非常重要的思路便是：尽早的将数据过滤</p><ul><li>数据过滤的越早，后续在算子之间传输的数据就越少，开销也就越少</li></ul><br><p>一些选择率的估计指标</p><ul><li>数据在均匀的情况下</li><li>每个查询谓词相互独立的情况下</li><li>join存在结果的情况下</li><li>如果数据不均匀，就需要直方图来解决</li><li>有两个表在数据内容上是高度相关的，那么就有一些数据库可以将这两个表关联起来，在计算它们的统计信息</li></ul><br><p>动态规划依然是，在做join操作中比较不同join花费时，选取最优策略的最佳手段</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Backround&quot;&gt;&lt;a href=&quot;#Backround&quot; class=&quot;headerlink&quot; title=&quot;Backround&quot;&gt;&lt;/a&gt;Backround&lt;/h1&gt;&lt;p&gt;上节课说的是基于规则的优化器，而本节课要说的就是&lt;strong&gt;基于代价模型的优化器
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 13-Query Planning Optimization Part I</title>
    <link href="https://dancsmshenry.github.io/2023/01/19/cmu-15-445-13-query-planning-optimization-part-i/"/>
    <id>https://dancsmshenry.github.io/2023/01/19/cmu-15-445-13-query-planning-optimization-part-i/</id>
    <published>2023-01-19T15:15:28.000Z</published>
    <updated>2024-09-17T06:10:19.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Query-optimization"><a href="#Query-optimization" class="headerlink" title="Query optimization"></a>Query optimization</h1><p>为什么会有优化器的存在？</p><ul><li><p>SQL是声明式的，它只说明了需要的数据（答案）是什么，但没有说明要以什么方式去获取数据</p></li><li><p>因此DBMS可以对语句进行优化，从而以最小的成本获取相同的数据</p></li><li><p>因此有了众多SQL优化器</p></li></ul><br><br><h2 id="IBM-System-R"><a href="#IBM-System-R" class="headerlink" title="IBM System R"></a>IBM System R</h2><p>从IBM SYSTEM R，就开始了优化器的历程</p><br><p>一个争论：人为制定的执行计划和机器做出的执行计划，哪个效率会高？</p><p>因此DBMS在<strong>执行</strong>上，有以下两个流派：</p><ul><li>一个是SQL为代表的，机器对语句进行优化</li><li>另一个是类似flink（虽然有插件，可以直接写SQL），但是flink是要用户直接写具体语句的执行计划，流式处理系统</li></ul><br><p>而DBMS对SQL进行优化，又有以下两个方向：</p><br><br><h2 id="Heuristice-rules"><a href="#Heuristice-rules" class="headerlink" title="Heuristice/rules"></a>Heuristice/rules</h2><p>基于规则（启发式）的查询模型</p><p>基于一些规则或者变化的手段，用来优化用户SQL中比较低效的部分</p><ul><li>规定一些查询优化的trick，将语句等效的替换或变换，然后获取高效的性能</li></ul><p>重写SQL查询，去掉一些stupid或inefficient的查询</p><p>需要查询catalog（元数据），需要看一下数据库表行列的情况</p><ul><li>但是不需要数据的具体情况，即发现数据库有索引就直接走索引，不用关心数据的分布以及直方图等信息</li></ul><br><br><h2 id="Cost-based-search"><a href="#Cost-based-search" class="headerlink" title="Cost-based search"></a>Cost-based search</h2><p>基于代价的查询模型</p><p>需要构建代价模型，再判断不同的执行计划的开销是多少，从而选出最优的执行计划</p><p>因此，需要知道具体数据的分布（需要知道算子要处理多少数据，才能够知道代价是多少）</p><br><br><p>本节主要研究的是<strong>基于规则的查询模型</strong></p><br><br><br><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><img src="architecture overview.png" style="zoom:150%;"><br><br><h2 id="SQL-rewriter"><a href="#SQL-rewriter" class="headerlink" title="SQL rewriter"></a>SQL rewriter</h2><p>对SQL语句进行一些预处理，在SQL的文本级别上做一些简单的优化</p><br><br><h2 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h2><p>将SQL语句转化为抽象语法树（abstract syntax tree）</p><br><br><h2 id="Binder"><a href="#Binder" class="headerlink" title="Binder"></a>Binder</h2><p>语法树会涉及表的名称，列的名称；而这些数据和DBMS里面的名称一般是不一样的</p><ul><li>所以需要将SQL中数据表的id、列id，绑定（bind）到system catalog中数据表的id、列id</li><li>如果表或列不存在，就会报错</li></ul><br><br><h2 id="Tree-rewriter"><a href="#Tree-rewriter" class="headerlink" title="Tree rewriter"></a>Tree rewriter</h2><p>把上面的抽象语法树转化成一个优化器可以工作的最原始的逻辑结构（又名<strong>正则化</strong>）</p><p>生成一个最原始的查询逻辑计划（logical plan）</p><br><br><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><p>接着生成optimizer（这是一个未优化的查询逻辑）</p><ul><li>如果是启发式优化的，ruled based search，也叫做基于规则的查询，会查询一些系统的源数据，对查询进行优化</li><li>如果是代价式优化的，cost model，不光会查询系统的原数据，还是查询代价模型（比如说DBMS规定的一些代价模型）</li></ul><br><p>最后会生成一个物理的查询计划physical plan，里面都是真正需要执行的算子</p><br><br><br><h1 id="Logical-vs-physical-phans"><a href="#Logical-vs-physical-phans" class="headerlink" title="Logical vs physical phans"></a>Logical vs physical phans</h1><p>逻辑计划：关系代数级别的（join）</p><p>物理计划：怎么执行这个join（比如说怎么执行join，是用hash join，还是nested loop join）</p><br><p>在优化器中，逻辑计划和物理计划的算子都是由对应关系的</p><p>物理计划会制定一个具体的执行方式，是走索引还是走扫描</p><ul><li>会根据具体的物理情况，决定使用哪些物理算子</li><li>物理算子和逻辑算子不一定是一对一的关系，一个逻辑算子可能会对应多个物理算子</li></ul><br><br><br><h1 id="Query-optimization-is-NP-hard"><a href="#Query-optimization-is-NP-hard" class="headerlink" title="Query optimization is NP-hard"></a>Query optimization is NP-hard</h1><p>优化器对查询的优化是一个很难的问题，以至于不知道是否有一个最优的结果存在，也就是NP问题</p><br><p>一种思路是，用Machine Learning对优化器进行优化，比如DB2就用了人工智能优化器</p><p>但是缺点是类似黑盒，即查询器的输出很难make sense，就人工智能也不知道为什么要选择这个方式</p><p>PS：近年又开始研究<del>火</del>起来了</p><br><p>而另一种思路是，辅助优化器对语句进行优化，即对于优化器给出的执行计划，提出建议</p><p>最后优化器自己综合做出决定</p><br><br><br><h1 id="Relational-algebra-equivalences"><a href="#Relational-algebra-equivalences" class="headerlink" title="Relational algebra equivalences"></a>Relational algebra equivalences</h1><p>关系代数的等价</p><ul><li>如果两个关系表达式是等价的话，就表明二者输出的结果集是一样的；反之也是一样的</li></ul><p>DBMS可以利用关系代数，从逻辑上判断两个执行计划是否是等价的，而不需要代价模型</p><p>同时，利用关系代数也可以实现SQL的重写</p><br><br><p>通过逻辑谓词的下推，实现了两个关系表达式的等效</p><img src="predicate pushdown.png" style="zoom:150%;"><br><br><p>将谓词进行分割</p><img src="relational algebra equivalences.png" style="zoom:150%;"><br><br><p>join的交换律</p><p>如果有n个表进行join，那么就有4^n种执行方法</p><img src="join的交换律.png" style="zoom:150%;"><br><br><p>早晚物化的问题</p><ul><li><p>一方面，可以将不需要的数据舍弃掉，减少传输的数据量</p></li><li><p>另一方面，可以选择在join的时候就物化数据，或者最后再回表一次得到数据</p></li></ul><p>但是这对于一个列存的数据库来说是无用的，因为它始终是最后才物化的</p><br><br><br><h1 id="Logical-query-optimization"><a href="#Logical-query-optimization" class="headerlink" title="Logical query optimization"></a>Logical query optimization</h1><p>逻辑计划上的优化，需要先写一些规则，再让数据库去匹配（类似模式匹配）</p><br><p>缺点：无法比较计划和计划之间的好坏</p><ul><li><p>这种方法不能自适应的评价计划和计划之间的好坏</p></li><li><p>选择方法一而不选择方法二的原因只能是因为你给的规则是这样写的，因为它没有代价模型，不能自己去判断</p></li></ul><br><br><h2 id="Split-conjunctive-predicates"><a href="#Split-conjunctive-predicates" class="headerlink" title="Split conjunctive predicates"></a>Split conjunctive predicates</h2><p>将语句中的连接谓词分开</p><p>比如下图，将语句中用and连接的一串谓词分开</p><img src="split conjunctive predicates.png" style="zoom:150%;"><br><br><h2 id="Predicate-pushdown"><a href="#Predicate-pushdown" class="headerlink" title="Predicate pushdown"></a>Predicate pushdown</h2><p>谓词下推，谓词的执行越接近读表越好（可以提前过滤掉大量的无用数据）</p><img src="predicate pushdown_01.png" style="zoom:150%;"><br><br><h2 id="Replace-cartesian-products"><a href="#Replace-cartesian-products" class="headerlink" title="Replace cartesian products"></a>Replace cartesian products</h2><p>把笛卡尔积转换为join</p><p>两个表连表后（即笛卡尔积）再用条件判断，就相当于一个join了，所以就可以把笛卡尔积变为join</p><img src="replace cartesian products with joins.png" style="zoom:150%;"><br><br><h2 id="Projection-pushdown"><a href="#Projection-pushdown" class="headerlink" title="Projection pushdown"></a>Projection pushdown</h2><p>投影下推，发现很多时候我们只需要部分列的数据，整行的记录没必要全部往上传，所以就只传递部分数据即可</p><img src="projection pushdown.png" style="zoom:150%;"><br><br><br><h1 id="Nested-sub-queries"><a href="#Nested-sub-queries" class="headerlink" title="Nested sub-queries"></a>Nested sub-queries</h1><p>针对嵌套的子查询，有两个优化的方向：</p><ul><li>重写（Rewrite）：将里面和外面的查询重写成一个新的查询</li><li>解耦查询（Decompose）：不要让子查询一直阻塞在主查询里面（把它单独拿出来，提前执行）</li></ul><br><br><h2 id="Rewrite"><a href="#Rewrite" class="headerlink" title="Rewrite"></a>Rewrite</h2><p>发现可以用连表的方式来重写嵌套查询</p><p>比如下图，将两条查询SQL，优化为一条查询SQL</p><img src="rewrite.png" style="zoom:150%;"><br><br><h2 id="Decompose"><a href="#Decompose" class="headerlink" title="Decompose"></a>Decompose</h2><p>可以预先执行一些查询语句，使得主查询不必一直阻塞在子查询上</p><ul><li>如果不预先处理这个子查询的话，每拿一条记录都要再执行一遍这个子查询（浪费资源）</li></ul><br><p>即，可以先把子查询做了，然后把结果放到单独的一个表里面（作为子查询的结果）</p><p>需要子查询语句的结果时，直接去里面读取即可</p><br><img src="decompose.png" style="zoom:150%;"><p>比如上面的SQL，发现<code>SELECT MAX(S2.rating) FROM sailors S2</code>的结果是一个不变的量</p><p>因此可以先执行该子查询，得到并储存结果，方便后续读取</p><p>而不是每次读取到这条语句的时候，都重复执行</p><img src="decomposing queries.png" style="zoom:150%;"><br><br><br><h1 id="Expression-rewriting"><a href="#Expression-rewriting" class="headerlink" title="Expression rewriting"></a>Expression rewriting</h1><p>对谓词表达式进行重写 ，让谓词本身变得更高效</p><p>可以给DBMS写入一些规则，然后让DBMS去SQL中查找符合规则的部分进行rewrite（类似模式匹配）</p><br><br><h2 id="Impossible-unnecessary-predicates"><a href="#Impossible-unnecessary-predicates" class="headerlink" title="Impossible/unnecessary predicates"></a>Impossible/unnecessary predicates</h2><p>对于一些比较绝对的逻辑，可以直接优化</p><p>比如下图，1必然是不等于0的，所以这里可以直接优化为false，输出空结果即可</p><img src="impossible predicates.png" style="zoom:150%;"><br><br><h2 id="Join-elimination"><a href="#Join-elimination" class="headerlink" title="Join elimination"></a>Join elimination</h2><p>对于一些语句可以直接得到结果的，可以直接优化</p><p>比如下图，相当于自己和自己连表，然后查询的又是自己的全部数据</p><p>因此可以修改为为<code>SELECT * FROM A;</code></p><img src="join elimination.png" style="zoom:150%;"><br><br><h2 id="Join-elimination-with-sub-query"><a href="#Join-elimination-with-sub-query" class="headerlink" title="Join elimination with sub-query"></a>Join elimination with sub-query</h2><p>发现当前查询以及子查询在联表查询时，连接的都是同一张表</p><img src="join elimination with sub-query_01.png" style="zoom:150%;"><br><p>那么就可以改写为以下SQL</p><img src="join elimination with sub-query_02.png" style="zoom:150%;"><br><br><h2 id="Merge-predicates"><a href="#Merge-predicates" class="headerlink" title="Merge predicates"></a>Merge predicates</h2><p>将谓词进行合并</p><img src="merge predicate_01.png" style="zoom:150%;"><p>可以将谓词里面的数据范围进行合并</p><img src="merge predicate_02.png" style="zoom:150%;"><br><br><br><h1 id="Cost-model"><a href="#Cost-model" class="headerlink" title="Cost model"></a>Cost model</h1><br><h2 id="Cost-based-query-planning"><a href="#Cost-based-query-planning" class="headerlink" title="Cost-based query planning"></a>Cost-based query planning</h2><p>此前讨论的都是基于规则的优化（启发式），而后续则需要讨论基于开销的优化</p><p>基于开销的优化，需要根据数据库数据的具体分布等情况</p><p>对执行计划的花费开销进行比对，从而选出一个当前最优的方案</p><br><p>但是，这里对执行计划开销的估计，换一个数据库（或是机器硬件）就不适用了</p><ul><li>比如说某个SQL的查询，在MySQL中执行是2W，在PG中执行是20W，这二者是没有任何比较性的</li><li>因为每个数据库对于查询复杂度的衡量，都是基于本身的体系衡量出来的，二者不能在不同的标准上进行比较</li></ul><br><p>PS：估算SQL执行的开销，和计划列举的步骤是分开的</p><img src="query optimization.png" style="zoom: 150%;"><br><br><h2 id="Cost-model-components"><a href="#Cost-model-components" class="headerlink" title="Cost model components"></a>Cost model components</h2><p>代价估算的三个方向：</p><br><p><strong>Choice 1：Physical costs</strong></p><p>物理代价（例如：需要多少CPU的计算，多少次IO，多少次miss cache，读取内存的开销，预取数据的开销）</p><p>极度依赖于硬件的性能（换一个硬件环境，估算的代价都会有变动）</p><p>这种估值方案经常出现在数据库一体机上（例如：Oracle，因为硬件是不变的）</p><p>或者SQL Server上，主要是Windows对硬件的性能有较深的把控</p><p>一般是商用的会做的比较细，开源的一般不会</p><br><p><strong>Choice 2：Logical costs</strong></p><p>逻辑开销，估算每个算子的开销</p><p>开销的计算和每个算子之间是独立的</p><p>需要数据的统计信息（比如分布之类的），以便知道算子处理多少数据，从而估计开销</p><br><p><strong>Choice 3：Algorithmic costs</strong></p><p>比较细的估计算子的开销，从算法的层次去估计开销</p><p>例如：join，具体分为几个步骤、每个步骤的时间复杂度是多少</p><br><br><h2 id="Disk-based-dbms-cost-model"><a href="#Disk-based-dbms-cost-model" class="headerlink" title="Disk-based dbms cost model"></a>Disk-based dbms cost model</h2><p>因为目前主要研究的是基于磁盘的DBMS，所以相比CPU的开销，磁盘IO的开销更大，更值得关注</p><ul><li>CPU的开销几乎可以忽略</li><li>必须考虑随机IO和顺序IO（尽量将随机IO改为顺序IO）</li></ul><p>同时，DBMS是完全控制了磁盘文件页的读取，所以可以在更细的粒度上管理磁盘页</p><br><br><h2 id="Postgres-costs-model"><a href="#Postgres-costs-model" class="headerlink" title="Postgres costs model"></a>Postgres costs model</h2><p>PostgreSQL的代价估算模型</p><p>用<strong>魔法数</strong>将磁盘IO的开销和CPU计算的开销联系在一起</p><p>魔法数：用数个系数和某种算法，建立数据之间的关系（一般是写死的；根据经验得出来的）</p><p>比如说从硬盘中取数据，比从内存中取数据慢了400倍；顺序IO比随机IO快4倍</p><p>并且，DBMS中很多算法都是基于这个魔法数的，不能随意修改</p><br><br><h2 id="IBM-db2-cost-model"><a href="#IBM-db2-cost-model" class="headerlink" title="IBM db2 cost model"></a>IBM db2 cost model</h2><p>与开销有关的几个因素：</p><ul><li>系统本身的数据</li><li>硬件配置</li><li>存储器类型</li><li>通信的带宽（是单机还是分布式部署）</li><li>内存（缓存池）</li><li>并发环境（并发数量、隔离级别、锁的情况）</li></ul><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>基于规则（启发式）的优化器，基于给定的规则去优化一个执行计划</p><ul><li>数据的分布以及其他情况，是不需要了解的</li><li>只需要根据规则进行替换</li></ul><br><p>而基于代价的优化器，需要知道数据的统计信息，比前者更加先进，更容易得到最优的执行计划</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Query-optimization&quot;&gt;&lt;a href=&quot;#Query-optimization&quot; class=&quot;headerlink&quot; title=&quot;Query optimization&quot;&gt;&lt;/a&gt;Query optimization&lt;/h1&gt;&lt;p&gt;为什么会有优
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 12-Query Execution Part II</title>
    <link href="https://dancsmshenry.github.io/2022/12/29/cmu-15-445-12-query-execution-part-ii/"/>
    <id>https://dancsmshenry.github.io/2022/12/29/cmu-15-445-12-query-execution-part-ii/</id>
    <published>2022-12-29T13:53:43.000Z</published>
    <updated>2024-09-17T06:10:19.543Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Why-care-about-parallel-execution"><a href="#Why-care-about-parallel-execution" class="headerlink" title="Why care about parallel execution"></a>Why care about parallel execution</h1><p>上节课讨论的都是单个SQL语句是如何执行的，但是实际上我们很多时候都是多线程执行SQL语句</p><br><p>为什么要多线程并发执行</p><ul><li><p>从单条语句看，能够提高响应时间（单独运行的情况下需要运行5s，而多线程的情况下只需要运行0.5s）</p></li><li><p>从多条语句看，能够提高吞吐量（单位时间能够处理多少条语句）</p></li><li><p>能够提高应用的响应性和可用性（底层运行的越快，越能提高上层的可用性）</p></li><li><p>降低开销（提高效率，能够使用更少的时间、更少的电费去实现功能）</p></li></ul><br><br><br><h1 id="Parallel-vs-Distributed"><a href="#Parallel-vs-Distributed" class="headerlink" title="Parallel vs Distributed"></a>Parallel vs Distributed</h1><p>并行数据库</p><ul><li>所有的资源、线程都是在同一个机器上</li><li>并行数据库资源之间的通信是高速的（比如说通过共享内存）</li><li>并行数据库之间线程的通信都是简易和可靠的</li></ul><br><p>分布式数据库</p><ul><li>节点之间的物理距离可能非常遥远</li><li>分布式数据库的通信是非常慢的（需要互联网）</li><li>分布式数据库之间的通信以及相关问题是无法被忽略的</li></ul><br><br><br><h1 id="Process-models"><a href="#Process-models" class="headerlink" title="Process models"></a>Process models</h1><p>研究多个用户的SQL是如何并发执行的，即研究线程模型</p><p>可以将SQL中的操作拆解为不同的算子，每个算子则可以抽象为worker，分配给不同的对象执行</p><br><br><h2 id="Process-per-DBMS-Worker"><a href="#Process-per-DBMS-Worker" class="headerlink" title="Process per DBMS Worker"></a>Process per DBMS Worker</h2><p>每一个worker分配一个进程去做（进程的调度是依赖于操作系统的）</p><br><p>进程间使用shared memory通信</p><br><p>优点：一个进程的崩溃不会影响其他的进程</p><p>缺点：如果并发量非常大的话，创建过多的进程会极度的浪费资源</p><p>应用：DB2，Oracle，Postgresql</p><br><p>当SQL语句到来的时候，会被dispatcher分配worker去执行语句，worker执行完后就将数据返还给DBMS</p><img src="process per DBMS Worker.png" style="zoom:150%;"><br><br><h2 id="Process-pool"><a href="#Process-pool" class="headerlink" title="Process pool"></a>Process pool</h2><p>背景：因为多进程会浪费资源，所以想到了复用进程，进而提出进程池</p><p>其中dispatcher不再是直接创造出进程，而是从进程池里面找到可用的进程给SQL去执行，用完后再返回进程池</p><p>应用：DB2，postgresql</p><img src="process pool.png" style="zoom:150%;"><br><br><h2 id="Thread-per-DBMS-Worker"><a href="#Thread-per-DBMS-Worker" class="headerlink" title="Thread per DBMS Worker"></a>Thread per DBMS Worker</h2><p>背景：由于进程的切换代价高，进程本身占用过多资源，因此引入pthread线程（并且pthread天生就能够相互通信）</p><p>每个worker都分配一个线程</p><p>线程之间的调度是由DBMS调度（有点类似用户态线程）</p><p>dispatcher的数量不定，一个或者多个</p><br><p>优点：线程的切换代价上是小于进程的切换的；线程天生支持共享内存通信</p><p>缺点：一个线程的崩溃会导致整个进程崩溃（稳定性差）</p><p>应用：DB2，Oracle，SQL Server，MySQL</p><img src="thread per worker.png" style="zoom:150%;"><br><p>很多DBMS都用了多线程的技术</p><ul><li>这里的多线程其实是指一个SQL语句由一个worker去跑，多线程是指可以同时跑多个SQL语句</li><li>而将一条SQL开多线程跑是另一种技术</li></ul><br><br><br><h1 id="Execution-parallelism"><a href="#Execution-parallelism" class="headerlink" title="Execution parallelism"></a>Execution parallelism</h1><p>SQL执行间的并发机制</p><p>针对每一个执行计划，DBMS都要决定在哪儿执行，什么时候执行以及如何去执行</p><ul><li>比如说将执行计划切分为多少个任务（如何将每条SQL语句分为多个worker去执行）</li><li>每个任务需要占有多少的CPU资源</li><li>哪些CPU资源需要执行哪些任务</li><li>单个小任务的数据应该如何汇集在一起</li></ul><br><p>尽量让DBMS本身来控制这些行为，而不是OS</p><br><br><h2 id="Inter-query-parallelism"><a href="#Inter-query-parallelism" class="headerlink" title="Inter query parallelism"></a>Inter query parallelism</h2><p><strong>查询之间</strong>如何并发的执行</p><p>优点：不同的查询并发的去执行，可以降低延迟，提高吞吐量</p><br><p>如果查询是只读的话，那么多个查询之间的冲突就会很小，就没有并发问题</p><p>但是如果查询有读有写，那么就会有并发问题（需要后续的并发控制协议）</p><br><br><h2 id="Intra-query-parallelism"><a href="#Intra-query-parallelism" class="headerlink" title="Intra query parallelism"></a>Intra query parallelism</h2><p><strong>查询内部</strong>的算子进行并发处理，即将一个一个执行计划切分为不同的线程去做，可以减少延迟（减少等待）</p><p>优点：将一个查询计划拆分为不同的算子，并分给好几个线程同时执行，从而提高单个查询的性能和效率</p><br><p>思想上有点像生产者消费者的模型（前面的算子生产出了数据，后续的算子消费数据）</p><br><p>成熟DBMS的每一个算子都有并发的版本</p><p>例子：比如说之前的grace hash join</p><ul><li>可以并发的多个线程去处理每个桶之间的数据，即对每个桶进行并发的join</li><li>也可以用单个线程实现hash join</li></ul><img src="hash join.png" style="zoom:150%;"><br><p>并发算子实现的两大思路</p><ul><li>多个线程都去操作集中的总数据</li><li>或者将数据分隔开，让多个线程在本地就能处理不同部分的数据</li></ul><br><br><h3 id="Intra-operator-horizontal"><a href="#Intra-operator-horizontal" class="headerlink" title="Intra-operator(horizontal)"></a>Intra-operator(horizontal)</h3><p>水平切分；将需要处理的数据切分为多份，然后分发给多个线程执行</p><p>即每个线程执行的逻辑是相同的，但是负责的数据部分不同</p><p>最后插入exchange算子（用于数据的拆分聚集的）</p><br><p>下面的算子调用一次exchange算子</p><p>然后exchange算子并发的开启多个线程A1A2A3去执行</p><p>最后把得到的结果汇总给上面的算子</p><img src="intra-operator parallelism_01.png" style="zoom:150%;"><br><br><h4 id="Exchange-operator"><a href="#Exchange-operator" class="headerlink" title="Exchange operator"></a>Exchange operator</h4><p>有三种类型的exchange算子：</p><ul><li>gather：将下面并发执行的结果收集好分配给上面</li><li>distribute：将数据分发给不同的算子去执行，分配的算子</li><li>repartition：重分配的算子，即把三个算子的结果分配给两个算子去执行</li></ul><img src="exchange operator.png" style="zoom:150%;"><br><br><h3 id="Inter-operator-vertical"><a href="#Inter-operator-vertical" class="headerlink" title="Inter-operator(vertical)"></a>Inter-operator(vertical)</h3><p>垂直切分；一个SQL语句是由很多个算子组成的</p><p>那么就可以分配多个线程，分别取执行不同阶段的算子，以此实现并发</p><br><p>比如说线程1在下面执行hash join，而线程2在执行上面的算子</p><p>每个算子都由一个线程负责，数据就在线程之间进行传递</p><img src="inter-operator parallelism_01.png" style="zoom:150%;"><br><p>缺点：参考流式模型的缺点（如果某个算子的执行效率过低，那么就会影响后续算子的运行）</p><br><br><h3 id="Bushy-parallelism"><a href="#Bushy-parallelism" class="headerlink" title="Bushy parallelism"></a>Bushy parallelism</h3><p>是上述两种执行方法的融合版本，既有水平切分，也有垂直切分</p><img src="bushy parallelism.png" style="zoom:150%;"><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>其实DBMS真正的瓶颈是数据的IO，上面无论做再多的优化，如果磁盘的IO还是很慢的话，这些优化都不值一提</p><p>磁盘是瓶颈，但是我们还让不同的线程去读磁盘不同的部分，即随机IO</p><p>那么就会加剧这种瓶颈，所以要想到如何优化硬盘IO的性能</p><br><br><br><h1 id="I-O-parallelism"><a href="#I-O-parallelism" class="headerlink" title="I/O parallelism"></a>I/O parallelism</h1><p>磁盘IO的并发优化</p><p>最简单的思路：希望将数据库分为不同的部分，存储到不同的磁盘上，提高并发的性能</p><ul><li>比如说将A库存在一块磁盘上，将B库存在另一块磁盘上，这样在读取两个数据库的数据时是可以做到并发的</li></ul><p>常见的操作有：</p><ul><li><p>将同一个数据库存储在不同的硬盘上</p></li><li><p>一个数据库存放在一个硬盘上</p></li><li><p>一个数据表存放到一个硬盘上</p></li><li><p>把同一个数据表分割为不同的部分，存储在硬盘上</p></li></ul><br><p>这种做法还是在数据库层面，需要修改数据库的元数据配置</p><br><br><br><h1 id="Multi-disk-parallelism"><a href="#Multi-disk-parallelism" class="headerlink" title="Multi-disk parallelism"></a>Multi-disk parallelism</h1><p>从物理硬件（操作系统）层面，提高IO并发的效率（在数据库层面是无感知的，即DBMS像往常一样存取数据即可）</p><br><p>磁盘阵列（RAID），有多个磁盘，但是通过一些配置，使得看起来只有一个磁盘一样（使得DBMS感觉只有一个磁盘一样）</p><p>并且这种底层的磁盘配置对于DBMS来说是透明的（DBMS会认为此时只有一个磁盘，而实际上数据是存储在多个磁盘）</p><br><p><strong>RAID 0</strong></p><p>把page1和page4放到第一个盘，page2和page5放到第二个盘，page3和page6放到第三个盘</p><p>主要是操作系统和硬件共同控制；从文件系统上看就只有一个盘，但是底层是将数据切分为不同的部分存储到不同的硬盘的</p><img src="RAID 0.png" style="zoom:150%;"><br><p>优点：</p><ul><li>能够提高并行的读写（可以同时读写page1和page2）</li><li>拓展性高，可以横向添加多个硬盘</li></ul><p>缺点：</p><ul><li>如果一块硬盘坏了，其他盘中的文件碎片也会失效（因为这种方法是将文件的多个页面进行拆分的，如果一个文件其中某一页出现了问题，那么整个文件页就会失效）</li><li>因此需要备份的手段</li></ul><br><br><p><strong>RAID 1</strong></p><p>同一个数据页存到不同的磁盘中，相当于数据备份在不同的磁盘上</p><img src="RAID 1.png" style="zoom:150%;"><p>优点：可靠性高，多备份（其中一个数据盘坏了也不受影响）；可以并行读（并发写的话需要同步机制）</p><p>缺点：利用率低（3个1T的硬盘只能存1T的数据）</p><br><br><p><strong>RAID 5</strong></p><p>拿RAID 0举例：</p><p>把page1和page4放到第一个盘，page2和page5放到第二个盘</p><p>而第三个盘存储的是第一个盘和第二个盘中的数据，<strong>异或</strong>以后的结果</p><p>如果第三个盘挂了，那么重新将第一个盘和第二个盘异或即可</p><p>如果第二/一个盘挂了，那么可以利用第三个盘将挂了的盘进行恢复</p><p>当然还可以备份异或得到的结果，由此衍生不同的变种</p><img src="RAID 0.png" style="zoom:150%;"><br><br><br><h1 id="Database-partitioning"><a href="#Database-partitioning" class="headerlink" title="Database partitioning"></a>Database partitioning</h1><p>从数据库的表本身将数据切分开</p><br><p>对于数据分库，大部分的DBMS都支持将数据切分到不同的磁盘上</p><ul><li>主要因为DBMS是保存在不同的文件系统的不同的文件夹上</li><li>PS：DBMS用于recovery的log就需要在多个库之间共享</li></ul><br><p>而对于数据分区，可以在物理上将一个数据表分为多个不同的数据表</p><p>但是客户端（使用者）对此是无感知的，全部由DBMS控制数据的分表</p><p>表数据分区的两种思路：垂直分表、水平分表</p><br><h2 id="Vertical-partitioning"><a href="#Vertical-partitioning" class="headerlink" title="Vertical partitioning"></a>Vertical partitioning</h2><p>垂直分表，将不同列的数据存放到不同的磁盘（目录或者文件系统）中（使用的时候配置一下DBMS即可）</p><p>比如下图就是将attr1、attr2、attr3和attr4进行了分区处理</p><img src="vertical partitioning.png" style="zoom:150%;"><br><p>优点：</p><ul><li>针对同一条数据的IO，可以实现并发的读写数据</li><li>将冷热数据分离，提高读写效率（将一些不常用的数据和热点数据分表存储）</li></ul><br><br><h2 id="Horizontal-partitioning"><a href="#Horizontal-partitioning" class="headerlink" title="Horizontal partitioning"></a>Horizontal partitioning</h2><p>水平分表，按照某一列的值将一个数据表分割为多个数据表</p><p>对于数据分割的方法有很多，比如常见的hash分区、范围分区、再或者谓词分区</p><img src="horizontal partitioning_01.png" style="zoom:150%;"><p>一些分库分表的中间件也可以做水平分区</p><p>就像是一个网关，将客户端的数据分成不同的部分，然后再存储到不同的数据库（节点）上</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>并发执行、并行是非常重要的（能够降本增效），因此几乎所有的DBMS都实现了并发执行</p><ul><li>主要指的是SQL语句之间的并发</li></ul><br><p>模型看着简单，但是coding却非常的麻烦</p><ul><li>worker的调度、协调</li><li>worker的并发（数据的加锁解锁）</li><li>worker资源上的冲突（比如说多个worker都需要相同的资源，那么磁盘的资源如何协调）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Why-care-about-parallel-execution&quot;&gt;&lt;a href=&quot;#Why-care-about-parallel-execution&quot; class=&quot;headerlink&quot; title=&quot;Why care about parallel ex
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 11-Query Execution Part I</title>
    <link href="https://dancsmshenry.github.io/2022/12/29/cmu-15-445-11-query-execution-part-i/"/>
    <id>https://dancsmshenry.github.io/2022/12/29/cmu-15-445-11-query-execution-part-i/</id>
    <published>2022-12-29T13:53:35.000Z</published>
    <updated>2024-09-17T06:10:19.539Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Processing-model"><a href="#Processing-model" class="headerlink" title="Processing model"></a>Processing model</h1><p>执行模型有哪些，执行计划是如何运作的</p><p>DBMS的执行模型规定了系统是如何执行查询计划的</p><p>根据不同的工作负载（TP or AP），在执行计划上有不同的权衡</p><br><br><h2 id="Approach-1-iterator-model"><a href="#Approach-1-iterator-model" class="headerlink" title="Approach 1 iterator model"></a>Approach 1 iterator model</h2><p>迭代器模型，也叫火山模型（Volcano Model），或者流式模型（Pipeline Model）</p><p>每个算子都要实现一个<code>next()</code>方法</p><p>当父算子调用当前算子的<code>next()</code>方法的时候，当前算子就会向父算子返回一条数据（或者是返回NULL，表示当前算子运行结束）</p><p>如果当前算子有子算子的话，就需要循环的调用子算子的<code>next()</code>方法，得到下一层的数据</p><p>需要多少条数据，就会有多少次这样的链式的函数调用</p><img src="iterator model_01.png" style="zoom: 150%;"><br><br><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>1号算子循环调用<code>child.next()</code>算子，即2号算子</p><p>2号算子分为两部分，要先执行<code>left.next()</code>算子（hash join中构建hash表），再执行<code>right.next()</code>算子（将数据放入hash表中映射）</p><p><code>left.next()</code>算子，即3号算子，则需要一行一行的向上返回数据；4、5号算子同理</p><img src="iterator model_02.png" style="zoom:150%;"><p>而在执行2、3、4、5号算子的过程中，1号算子会因为2号算子没有返回数据而阻塞（因为只有下面的算子返回了数据，上面的算子才能继续运行）</p><br><br><p><strong>几乎所有的DBMS都用到了火山模型</strong>（或者它的变种）</p><p>一条条数据向上吐出（数据流处理），和直观上认为DBMS的运行是不一样的（直观上认为是把所有的数据都计算好，再往上返回）</p><p>某些算子存在阻塞阶段</p><ul><li>比如join算子在构建hash表的时候，是不会返回数据的</li><li>又或者说subqueries子查询</li><li>再比如order by排序，因为需要将所有的数据都获取了以后，进行排序才能够返回</li></ul><p>使用这种方法非常方便控制数据的输出</p><ul><li>比如说此时要求<code>limit 100</code>，那么只需要输出到100条数据的时候停止即可</li><li>而不需要控制底层算子具体需要读取多少条数据，只需要控制算子的出口输出即可</li></ul><p>性能上的一些问题</p><ul><li><p>部分算子依旧存在阻塞</p></li><li><p>每一条数据的输出都是依靠函数调用，可能出现函数栈溢出</p></li></ul><img src="iterator model_03.png" style="zoom:150%;"><br><br><h2 id="Approach-2-materialization-model"><a href="#Approach-2-materialization-model" class="headerlink" title="Approach 2 materialization model"></a>Approach 2 materialization model</h2><p>物化模型（一般大众直观上认为的一种做法）</p><p>每个算子的输入就是当前语句需要执行的所有数据，输出的是语句的所有结果</p><p>即将当前语句涉及的所有数据都处理好了，才返回给上一级</p><br><p>每一个算子都有一个out数组，用于存储当前算子处理好了的数据，并作为结果返回给上一级算子</p><p>模型中所有的算子都只会被调用一次</p><img src="materialization model_01.png" style="zoom:150%;"><br><p>一些偏向OLTP的数据库，比如交易的数据库会使用这种数据库</p><ul><li>因为涉及交易的操作很多都是点查询，只涉及很少的数据</li><li>无论是最终结果还是中间结果，数据量都很小，DBMS能够轻松负载</li></ul><p>因此这种做法并不适用于OLAP的数据库，因为中间结果太大，容易爆内存</p><img src="materialization model_02.png" style="zoom:150%;"><br><br><h2 id="Approach-3-vectorized-batch-model"><a href="#Approach-3-vectorized-batch-model" class="headerlink" title="Approach 3 vectorized/batch model"></a>Approach 3 vectorized/batch model</h2><p>向量化模型（分批模型），属于是方法一和方法二的中间派，就是两种方法的结合</p><p>和<code>iterator model</code>一样有<code>next()</code>方法，但是返回的不是一条数据，而是一批数据</p><p>也和<code>materialization model</code>一样有<code>out</code>数组，但返回的不是全部数据，而是部分数据</p><img src="vectorization model_01.png" style="zoom:150%;"><br><br><p>适用于OLAP类型的数据库</p><ul><li>因为既能使得中间的结果集不太大，又能使得函数的调用次数相对少一点</li></ul><p>在底层指令集上的优势：</p><ul><li>背景：intel有一个能够同时处理多个数据的指令（即在一个机器指令的周期就能够将数据全部计算好），即<strong>AVX指令集</strong></li><li>这种模型的底层就可以利用这种批处理的指令，实现一次性处理多条数据</li><li>也叫做向量执行模型</li></ul><img src="vectorization model_02.png" style="zoom:150%;"><br><br><br><h1 id="Plan-processing-direction"><a href="#Plan-processing-direction" class="headerlink" title="Plan processing direction"></a>Plan processing direction</h1><p>执行语句时，函数调用的方向（是从根节点的函数往下调用叶子节点的函数，还是从叶子结点的函数往上调用根结点的函数）</p><p>PS：数据流动的方向一直是从下往上的</p><br><p>方法一：<strong>top to bottom</strong></p><ul><li>从上往下执行，先执行根结点，再执行叶子节点</li></ul><br><p>方法二：<strong>bottom to top</strong></p><ul><li>从下往上执行，先执行叶子节点，然后叶子节点调用根结点</li></ul><br><br><br><h1 id="Access-methods"><a href="#Access-methods" class="headerlink" title="Access methods"></a>Access methods</h1><p>从磁盘读取数据、存储数据的方式有哪些</p><p>主要就是研究如何读表中的数据</p><img src="access methods.png" style="zoom:150%;"><br><br><h2 id="Sequential-scan"><a href="#Sequential-scan" class="headerlink" title="Sequential scan"></a>Sequential scan</h2><p>顺序扫描，从磁盘中把数据页放到内存中，每条记录每条记录的扫描遍历（说白了就是全表遍历）</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> page <span class="token keyword">in</span> table<span class="token punctuation">.</span>pages<span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#    外层循环遍历数据页</span>    <span class="token keyword">for</span> t <span class="token keyword">in</span> page<span class="token punctuation">.</span>tuples<span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#    内存循环遍历数据页里面的数据</span>        <span class="token keyword">if</span> evalPred<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">#    do something</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果需要某个数据页页，就先在buffer pool中去找，如果有的话，就把它取出来遍历；否则就去硬盘中去找</p><p>在执行过程中的算子需要保持一个指针，把这个指针当作迭代器一样去扫描遍历数据（同时记录上一次读取到哪里的数据了）</p><br><br><h3 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations"></a>Optimizations</h3><p>类似全表扫描等操作，存在很多优化的可能</p><p>方法一：prefetching</p><p>在执行计划之前，提前将数据从磁盘中预先取出来</p><br><p>方法二：buffer pool bypass</p><p>在全表扫描时，假如用过的数据后续不会再用了，那么就不用将数组再存储在buffer中了，而是用完后就丢掉</p><br><p>方法三：parallelization</p><p>多线程并行执行：启用两个线程，一个线程从前扫到中间，另一个线程从中间扫到后面</p><br><p>方法四：zone maps</p><p>背景：假设有一个需求，要扫描大于100的数据值；但是有可能某个数据页里面所有的值都小于100，如果把该页放入内存，就会造成资源的浪费</p><p>所以希望用一个map，用来<strong>记录关于这个页</strong>的相关信息（比如说max，min，avg，sum等），以便DBMS筛选掉某些页，从而优化全表扫描的速度</p><img src="zone maps.png" style="zoom:150%;"><p>缺点：</p><ul><li>浪费空间；如果该信息是存放在每个页的话，那么就无法达到筛选的目的（因为我们本来就是希望利用zone map减少无用数据页的读取），所以必然是存储在额外的数据页的</li><li>不利于数据的存放；如果原始数据可能发生了一点点修改，那么map可能会因此发生很大的修改，不方便维护，甚至可能造成写放大，即单单写入一个数据表的数据，结果需要修改过多zone map上的数据</li></ul><br><p>方法五：late materialization</p><p>延迟物化</p><p>只需要把符合条件的记录的id（offsets）给返回，在最后返回数据的时候才将数据进行物化（最后才回表），减少了扫描的工作量</p><p>适用于<strong>列存储</strong>的数据库，因为算子一般只对列的数据进行处理（而行存储是将一连串数据一起存储，不方便获取单独列的数据）</p><br><br><h2 id="Index-scan"><a href="#Index-scan" class="headerlink" title="Index scan"></a>Index scan</h2><p>查询扫描走索引的一些条件：</p><ul><li>索引有没有我们需要的属性</li><li>索引是否含有我们需要的输出列</li><li>索引的值域</li><li>谓词的压缩</li><li>是否为唯一索引</li></ul><br><p>假如有两个索引，应该选择哪一个索引效果更好？</p><img src="index scan.png" style="zoom:150%;"><p>选择该索引后，剩下的数据，即需要再排查的数据越少，就选那一个</p><p>比如说上面要选择age &lt; 30的，那么如果选择age的索引，最后剩下的数据更少，那么就选择age的索引</p><br><br><h2 id="Multi-index-scan"><a href="#Multi-index-scan" class="headerlink" title="Multi-index scan"></a>Multi-index scan</h2><p>比如上面的问题，多索引的思路是用一个索引筛出数据A，用另一个索引筛出数据B，然后对这两个数据进行取交集</p><img src="multi-index scan.png" style="zoom:150%;"><p>在PG中，multi-index scan的底层就是用bitmap实现的</p><br><br><br><h1 id="Modification-queries"><a href="#Modification-queries" class="headerlink" title="Modification queries"></a>Modification queries</h1><p>此前对于数据的研究都是读取，并没有涉及到数据层面的修改</p><p>而涉及数据的修改的语句的执行逻辑，和读取的逻辑是截然不同的</p><br><p>比如说，对于数据的插入、更新和删除，都是要检查其是否符合数据库的约束的，即一致性（比如unique等），同时还要维护数据的索引</p><br><p>update/delete</p><ul><li>下面的算子将要删除的记录id返还给上一层（而不是整条数据），然后用这个id回表删除记录</li><li>删除算子和更新算子都要记录自己对哪些数据进行了操作</li></ul><br><p>insert</p><ul><li>算子内部将数据物化，将数据整个插入</li><li>需要子算子将行记录物化好，则当前的insert算子只要将记录插入即可</li></ul><br><br><h2 id="Update-query-problem"><a href="#Update-query-problem" class="headerlink" title="Update query problem"></a>Update query problem</h2><p>假设要更新一个索引上所有的数据，使其全部加上100</p><p>update的操作流程是，按照索引的顺序，每读一个数据就把该数据先从index中移除，接着给这个数据+100，然后再放回去</p><p>而如果不记录当前update的算子对于哪些数据进行了操作，</p><p>比如说我们希望age小于30的人全部加10岁，某个人现在11岁</p><p>那么在第一次加10岁以后，变成了21岁，但我们没有记录对哪些数据进行了操作，那么就会重复给这个数据再加10岁</p><p>造成数据更新的重复</p><p>因此无论是update还是delete，都要记录下自己对哪些数据进行了操作</p><p>这个问题被简称为halloween problem，即万圣节问题</p><br><br><br><h1 id="Expression-evaluation"><a href="#Expression-evaluation" class="headerlink" title="Expression evaluation"></a>Expression evaluation</h1><p>谓词表达式的一些计算（谓词表达式本质上就是一个计算式，涉及到不同的符号，比如等于不等于等符号）</p><img src="expression evaluation.png" style="zoom:150%;"><br><br><p>在DBMS中，一个通用的处理方案是：</p><p>将谓词表达式拆分为一个树状的流程图，即分为几个不同的算子</p><img src="expression evaluation_01.png" style="zoom:150%;"><br><br><p>不过这种流程存在一些优化的方向：</p><img src="expression evaluation_02.png" style="zoom:150%;"><br><p>这里的<code>WHERE</code>需要先读取<code>B.value</code>，然后计算<code>? + 1</code>的值是多少，最后再将二者进行比较看是否相等</p><p>而每次都要计算一遍<code>? + 1</code>的值是多少，效率非常低</p><p>一个优化的方式就是先直接将<code>? + 1</code>的值计算好，后续直接调用即可</p><br><p>这就有点类似java里面的JIT</p><ul><li><p>just in time，java运行的是字节码，相当于把代码编译为了字节码，而不是二进制；于是有一种思路就是，发现一些重复利用的代码，于是就将其编译成了二进制，提高效率，即再使用这类代码的时候就变为二进制执行了</p></li><li><p>把一些热点的代码段编译为二进制，从而提高效率</p></li><li><p>PS：jit是在执行的时候判断</p></li><li><p>而与JIT对立的是AOT，执行之前就判断，还没运行的时候就将重复的字节码编译为二进制</p></li></ul><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>一个相同的执行计划，不同的执行模型，执行方法也会不同</p><p>在排查大部分DBMS的问题的时候，查询是否走索引是一个经常需要注意的方向</p><p>按照树形的方法进行查询是非常灵活的，但是会很慢，所以需要后续的一些优化</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Processing-model&quot;&gt;&lt;a href=&quot;#Processing-model&quot; class=&quot;headerlink&quot; title=&quot;Processing model&quot;&gt;&lt;/a&gt;Processing model&lt;/h1&gt;&lt;p&gt;执行模型有哪些，执行计划是如
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 10-Join Algorithms</title>
    <link href="https://dancsmshenry.github.io/2022/12/26/cmu-15-445-10-join-algorithms/"/>
    <id>https://dancsmshenry.github.io/2022/12/26/cmu-15-445-10-join-algorithms/</id>
    <published>2022-12-26T14:03:41.000Z</published>
    <updated>2024-09-17T06:10:19.535Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Why-do-we-need-to-join"><a href="#Why-do-we-need-to-join" class="headerlink" title="Why do we need to join"></a>Why do we need to join</h1><p>因为数据在关系型数据库中的存储，是按照数据模型间的连接关系分开的</p><p>所以，如果想要获取一连串相关联的数据，就需要用join连表查询</p><p>本节主要研究的是<strong>内连接</strong>，用<strong>相等</strong>谓词连接的算法</p><p>在进行join的时候，有个原则就是尽量把小一点的表放到左边（也就是外表）</p><p>PS：本节说的小表，都是指<strong>文件页少</strong>的数据表</p><br><br><br><h1 id="Join-operators"><a href="#Join-operators" class="headerlink" title="Join operators"></a>Join operators</h1><p>首先就要研究<strong>算子的输出</strong>，向上级输出的数据是什么类型的</p><p>接着就要研究<strong>不同算法的花费</strong>，并根据开销决定用选取算法</p><br><br><h2 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h2><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><p>early materialization（提前物化）</p><p>向上输出的是两个表连接后得到的数据，即把整条数据记录都往上传</p><p>优点：算子得到的结果不需要回表查询</p><p>缺点：传输整条数据的开销过大</p><img src="data.png" style="zoom:150%;"><br><br><h3 id="Record-ids"><a href="#Record-ids" class="headerlink" title="Record ids"></a>Record ids</h3><p>late materialization（延迟物化）</p><p>向上输出的是数据记录的id号</p><p>优点：数据在算子间的传输开销较小</p><p>缺点：如果想要获取完整的数据记录，就需要回表查询</p><img src="ids.png" style="zoom:150%;"><br><br><h2 id="Cost-analysis-criteria"><a href="#Cost-analysis-criteria" class="headerlink" title="Cost analysis criteria"></a>Cost analysis criteria</h2><p>对算法的开销进行分析</p><p>以<strong>磁盘的IO次数</strong>衡量算法的开销</p><br><p>笛卡尔积</p><p>笛卡尔积是解决join最朴素的方法，但它是非常低效的</p><p>因此，为了降低连表查询时开销，提出了以下算法：</p><ul><li>nested loop join（simple，stupid，block，index）</li><li>sort-merge join</li><li>hash join</li></ul><br><br><br><h1 id="Nested-loop-join"><a href="#Nested-loop-join" class="headerlink" title="Nested loop join"></a>Nested loop join</h1><p>嵌套循环join</p><br><h2 id="Simple-nested-loop-join"><a href="#Simple-nested-loop-join" class="headerlink" title="Simple nested loop join"></a>Simple nested loop join</h2><p>简单嵌套循环，分为外层循环和内层循环（可以理解为<code>O(n^2)</code>的循环）</p><p>外层循环时遍历R表的每一行，针对R表的每一行</p><p>再在内层循环中遍历S表中的每一行，进行匹配</p><br><p>具体的操作就是读取外表（R表）的每一条记录，然后从头开始遍历一遍S表，看看是否能够匹配上</p><p>PS：此时内存最少能够存放三个数据页即可（R、S表的数据页，以及匹配结果的数据页）</p><img src="stupid nested loop join.png" style="zoom:150%;"><br><p>缺点：没有充分利用到缓存池的特点</p><ul><li>比如说对于R表的第一条记录进行join的时候，会轮流将S表的数据都读到buffer中</li><li>而在用完S表的数据后又会将它放回磁盘，并在对R表的第二条记录进行join的时候重新读入</li><li>此时就会发现buffer失效了，明明可以重复利用此前读入内存的S表的数据页，但都没有用上</li><li>即，这种做法并没有利用缓冲池能提高内存页的利用率的优点</li></ul><br><br><p><strong>算法开销</strong></p><p>要读取整个R表，所以是<code>M</code>（总共有M个数据页）</p><p>对于R表中的每一条记录，都需要一一和S表中的数据匹配，所以是<code>m * N</code>（R表中有m条记录，每条记录都需要读取S表的N个数据页）</p><img src="stupid nested loop join_01.png" style="zoom:150%;"><br><br><h2 id="Block-nested-loop-join"><a href="#Block-nested-loop-join" class="headerlink" title="Block nested loop join"></a>Block nested loop join</h2><p>一个优化思路，此前都是按照一条条数据记录进行join，可以改进为按照数据页进行遍历</p><br><p>先读取R数据表的数据页A</p><p>然后再依次的遍历S中的数据页，从而将数据页A中的数据一一对上</p><p>接着再读取R表的下一个数据页B，一次类推</p><p>PS：此时内存最少能够存放三个数据页即可（R、S表的数据页，以及匹配结果的数据页）</p><p>下图的block可以理解为一个页Page</p><img src="block nested loop join_01.png" style="zoom:150%;"><br><br><p><strong>算法开销</strong></p><p>要读取整个R表，所以是<code>M</code>（R表中有M个页）</p><p>而此时是以数据页进行匹配的，即每个数据页都匹配一遍S表，所以是<code>M * N</code>（R表中有M个页，S表有N个页）</p><img src="block nested loop join_02.png" style="zoom:150%;"><br><br><p><strong>基于缓冲池的优化</strong></p><p>假设内存缓冲池中有B个缓存页</p><p>选取其中一个页作为输出缓存，一个页作为内表（S表）的缓存</p><p>剩下的B-2个页作为外表（R表）的缓存</p><p>此时的流程：将R表的数据读入内存后，依次从头遍历S表的每一页，将S表上的数据和R表上的数据进行匹配</p><img src="block nested loop join_03.png" style="zoom:150%;"><br><br><p><strong>算法开销</strong></p><p><code>M + (M / (B - 2) * N)</code></p><ul><li>M表示要将R表中所有的数据都读取一遍</li><li><code>M/(B - 2)</code>表示将R表中的数据全数放入大小为<code>B - 2</code>内存中，需要多少次</li><li>因此如果``B - 2 &gt; M<code>，那就相当于只需要</code>M + N`</li></ul><img src="block nested loop join_04.png" style="zoom:150%;"><br><br><h2 id="Index-nested-loop-join"><a href="#Index-nested-loop-join" class="headerlink" title="Index nested loop join"></a>Index nested loop join</h2><p>思考：为什么simple/block nested loop join那么慢？换言之，为什么一定要完全遍历S表的所有数据？</p><p>主要是因为内表（S表）没有加索引，导致每次数据的查询必须全遍历，由此引申出基于索引的查询</p><br><p>算法的开销：<code>M + (m * C)</code>（C是指每次查询所有需要的页数）</p><img src="index nested loop join.png" style="zoom:150%;"><br><br><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>如果选取nested loop join作为join的算法，那么：</p><ul><li><p>尽量把小一点的表作为外表（这样遍历内表的次数就会减少）</p></li><li><p>尽量缓存多一点外表的数据，这样可以减少内表的遍历次数</p><ul><li>因为我们是以外表为核心遍历的，所以内表的数据缓存下来是没有意义的，每次都还是得从头遍历</li></ul></li><li><p>每次查找都会一直遍历循环内表，因此提出利用索引进行查询，提高效率</p></li></ul><br><br><br><h1 id="Sort-merge-join"><a href="#Sort-merge-join" class="headerlink" title="Sort-merge join"></a>Sort-merge join</h1><p>将需要进行join的数据列，先进行sort，然后再merge</p><img src="sort merge join的伪代码.png" style="zoom: 150%;"><br><p>merge时的一些细节：</p><ul><li><p>首先，哪一边较小，就将小的一边的指针往下移一位</p></li><li><p>而，对于双指针中二者值相等的时候，一般的做法是输出值后同时下移指针</p></li><li><p>但这里内表（S表）中可能会出现多个数据相同的情况，如果同时下移指针可能会略过一些数据</p></li><li><p>所以不能同时移动两边的指针，而只能移动内表的指针（即移动S表的指针）</p></li></ul><br><br><p><strong>算法开销</strong></p><p>排序时的开销就是上一节所说的外部排序</p><img src="sort merage join的cost_01.png" style="zoom:150%;"><br><br><p>缺点：如果两边的数据全都一样，或者说重复的数据太多，在最严重的时候会导致退化为simple nested loop join</p><ul><li>比如两个表的数据都是完全一样的话，那么执行效率上就会和Simple nested loop join的双层循环一样了</li></ul><img src="sort-merge.png" style="zoom:150%;"><br><br><p>那什么时候该算法才是最高效的？</p><ul><li>当数据本身就排好序了，就减少了sort的过程，直接merge（比如说下一级算子给的数据是有序的，或者是从index读取的数据）</li><li>或者说需要的数据本身要求是有序的，那么sort就必不可少（比如说是按照索引读取数据的）</li></ul><br><br><br><h1 id="Hash-join"><a href="#Hash-join" class="headerlink" title="Hash join"></a>Hash join</h1><p>思考：发现B+树的查询有点随机性（和树的结点数和层数有关）；并且我们的需求其实是点查询，不需要B+树范围扫描的特性</p><p>而点查询中最快的是hash，因此引入了hash查询</p><br><h2 id="Basic-hash-join-algoritham"><a href="#Basic-hash-join-algoritham" class="headerlink" title="Basic hash join algoritham"></a>Basic hash join algoritham</h2><p>Phase I：build，扫描外表数据，构建hash表</p><p>Phase II：probe，扫描内表的数据，放入hash表中查询</p><img src="basic hash join algorithm.png" style="zoom:150%;"><br><br><h2 id="Hash-table-values"><a href="#Hash-table-values" class="headerlink" title="Hash table values"></a>Hash table values</h2><p>hash表中的key是语句用于join的那一列数据</p><p>而value有以下几种表示方法：</p><ul><li>提前物化（full tuple，将整个元组作为数据存储）</li><li>推迟物化（tuple identifier，即是数据的行id之类的，后续回表取数据）</li><li><img src="hash table values.png" style="zoom:150%;"></li></ul><br><br><h2 id="Probe-phase-optimization"><a href="#Probe-phase-optimization" class="headerlink" title="Probe phase optimization"></a>Probe phase optimization</h2><p>背景：发现如果使用hash匹配数据，没匹配上很浪费时间精力，因此想要用<strong>bloom filter</strong>进行优化</p><br><p>即用外表做一个hash，同时维护一个bloom filter，然后内表查数据的时候，就先查bloom filter，如果没有就不继续查了</p><br><p>为什么bloom filter可以提高性能，因为内表查询数据首先会去filter中查找，如果没找到，就会跳过当前数据</p><p>而如果没有bloom filter的话，就会加载hash表的page，然后去寻找（这种磁盘的IO无疑是浪费资源的）</p><p>所以bloom filter就可以提早知道数据不存在，就不会去读取内存，从而提高效率</p><p>PS：bloom filter会出现假阳性</p><br><br><p><strong>算法开销</strong></p><img src="hash join cost_01.png" style="zoom:150%;"><br><br><h2 id="Grace-hash-join"><a href="#Grace-hash-join" class="headerlink" title="Grace hash join"></a>Grace hash join</h2><p>背景：上述算法的主要问题是：内存不够，会导致hash难以构建，那该怎么办？因此需要把一些hash表的数据放到硬盘中</p><p>但是又不需要随机的将数据页驱逐到磁盘中，而是希望能够控制内存页驱逐的策略</p><ul><li>所以有了grace hash join</li></ul><br><p>Phase I：用同一个hash函数，把R表和S表分别做一个hash表1和hash表2</p><p>Phase II：把R表的hash表1和S表的hash表2，各取一个分区的数据，进行nested loop join</p><ul><li>这里的原理就是，都是用的同一种hash算法，能够join的元素必然是在同一个分区当中的</li></ul><img src="grace hash join.png" style="zoom:150%;"><br><br><h3 id="Recursive-partitioning"><a href="#Recursive-partitioning" class="headerlink" title="Recursive partitioning"></a>Recursive partitioning</h3><p>背景：上述的假设中，每个单独的bucket（即分区）是可以放入到内存中的</p><p>但，如果一个分区的元素都非常多，都放不到内存中，该如何处理？</p><p>解决办法：对这个非常大的分区，对两边的数据表，再用一个新的hash函数进行hash，直到能够分到足够小的块</p><img src="recursive partitioning.png" style="zoom: 150%;"><br><br><p><strong>算法的开销</strong></p><p>partitioning phase：<code>2（M + N）</code></p><ul><li>无论是内表还是外表，一次是要把数据从硬盘读到内存中，另一次是要把数据放到hash表中并写入磁盘</li><li>这里假设hash表的页数也是和原来的数据表同页</li></ul><br><p>probing phase：<code>M + N</code></p><ul><li>两边分别把hash表的数据都读入到内存，所以就是M + N</li><li>读到内存的数据再进行nested loop join</li></ul><br><p>因此总共的开销是<code>3 * (M + N)</code></p><img src="grace hash join cost.png" style="zoom:150%;"><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>如果提前知道外表的大小，就可以用静态的hash表对数据操作，而不是使用动态扩容的hash表</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><img src="join algorithms summary.png" style="zoom: 150%;"><p>如果是两个大表做join的话，最好就是做hash join（绝大部分情况下，都是选择hash join的）</p><p>但，如果需要数据是倾斜的，即发生hash冲突的概率较大（会导致算法退化），那么最好还是选择sort-merge</p><p>或者，输出结果需要被排序的时候，会选择sort-merge</p><p>一般，比较好的DBMS会选择hash join和sort-merge join</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Why-do-we-need-to-join&quot;&gt;&lt;a href=&quot;#Why-do-we-need-to-join&quot; class=&quot;headerlink&quot; title=&quot;Why do we need to join&quot;&gt;&lt;/a&gt;Why do we need to jo
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 09-Sorting,Aggregations</title>
    <link href="https://dancsmshenry.github.io/2022/12/26/cmu-15-445-09-sorting-aggregations/"/>
    <id>https://dancsmshenry.github.io/2022/12/26/cmu-15-445-09-sorting-aggregations/</id>
    <published>2022-12-26T14:02:25.000Z</published>
    <updated>2024-09-17T06:10:19.531Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Course-status"><a href="#Course-status" class="headerlink" title="Course status"></a>Course status</h1><p>接下来的几节课里面，主要讲述以下内容：</p><ul><li>Operator Algorithms（具体的算子，比如join，sort是如何执行的）</li><li>Query Processing Models（用什么方案执行查询，比如火山模型）</li><li>Runtime archiectures（查询在内存中是什么架构，例如进线程模型）</li></ul><br><br><br><h1 id="Disk-oriented-DBMS"><a href="#Disk-oriented-DBMS" class="headerlink" title="Disk-oriented DBMS"></a>Disk-oriented DBMS</h1><p>硬盘中存储了大量的数据</p><p>而查询过程中，数据的中间结果不能全放在内存中</p><ul><li>内存空间有限，中间结果可能很多，存放太多中间结果会导致内存用尽</li></ul><p>并且，需要内存缓存池和硬盘进行配合，进行算子的操作</p><p>同时希望最大化的利用顺序IO，降低随机IO的次数</p><br><br><br><h1 id="Why-do-we-need-to-sort"><a href="#Why-do-we-need-to-sort" class="headerlink" title="Why do we need to sort?"></a>Why do we need to sort?</h1><p>关系型数据库没有要求数据要按照特定的顺序排列（如果没有指定，一般SQL得到的结果都是无状态的）</p><p>但是查询往往希望按照特定的顺序检索元组</p><p>比如一些常见的操作：</p><ul><li>去重操作（DISTINCT，先排序再去重）</li><li>聚合操作（GROUP  BY、ORDER BY等，先排序再聚集）</li></ul><br><br><br><h1 id="Sorting-algorithms"><a href="#Sorting-algorithms" class="headerlink" title="Sorting algorithms"></a>Sorting algorithms</h1><p>如果数据能够在内存中排序（即要排序的数据都在内存中），那么就可以使用标准的排序算法（比如快排等）</p><p>否则，就需要一种排序方法，能将大于内存大小的数据进行排序，同时也能兼顾数据在磁盘上读写的成本</p><br><br><h2 id="External-merge-sort"><a href="#External-merge-sort" class="headerlink" title="External merge sort"></a>External merge sort</h2><p>要排序的数据不是在内存中的，而是在硬盘中的</p><p>将数据集分割成单独的运行，然后分别排序</p><p>阶段一：排序（对装入主存的数据块进行排序，然后将排序后的数据块写回磁盘上的文件中）<strong>Sorting</strong></p><p>阶段二：合并（将排序后的子文件合并成一个更大的文件）<strong>Merging</strong></p><br><br><h2 id="Sorted-run"><a href="#Sorted-run" class="headerlink" title="Sorted run"></a>Sorted run</h2><p>假设我们需要对数据的某一列进行排序，则将这一列设为key，这一条数据设为value，组成一个kv对</p><p>其中数据的表达形式（即value）有以下两种方式：</p><ul><li>方式一：v存储的是一整行的数据（early materialization，提早物化）<ul><li>数据排序后不需要回表查询</li></ul></li><li>方式二：v存储的是记录的id或者主键值（late materialization，延迟物化）<ul><li>数据排序后需要用id或主键值进行回表查询</li></ul></li></ul><br><br><h2 id="2-way-external-merge-sort"><a href="#2-way-external-merge-sort" class="headerlink" title="2-way external merge sort"></a>2-way external merge sort</h2><p>2路归并排序</p><br><p>假设当前有page1和page2</p><p>先把page1放到内存中进行排序，把得到的结果1写入磁盘中</p><p>再把page2放到内存中进行排序，把得到的结果2写入磁盘中</p><p>此时磁盘中有page1、page2、结果1、结果2</p><p>然后将结果1和结果2都放到内存中，进行归并；合并得到的结果放到一个新的数据页中</p><p>合并好后把这个数据页放到磁盘中</p><br><br><h3 id="Phase-I"><a href="#Phase-I" class="headerlink" title="Phase I"></a>Phase I</h3><p>将表中的数据页读入到内存中，对数据页的内容进行排序，然后把排序好的结果返回给磁盘</p><img src="2-way external merge sort_01.png" style="zoom: 150%;"><br><br><h3 id="Phase-II"><a href="#Phase-II" class="headerlink" title="Phase II"></a>Phase II</h3><p>递归的将数据页成对成对合并（使用三个缓冲页，2个输入页，1个输出页）</p><img src="2-way external merge sort_02.png" style="zoom:150%;"><br><br><h3 id="Cost"><a href="#Cost" class="headerlink" title="Cost"></a>Cost</h3><p>因为需要对每个页内部的数据进行排序，所以就需要<code>1</code>个阶段</p><p>而每两个页进行合并排序，所以需要<code>log2 N</code>个阶段（这里需要向上取整）</p><p>统计总共需要多少个阶段，然后再乘以一个2N（因为每个阶段都需要读写2次数据，一次是将数据写入到内存，一次是将排序好的数据写入回内存）</p><img src="2-way external merge sort_cost.png" style="zoom: 150%;"><br><br><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Pass #0：读取每一个数据页，将每一个数据页内的数据进行内部排序，使得数据页本身变为有序的</p><p>Pass #1，2，3：每次将两个数据页读入到内存中，将它们归并排序</p><img src="2-way external merge sort.png" style="zoom:150%;"><br><br><h3 id="Double-buffering-optimization"><a href="#Double-buffering-optimization" class="headerlink" title="Double buffering optimization"></a>Double buffering optimization</h3><p>发现该算法只需要3个缓冲区页来执行排序，但是我们的内存buffer远远不止三个缓冲页，即这个思路没有有效的把空间利用起来</p><p>因此，当发生排序的时候，在后台预先取下一次要运行的数据页，并在系统当前处理其他页面的时候把它放到第二个缓冲区</p><p>不断的利用磁盘读取数据，减少每一步的IO请求的等待时间</p><p>本质上就是利用多余的内存，实现提前拉取数据的目的</p><br><br><h2 id="General-external-merge-sort"><a href="#General-external-merge-sort" class="headerlink" title="General external merge sort"></a>General external merge sort</h2><p>K路归并排序</p><p>Phase I：使用B个缓冲页对数据进行排序（假设数据表总共有N个数据页，总共需要<code>[N/B]</code>次读取数据并排序）</p><p>Phase II：将内存中的一个缓冲页作为输出页，其他的B-1个缓冲页用作K路合并排序</p><p>PS：MySQL就是用这种方法的</p><img src="general external merge sort.png" style="zoom:150%;"><br><br><h3 id="Cost-1"><a href="#Cost-1" class="headerlink" title="Cost"></a>Cost</h3><p>总共的阶段数是$1 + \lceil log_{B-1} \lceil N / B\rceil \rceil$（推理过程同上）</p><p>总共的消耗是$2N* (1 + \lceil log_{B-1} \lceil N / B\rceil \rceil)$</p><br><br><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p>第一个阶段，读取5个数据页，将这5个数据页的数据进行一次<strong>整体</strong>的排序</p><p>Pass #0：此时有108个数据页，分为22个整体（108/5向上取整，每个整体有5个page，最后一个整体只有3个page）；对每个整体内的数据进行排序</p><p>第二个阶段，将一个数据页位置作为输出位，那么此时剩余4个数据页</p><p>Pass #1：此时有22个整体（108/5向上取整，每个整体有5个page，最后一个整体只有3个page），那么每次就取4个整体，每个整体中取出一页，进行归并排序</p><p>Pass #2：此时有6个整体（22/4向上取整，每个整体有20个page，最后一个整体只有8个page），那么每次就取4个整体，每个整体中取出一页，进行归并排序</p><p>Pass #3：此时有2个整体（6/4向上取整，每个整体有80个page，最后一个整体只有28个page），那么每次就取4个整体，每个整体中取出一页，进行归并排序</p><img src="general external merge sort_cost.png" style="zoom:150%;"><br><br><h2 id="Using-B-trees-for-sorting"><a href="#Using-B-trees-for-sorting" class="headerlink" title="Using B+trees for sorting"></a>Using B+trees for sorting</h2><p>如果需要排序的属性，在表中建立了索引（比如说B+ tree），那么就可以使用它来加速排序</p><p>通过直接遍历B+ tree的叶子数据页，得到排序好的数据</p><br><p>这总是比外部排序好，因为没有计算成本，而且所有的磁盘访问都是顺序IO</p><p>分类：聚簇索引和非聚簇索引的B+树</p><br><br><h3 id="Clustered-index"><a href="#Clustered-index" class="headerlink" title="Clustered index"></a>Clustered index</h3><p>聚簇索引，数据提早物化，已经放到B+树里面中，查询数据后不需要回表</p><p>B+树的数据结点和文件页是一一关联的，每一个叶子结点的数据，和文件页里面的tuple是一一关联的</p><img src="clustered index.png" style="zoom:150%;"><br><br><h3 id="Unclustered-index"><a href="#Unclustered-index" class="headerlink" title="Unclustered index"></a>Unclustered index</h3><p>非聚簇索引，数据延迟物化，只记录行id，查询数据后需要用id进行回表</p><p>随机IO的次数可能会因为回表而变多</p><p>叶子结点的内容和数据页文件本身是不关联的</p><img src="unclustered index.png" style="zoom:150%;"><br><br><br><h1 id="Aggregations"><a href="#Aggregations" class="headerlink" title="Aggregations"></a>Aggregations</h1><p>将多个元组<strong>聚合</strong>为单个标量值</p><p>主流的方式是<strong>排序</strong>和<strong>哈希</strong></p><br><br><h2 id="Sort-aggregation"><a href="#Sort-aggregation" class="headerlink" title="Sort aggregation"></a>Sort aggregation</h2><p>将数据过滤后，对数据进行排序，然后聚合去重</p><img src="sorting aggregation.png" style="zoom: 150%;"><p>如果SQL语句不要求对原数据进行排序，那么这种方法的时间复杂度就会偏高</p><ul><li>比如说group by分组，不需要排序</li><li>比如说distinct中的重复项，也不需要排序</li></ul><br><p>因此，在上述情况下，hash aggregation是一个更好的选择：</p><ul><li>只删除重复的数据</li><li>比排序更加的高效</li></ul><br><br><h2 id="Hash-aggregation"><a href="#Hash-aggregation" class="headerlink" title="Hash aggregation"></a>Hash aggregation</h2><p>执行Hash aggregation的两个目的：</p><ul><li>DISTINCT：对原数据进行<strong>去重</strong></li><li>GROUP BY：对原数据进行<strong>聚集</strong></li></ul><img src="external hashing aggregate.png" style="zoom:150%;"><br><br><h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>利用hash函数将数据进行划分（这里假设数据量非常大，因此需要将部分数据先写入磁盘中）</p><img src="hash partition.png" style="zoom:150%;"><p>假设总共有B个buffer page，那么就将B-1个page作为分区，1个用于输入数据的缓冲区</p><p>使用哈希函数h1将元组拆分为磁盘上的分区，把所有相同hash值都位于同一分区中</p><p>最后将数据按照分区放到磁盘中（落盘的时候可以做一些优化，比如说把重复的数据给删除）</p><img src="hash_partition.png" style="zoom: 150%;"><br><br><h3 id="Rehash"><a href="#Rehash" class="headerlink" title="Rehash"></a>Rehash</h3><p>为每个分区建立内存哈希表并计算聚合</p><ul><li>为什么这里还需要rehash，因为上一个阶段的hash1可能发生哈希碰撞，因此需要rehash</li></ul><img src="hash rehash.png" style="zoom:150%;"><p>把每个分区得数据都读到内存中（假设每个分区都适合内存），再进行以此rehash，就可以把第一次发生碰撞的值给找出来</p><p>对于磁盘上的每个分区，将其读入内存并构建内存哈希表（基于第二个哈希函数h2，h2适用于将数据按照指定条件分割）</p><p>然后遍历该hash的bucket以匹配元组</p><img src="hash_rehash.png" style="zoom: 150%;"><br><br><h3 id="Hash-summarization"><a href="#Hash-summarization" class="headerlink" title="Hash summarization"></a>Hash summarization</h3><p>存在一些场景，需要对数据进行sum、max、min，或avg的运算</p><p>所以在Rehash阶段中的hash2函数（第二个hash函数），应该存入的是一个kv对</p><img src="hash summarization.png" style="zoom: 150%;"><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>对于Sort，Aggreagation，并没有说哪一种方法更好，只能说看情况选择合适的方法</p><ul><li>如果数据本身就已经排好序了，那么就用Sort进行Aggreagtions即可</li></ul><br><p>Sort排序时的一些优化思路：</p><ul><li>把多个文件页组成文件块</li><li>尽量将随机IO变为顺序IO</li><li>提前预读数据（pre read）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Course-status&quot;&gt;&lt;a href=&quot;#Course-status&quot; class=&quot;headerlink&quot; title=&quot;Course status&quot;&gt;&lt;/a&gt;Course status&lt;/h1&gt;&lt;p&gt;接下来的几节课里面，主要讲述以下内容：&lt;/p&gt;
&lt;u
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 23-Distributed OLAP Databases</title>
    <link href="https://dancsmshenry.github.io/2022/12/19/cmu-15-445-23-distributed-olap-databases/"/>
    <id>https://dancsmshenry.github.io/2022/12/19/cmu-15-445-23-distributed-olap-databases/</id>
    <published>2022-12-19T13:08:31.000Z</published>
    <updated>2024-09-17T06:10:19.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Decision-support-systems"><a href="#Decision-support-systems" class="headerlink" title="Decision support systems"></a>Decision support systems</h1><p>决策支持型数据库</p><p>分析当前的数据，以便对未来公司的发展做预计，帮助公司做商业决策</p><p>在这种AP型的数据库中，数据（表）的结构分为以下两种：<code>star schema</code>和<code>snowflake schema</code></p><br><h2 id="Star-schema"><a href="#Star-schema" class="headerlink" title="Star schema"></a>Star schema</h2><p>星型结构，一张主表被若干张维度表包围</p><p>数据的每一个维度都可以抽象出一张表，然后和主表的外键相连（不同维度之间没有关联）</p><img src="star schema.png" style="zoom:150%;"><br><p>优点：查询时更加迅速（相比Snowflake schema，因为不会造成过多表的join）</p><br><p>缺点：造成<strong>数据的冗杂</strong></p><p>可能每个同种类型的产品，都有相同的字段，如果对于每个产品都需要写入这个相同的字段，就会造成数据的冗余</p><ul><li>解决方案：用一个新的数据表记录每个类型的产品，然后用一个外键与其相连，以此减少数据的冗余</li></ul><br><p>造成<strong>数据类型不一致</strong></p><p>比如说针对产品属于哪一种类型，有些人可能会写入低端，而有些人可能会写入low，导致数据类型的不统一</p><ul><li>解决方案：和上面一样，用一个新的数据表记录，再用外键连接</li></ul><br><br><h2 id="Snowflake-schema"><a href="#Snowflake-schema" class="headerlink" title="Snowflake schema"></a>Snowflake schema</h2><p>雪花模型是在基于星型模型之上拓展来的，每一个维度可以再扩散出更多的维度，根据维度的层级拆分成颗粒度不同的多张表</p><img src="snowflake schema.png" style="zoom:150%;"><br><p>优点：减少维度表的数据量；占用更少的存储空间（不需要存储冗余的数据）</p><br><p>缺点：需要额外维护更多的维度表（导致join的查询上需要多表连接，查询效率低下）</p><br><br><br><h1 id="Execution-Models"><a href="#Execution-Models" class="headerlink" title="Execution Models"></a>Execution Models</h1><br><h2 id="Push-query-to-data"><a href="#Push-query-to-data" class="headerlink" title="Push query to data"></a>Push query to data</h2><p>将查询发送给带有数据的节点（<code>shared nothing架构</code>）</p><p>数据节点尽量在本地对数据进行一些过滤的操作，最后再将结果合并统一</p><p>数据在哪儿，就将查询发送到对应的节点上</p><br><p>比如说这里的查询，会将查询的操作传给每一个有对应数据的节点上</p><img src="push query to data.png" style="zoom:150%;"><br><br><h2 id="Pull-data-to-query"><a href="#Pull-data-to-query" class="headerlink" title="Pull data to query"></a>Pull data to query</h2><p>将数据传输到需要执行查询的节点上（<code>shared disked架构</code>）</p><p>节点需要什么数据，就拉取什么数据进行查询</p><br><p>每一个节点需要查询的范围不同，因此节点向Storage拉去的数据也都各不相同</p><img src="pull data to query_01.png" style="zoom:150%;"><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>从其他节点获取的数据和DBMS查询的中间临时结果都存储在缓冲池中</p><p>但是如果发生了崩溃，中间临时结果则会丢失</p><p>那么DBMS该如何处理这种情况呢？</p><br><br><h2 id="Query-fault-tolerance"><a href="#Query-fault-tolerance" class="headerlink" title="Query fault tolerance"></a>Query fault tolerance</h2><p>在大部分的<code>share nothing</code>架构的分布式OLAP中，都是假定执行期间事务是不会失败的</p><ul><li>因为一旦有一个节点失败了，那么整个查询都会失败，此时只需要重新查询即可</li></ul><br><p>因此，可以让DBMS在查询执行的过程中保留中间结果的快照，以便在节点崩溃的时候进行恢复</p><br><p>例如下面的查询，会将临时查询得到的数据存储在Storage中</p><img src="query fault tolerance_01.png" style="zoom:150%;"><br><p>那么即使后面该节点崩溃了，其他节点也可以去Storage上读取中间结果，而不用从头再开始查一次</p><img src="query fault tolerance_02.png" style="zoom:150%;"><br><p>一般来说用这种方式的数据库比较少</p><p>这种机制有点像Flink中的checkpoint</p><br><br><br><h1 id="Query-Planning"><a href="#Query-Planning" class="headerlink" title="Query Planning"></a>Query Planning</h1><p>在分布式OLTP的场景下，查询语句并不复杂，中间数据并不多，涉及到的数据量也不多，不需要太多的如何进行查询计划</p><p>但是在分布式OLAP的场景下，长时间海量的查询，多表查询，再加上数据的不同分布，需要考虑如何进行数据的查询</p><br><p>此前在单节点的DBMS中的一些查询优化，依然适用于分布式环境：</p><ul><li>谓词下推</li><li>数据的早物化或晚物化</li><li>join顺序的排序</li></ul><br><p>而分布式情况下，更加困难的是：</p><ul><li>数据都存放在不同的节点上</li><li>同时还要考虑网络传输的成本</li></ul><br><h2 id="Physical-operators"><a href="#Physical-operators" class="headerlink" title="Physical operators"></a>Physical operators</h2><p>将SQL的语句转化为物理查询计划，即若干个查询算子</p><p>然后将查询算子拆分为几个小节，让不同的节点去执行</p><p>是最多DBMS使用的方法</p><br><br><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p>将SQL语句，从字符串的角度切分为不同的节点</p><p>然后让不同的节点去执行（不同的节点对SQL语句进行解析和优化）</p><p>基本上没有DBMS使用这种方法</p><img src="SQL.png" style="zoom:150%;"><br><br><h2 id="Observation-1"><a href="#Observation-1" class="headerlink" title="Observation"></a>Observation</h2><p>其实，分布式的join查询效率高度依赖于数据表的分区情况</p><p>因此，分布式OLAP的查询计划，需要根据数据的不同分区，进行不同的处理</p><br><p>最简单的方法就是将整张表的数据都放到同一个节点，然后执行join操作</p><p>但，一方面这会导致分布式DBMS失去并行性</p><p>而另一方面，大量数据在网络中传输，开销巨大的同时，传输效率也会降低</p><br><br><br><h1 id="Distributed-Join-Algorithms"><a href="#Distributed-Join-Algorithms" class="headerlink" title="Distributed Join Algorithms"></a>Distributed Join Algorithms</h1><p>分布式OLAT的join算法</p><p>比如说要连接表R和表S的数据，那么DBMS需要做的</p><p>是基于当前节点已有的数据，将当前节点中可以进行join的部分进行join（而不再是像此前，将所有的数据都集中进行join）</p><br><p>当相应的数据元组到达了同一个节点上，就可以使用此前单机DBMS中的join算法了</p><br><p>下面列举两个表（表R和表S）进行join的情况：</p><p>需要执行的SQL：<code>SELECT *FROM R JOIN S ON R.id = S.id</code></p><br><br><h2 id="Scenario-01"><a href="#Scenario-01" class="headerlink" title="Scenario 01"></a>Scenario 01</h2><p>表R的数据是根据id（目标列；查询列）进行分区的，而表S的数据是每个节点都有表S中所有的数据（即每个节点都有表S的副本）</p><img src="scenario 01_01.png" style="zoom:150%;"><br><p>这种情况下的join是比较简单的，因为只需要在每个节点中</p><p>将每个节点所持有的R表的数据和S表的数据进行join，得到结果</p><p>然后再将每个节点的结果汇总在一起，便是查询的最终结果</p><img src="scenario 01_02.png" style="zoom:150%;"><br><br><h2 id="Scenario-02"><a href="#Scenario-02" class="headerlink" title="Scenario 02"></a>Scenario 02</h2><p>表R和表S的数据都是按照id（目标列；查询列）进行分区的，并且分区的数据范围都是相同的</p><img src="scenario 02_01.png" style="zoom:150%;"><br><p>只需要在每个节点上完成join的操作，最后汇总在一起就是最终结果</p><img src="scenario 02_02.png" style="zoom:150%;"><p>PS：如果每个分区的数据范围是不一致的话，对于每个节点的join</p><p>就需要强制将对应范围内的数据预先复制一份到本地，然后再进行操作</p><br><br><h2 id="Scenario-03"><a href="#Scenario-03" class="headerlink" title="Scenario 03"></a>Scenario 03</h2><p>表R的数据是按照id（目标列；查询列）进行分区的，而表S的数据则是按照Val（非查询列）进行分区的</p><img src="scenario 03_01.png" style="zoom:150%;"><br><p>此时对于每个节点的join操作，都需要从其他节点的位置，获取整个表S的副本</p><p>然后再进行操作，最后将结果汇总</p><img src="scenario 03_02.png" style="zoom:150%;"><br><br><h2 id="Scenario-04"><a href="#Scenario-04" class="headerlink" title="Scenario 04"></a>Scenario 04</h2><p>表S和表R都不按照id（目标列；查询列）进行分区</p><img src="scenario 04_01.png" style="zoom:150%;"><br><p>这种情况是最麻烦的，需要转化为Scenario 01的情况</p><p>对于每个节点，都需要先指定当前节点需要处理的数据</p><p>比如节点1需要处理id在1-100范围内的数据，节点2需要处理id在101-200范围内的数据</p><p>然后将划分好范围内的数据，迁移到指定的节点上</p><p>然后变化为Scenario 01的情况</p><img src="scenario 04_02.png" style="zoom:150%;"><br><br><h2 id="Semi-join"><a href="#Semi-join" class="headerlink" title="Semi-join"></a>Semi-join</h2><p>半连接（查询的结果只需要左表上的数据列）</p><p>很朴素的思路：检测左半边的数据是否可以和右半边的数据进行连接；如果可以，就保留左半边的数据</p><p>例子：<code>SELECT R.id FROM R JOIN S ON R.id = S.id WHERE R.id IS NOT NULL</code></p><br><p>有些DBMS是支持<code>SEMI JOIN</code>的语法的，如果不支持的话可以换为<code>EXISTS</code></p><p>上述语句可以替换为下述查询：</p><img src="semi-join_02.png" style="zoom:150%;"><br><p>针对上述这种朴素的思想，可以进一步的优化：</p><p>只传输需要查询的那一部分数据（比如这里只传输R表的id列），而不用将整个表都传输</p><img src="semi-join_03.png" style="zoom:150%;"><br><br><br><h1 id="Cloud-Systems"><a href="#Cloud-Systems" class="headerlink" title="Cloud Systems"></a>Cloud Systems</h1><p>越来越多的数据库厂商提供数据库产品服务，即<code>DBaaS</code></p><p>可以理解为，将数据库和数据库运行的具体环境（CPU、存储、硬盘等）打包</p><p>然后给用户提供使用该产品的接口（比如说可能是一个ip地址）</p><p>客户可以直接在这个ip地址上对DBMS进行操作</p><br><p>而另一方面，<code>shared-nothing</code>和<code>shared-disk</code>，这二者的界限也因为数据库的云化而变得逐渐模糊</p><p>比如说我们买一个虚拟服务器，但这个服务器上的硬盘可能也是厂商虚拟出来的（不存在CPU、内存和硬盘在同一个物理机上的情况）</p><p>而厂商的实现手段可能是<code>shared-disk</code>架构，即存算分离（虚拟出多个硬盘、CPU等资源）</p><p>使得用户好像是在使用<code>shared-nothing</code>架构一样</p><p>PS：现在很多厂商都在将原有的<code>shared-nothing</code>架构转向<code>shared-disk</code>架构</p><br><p>云厂商的数据库可以提供更加丰富的服务，比如说Amazon S3</p><p>可以在存储层对数据进行过滤，即在云的场景下，存储层可以实现更加丰富的功能</p><br><br><h2 id="Managed-DBMS"><a href="#Managed-DBMS" class="headerlink" title="Managed DBMS"></a>Managed DBMS</h2><p>DBMS的设计理念上保持不变，而是让传统的DBMS在云环境上运行</p><p>并将DBMS和其运行的云端环境打包，以此作为软件产品，对外提供服务（比如腾讯云、阿里云等）</p><p>可以理解为是将传统的DBMS是运行在云厂商的虚拟环境上</p><br><p>这种类型价格便宜，适合刚刚转向云端的厂商</p><br><br><h2 id="Cloud-Native-DBMS"><a href="#Cloud-Native-DBMS" class="headerlink" title="Cloud-Native DBMS"></a>Cloud-Native DBMS</h2><p>这种类型的DBMS从设计之初就是为了能够运行在云环境中的</p><p>首选<code>shared-disk</code>架构（主要是存算分离、方便扩容）</p><p>比如SnowFlake，Google BigQuery，Amazon Redshift，Microsoft SQL Azure</p><br><br><h2 id="Serverless-Databases"><a href="#Serverless-Databases" class="headerlink" title="Serverless Databases"></a>Serverless Databases</h2><p>在此之前，云厂商的客户都是一致使用着服务器等资源，无论此时服务器上是否有工作需要运行</p><p>而serverless DBMS，会根据服务器上的工作负载，动态的调度资源</p><br><p>无服务器，可以理解为客户使用的存储资源和计算资源都不是客户单独一人占有的</p><p>是从一个较大的存储缓冲池或是计算缓冲池中抽离出来的</p><p>当客户不再需要的时候又会归还回去</p><br><br><h2 id="Disaggregated-componsents"><a href="#Disaggregated-componsents" class="headerlink" title="Disaggregated componsents"></a>Disaggregated componsents</h2><p>可以像组装玩具一样，利用不同的插件，根据需求，满足不同数据库的需求</p><img src="disaggregated components.png" style="zoom:150%;"><br><br><h2 id="Universal-formats"><a href="#Universal-formats" class="headerlink" title="Universal formats"></a>Universal formats</h2><p>很多数据库之间的互通，一个比较难处理的事情就是数据页格式的不同</p><p>而不同系统之间，数据的传输，很多都是依赖于CSV，JSON，XML等文件格式</p><p>当然，也有一些致力于解决这些问题的开源项目</p><img src="universal formats.png" style="zoom:150%;">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Decision-support-systems&quot;&gt;&lt;a href=&quot;#Decision-support-systems&quot; class=&quot;headerlink&quot; title=&quot;Decision support systems&quot;&gt;&lt;/a&gt;Decision suppo
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 22-Distributed OLTP Databases</title>
    <link href="https://dancsmshenry.github.io/2022/12/19/cmu-15-445-22-distributed-oltp-databases/"/>
    <id>https://dancsmshenry.github.io/2022/12/19/cmu-15-445-22-distributed-oltp-databases/</id>
    <published>2022-12-19T13:08:21.000Z</published>
    <updated>2024-09-17T06:10:19.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OLTP-vs-OLAP"><a href="#OLTP-vs-OLAP" class="headerlink" title="OLTP vs OLAP"></a>OLTP vs OLAP</h1><h2 id="On-line-transaction-processing（OLTP）"><a href="#On-line-transaction-processing（OLTP）" class="headerlink" title="On-line transaction processing（OLTP）"></a>On-line transaction processing（OLTP）</h2><p>事务的流程较短、语句较少、涉及数据的读写操作（可能写数据的情况会多一些）</p><p>一般来说，每个事务对整体数据的影响都很小</p><p>存在大量重复性的小事务</p><br><br><h2 id="On-line-analytical-processing（OLAP）"><a href="#On-line-analytical-processing（OLAP）" class="headerlink" title="On-line analytical processing（OLAP）"></a>On-line analytical processing（OLAP）</h2><p>事务的流程较长、语句较多、大部分是只读操作</p><p>语句中有非常复杂的join操作</p><p>大部分用于数据分析的场景</p><br><br><br><h1 id="Decentralized-coordinator"><a href="#Decentralized-coordinator" class="headerlink" title="Decentralized coordinator"></a>Decentralized coordinator</h1><p>中心化的协调思想</p><p>应用先向主节点（primary node）发送事务开始的请求（begin request）</p><img src="decentralized coordinator_01.png" style="zoom:150%;"><br><p>然后，应用可以去各个节点对数据进行查询</p><img src="decentralized coordinator_02.png" style="zoom:150%;"><br><p>当事务结束以后，应用需要再给主节点（primary node）发送一个commit request的请求</p><p>然后主节点（primary node）需要去各个节点判断，事务是否可以在本节点上安全的提交</p><img src="decentralized coordinator_03.png" style="zoom:150%;"><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>但，这种场景下没有讨论如何确保所有的节点都能够成功的提交事务</p><p>比如说：</p><p>如果单个副节点的提交失败了，该如何处理？</p><p>节点直接的通信发生了严重的延迟，该如何处理？（rpc调用延迟过长）</p><p>不想等待所有的节点都同意再提交，该怎么处理？（可能有些节点需要很长时间才能够将事务提交）</p><br><br><br><h1 id="Important-assumption"><a href="#Important-assumption" class="headerlink" title="Important assumption"></a>Important assumption</h1><p>数据节点分布在全世界，而这里要假设每个节点的DBMS是正常工作的（是善意的），是可控的（是在可以管理的情况下的）</p><p>也就是说，数据节点不会被黑客攻击</p><br><p>因此，这里讨论的分布式数据库暂时不考虑<strong>拜占庭问题</strong></p><br><p>PS：类似区块链这种场景，可以理解为是一个分布式数据库</p><p>但是每个节点的信息是不可靠的（因为每个节点都是由不同的人或机构组成的，互相之间是不可信的）</p><p>因此在区块链的场景下，需要更加复杂的共识算法去实现共识机制，去解决拜占庭问题（比如工作量证明等）</p><br><br><br><h1 id="Atomic-commit-protocol"><a href="#Atomic-commit-protocol" class="headerlink" title="Atomic commit protocol"></a>Atomic commit protocol</h1><p>当一个多节点事务完成后，DBMS需要了解各个节点是否都是安全可提交的</p><p>因此为了实现分布式数据库中的原子提交，可以使用以下协议去实现：</p><img src="atomic commit protocol.png" style="zoom:150%;"><br><br><h2 id="Two-phase-commit"><a href="#Two-phase-commit" class="headerlink" title="Two-phase commit"></a>Two-phase commit</h2><p>2PC分为两个部分：<strong>准备阶段</strong>（prepare）和<strong>提交阶段</strong>（commit）</p><br><br><h3 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h3><p>首先接收到应用commit request的节点会变为协调者（coordinator）</p><p>而其他的节点会变为参与者（participant）</p><p>协调者首先会向参与者发送确认请求，让参与者确认本次事务的修改是否是合理正确的</p><p>如果是，就会回复ok</p><img src="2PC_01.png" style="zoom:150%;"><br><br><p>但如果不是，那么参与者（participant）就会回复abort，并进入abort阶段</p><img src="2PC_04.png" style="zoom:150%;"><br><br><h3 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h3><p>在收到参与者的回复（ok）之后，协调者就明白当前事务在其他各个节点上都是安全可提交的</p><p>接着进入commit阶段</p><p>此时协调者会再向参与者发送一个commit请求，参与者就会在本地提交当前的事务</p><p>提交成功后会回复ok</p><img src="2PC_02.png" style="zoom:150%;"><br><br><p>此时，事务提交成功，并会给应用层返回信息</p><img src="2PC_03.png" style="zoom:150%;"><br><br><h3 id="Abort"><a href="#Abort" class="headerlink" title="Abort"></a>Abort</h3><p>进入abort阶段后，协调者会发送abort请求给参与者</p><p>告知参与者事务需要取消回滚</p><p>参与者回复ok之后，协调者就会给应用层返回abort请求</p><img src="2PC_05.png" style="zoom:150%;"><br><br><h3 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations"></a>Optimizations</h3><p>2PC的两个优化方向</p><p><strong>Early prepare voting</strong></p><p>如果已知某个查询语句是事务中的最后一个语句，那么就可以将这个语句和commit request一并发送给coordinator协调者</p><p>而不是将语句和commit request分开发送</p><p>一并发送后可以提前开始投票，即提前开始prepare阶段</p><br><p><strong>Early acknowledgement after prepare</strong></p><p>在prepare阶段收到所有节点的同意的时候，就可以提前告知用户事务commit success</p><p>而不是等到commit阶段结束后再告诉用户（有点像异步IO）</p><img src="early acknowledgement.png" style="zoom:150%;"><p>但是这种方法也有缺点，比如说返回成功以后集群断电了，就可能造成数据的丢失</p><br><br><h3 id="question"><a href="#question" class="headerlink" title="question"></a>question</h3><p>如果2PC过程中，协调者发生了崩溃，那么参与者该如何处理？</p><p>答：有可能此时参与者还在执行着一部分事务，所以此时需要参与者将事务进行回滚</p><br><p>如果2PC过程中，参与者发生了崩溃，那么协调者该如何处理？（或者说发送的请求因为网络等其他原因，导致参与者没有接收到）</p><p>答：那么此时，协调者会认为该参与者是不同意该事务的发生的，默认它返回的是abort</p><br><br><h2 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h2><p>Paxos或Raft，其实本质上是一个<strong>共识机制</strong>，或者是一个<strong>一致性协议</strong></p><p>通过投票机制，取得大部分人的共识，选出一个大部分人都认可的决策</p><p>如果一个集群中大部分的参与者（都是正常可用的）都同意某个决定，那么全体成员就都需要执行这个决定</p><p>这里的大部分，一般是指一半的参与者</p><br><br><h3 id="单个事务的Paxos"><a href="#单个事务的Paxos" class="headerlink" title="单个事务的Paxos"></a>单个事务的Paxos</h3><p>在Paxos中，分为提议人（Proposer）和接收者（Acceptor）</p><p>收到应用commit request的就是提议人</p><p>首先，proposer收到应用的commit request，系统就会进入propose阶段</p><p>proposer会提出提案，即要将当前的事务提交</p><p>acceptor就会评估proposer给出的提案是否可以提交，如果能够提交，就会回复一个agree</p><img src="Paxos_01.png" style="zoom:150%;"><br><br><p>在收到acceptor的回复以后，如果有<strong>超过一半</strong>的acceptor都同意这个提案</p><p>接下来就会进入commit阶段</p><p>proposer会发指令让所有的acceptor都同意这个提案</p><p>最后，acceptor执行完之后，会再给proposer发送一个accept</p><img src="Paxos_02.png" style="zoom:150%;"><br><br><p>面对那些处于崩溃状态的节点（acceptor），proposer会持续不断地向其发送信息</p><p>直到该节点接受这条信息</p><br><br><h3 id="多个事务的Paxos"><a href="#多个事务的Paxos" class="headerlink" title="多个事务的Paxos"></a>多个事务的Paxos</h3><p>一开始进来的是事务n，此时的事务n完成了propose阶段</p><p>而此时又来了一个事务n+1，开始了它的第一阶段propose阶段</p><p>而Paxos为了要实现可串行化，因此就会要将原来的事务n给reject</p><p>所以acceptors就会给事务n的proposer一个reject</p><p>然后继续原来事务n+1的流程</p><img src="Paxos_03.png" style="zoom:150%;"><br><br><p>其实Paxos更多的是做<strong>副本分发的一致性</strong>，用于做事务的协调是很少的（基本没有）</p><br><br><h2 id="Multi-paxos"><a href="#Multi-paxos" class="headerlink" title="Multi-paxos"></a>Multi-paxos</h2><p>如果系统内部可以选举出一个单独的proposer，相比Paxos，那么就可以跳过Propose的过程</p><p>缺点：如果这个proposer挂了的话，就会导致系统的崩溃</p><br><p>因此，为了维护这个proposer，系统会周期性的维护这个proposer，即每隔一段时间就会选举出一个新的proposer</p><p>这种每隔一段时间选取出一个新的leader的机制在Raft中名为<strong>租约</strong></p><br><br><h2 id="2PC-vs-Paxos"><a href="#2PC-vs-Paxos" class="headerlink" title="2PC vs Paxos"></a>2PC vs Paxos</h2><p>在2PC，如果协调者或是接受者宕机了，整个系统都会无法运作</p><p>在Paxos，只要大多数的参与节点不会宕机（指一半），系统都是可以运作的</p><br><br><h1 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h1><h2 id="Replica-configurations"><a href="#Replica-configurations" class="headerlink" title="Replica configurations"></a>Replica configurations</h2><p>副本的架构</p><br><br><h3 id="Primary-replica"><a href="#Primary-replica" class="headerlink" title="Primary-replica"></a>Primary-replica</h3><p>主备模式</p><p>对于数据的操作，一般都需要在主节点上操作</p><p>主节点可以在没有原子提交的情况下（指可以只在主节点上操作，不需要多节点协调），通过log的方式将数据分发给备节点</p><p>对于只读操作，可以在备节点中进行</p><p>如果主节点崩溃了，那么就会在其余的备节点中选举出一个新的节点</p><p>主备模式是副本架构中运用<strong>最多</strong>的一种方式</p><br><p>主节点用于数据的读写</p><p>备节点用于做数据的备份、主节点崩溃时选取备节点当主节点、当需要查看线上数据的时候可以用备节点查看</p><p>比如说一些小公司，对于数据的分析，很多都是读取备节点上的数据</p><img src="primary-replica.png" style="zoom:150%;"><br><br><h3 id="Multi-primary"><a href="#Multi-primary" class="headerlink" title="Multi-primary"></a>Multi-primary</h3><p>多主模式</p><p>任何一个节点都是主节点，因此对于数据的操作可以在任何一个节点上执行</p><p>也正因如此，多个主节点之间需要频繁的同步数据，尤其是出现矛盾的时候，更加难以处理</p><p>因此需要原子提交协议的支持（多个主节点，2PC提交）</p><br><img src="multi-primary.png" style="zoom:150%;"><br><br><h3 id="K-safety"><a href="#K-safety" class="headerlink" title="K-safety"></a>K-safety</h3><p>需要保证线上的数据始终保持至少有k份</p><p>可以理解为这个叫作安全度，也就是说如果线上的数据数量少于这个，就不能够对外提供服务</p><p>比如说主备模式中，要始终保持线上的数据有2份</p><p>如果少于2份，就必须停止服务（这里可以理解为此时只有1份了，即主节点的数据，那么备节点就没有数据了，相当于备份失效）</p><br><br><h2 id="Propagation-scheme"><a href="#Propagation-scheme" class="headerlink" title="Propagation scheme"></a>Propagation scheme</h2><p>主节点的数据如何同步到其他节点上</p><br><h3 id="Synchronous"><a href="#Synchronous" class="headerlink" title="Synchronous"></a>Synchronous</h3><p>同步（强一致性）</p><p>当向主节点提交数据的时候，系统会强制将此时的数据同步到其他节点上（因此会造成延迟）</p><p>只有主节点和副节点都提交成功了以后，才会返回给用户（不仅仅是日志要到副节点上，而且副节点还要执行完这个日志才返回）</p><p>一般主节点使用log与副节点进行同步（比如mysql的binlog）</p><p>缺点：存在时延，需要多个节点一起同步</p><img src="synchronous.png" style="zoom:150%;"><br><br><h3 id="Asynchronous"><a href="#Asynchronous" class="headerlink" title="Asynchronous"></a>Asynchronous</h3><p>异步（最终一致性）</p><p>当主节点操作完数据以后，便立刻返回给用户，表示数据的操作成功了</p><p>将数据同步到备节点上的操作，后续再执行</p><p>缺点：如果后续数据同步的过程中，DBMS宕机了，就会造成数据的丢失</p><img src="asynchronous.png" style="zoom:150%;"><br><br><p>Mysql使用的是半同步半异步的方案：</p><p>主节点将日志传给备节点，然后当<strong>日志传输成功后</strong>，就返回给主节点，留着备节点慢慢执行</p><br><br><h2 id="Propagation-timing"><a href="#Propagation-timing" class="headerlink" title="Propagation timing"></a>Propagation timing</h2><p>数据传输的时机问题</p><h3 id="Continuous"><a href="#Continuous" class="headerlink" title="Continuous"></a>Continuous</h3><p>主节点不断地将数据传播给备节点，用户发一条SQL，主节点就发一条SQL给备节点</p><p>最后还需要将commit/abort的信息发送给备节点</p><br><p>缺点：如果发生了回滚，那么主备节点都需要一起回滚（复杂度高）</p><br><br><h3 id="On-commit"><a href="#On-commit" class="headerlink" title="On commit"></a>On commit</h3><p>平常的时候不会将操作SQL传给备节点</p><p>只有事务真正提交的时候，才会将SQL传给备节点</p><br><p>优点：回滚上不会有很大问题；不会浪费时间在发送失败事务的日志记录上</p><p>缺点：最后事务提交的时候，需要发送日志，存在时间上的开销</p><p>并且，如果事务的SQL太多的话，主节点本地就需要存储大量的日志，浪费空间</p><br><br><h2 id="Active-vs-Passive"><a href="#Active-vs-Passive" class="headerlink" title="Active vs Passive"></a>Active vs Passive</h2><h3 id="Active-active"><a href="#Active-active" class="headerlink" title="Active-active"></a>Active-active</h3><p>主备同步的时候，主节点传递的是SQL，因此SQL还需要在备节点上再执行一遍</p><p>即SQL需要在每个节点上单独执行一遍</p><p>最后，还要检查事务是否在每个副本中都得到了相同的结果</p><p>缺点：SQL会被不同的节点重复执行</p><br><br><h3 id="Active-Passive"><a href="#Active-Passive" class="headerlink" title="Active-Passive"></a>Active-Passive</h3><p>主备同步的时候，主节点先将SQL执行一遍</p><p>记录到底需要修改哪些数据，并记录成日志</p><p>然后再将日志传递给备节点</p><br><br><p>PS：此前说的数据，都是数据未分片的例子</p><p>而实际上，此前的做法也是可以用于数据分片的情况的</p><p>比如说主备模式，</p><p>节点A可以做数据1的主数据库、数据2的备数据库</p><p>节点B可以做数据2的备数据库、数据1的备数据库</p><p>那么操作数据1的时候，就得用节点A，然后同步到节点B</p><p>操作数据2的时候，就得用节点B，然后同步到节点A</p><br><br><br><h1 id="Consistency-issues（CAP）"><a href="#Consistency-issues（CAP）" class="headerlink" title="Consistency issues（CAP）"></a>Consistency issues（CAP）</h1><p><code>consistent</code>（<strong>一致性</strong>；线性一致性，最终一致性）</p><p><code>always available</code>（<strong>高可用</strong>；即使部分节点崩溃，也能对外提供服务）</p><p><code>network partition tolerant</code>（<strong>网络分区容忍</strong>；如果集群因为网络的断开，集群不会因此分裂为两个集群）</p><p><strong>三者不可能同时实现，最多同时实现其中两个</strong></p><img src="CAP.png" style="zoom:150%;"><br><p>为什么三者不能够同时实现？</p><br><p>比如说此时选择的是<strong>CP</strong>，那么在发生网络分区后</p><p>为了实现一致性和网络分区容忍性，我们就必须保证数据的读写都是在同一个数据中心上（一般名为<code>Leader</code>）</p><p>那么除去这个数据中心外的节点，就不能进行数据的读写，直到网络恢复后才能进行同步（<strong>违背了可用性</strong>）</p><br><p>或比如说此时选择的是<strong>AP</strong>，那么在发生网络分区后</p><p>为了实现一致性和可用性，就必须保证每个节点都是可以运行的（可以读写数据）</p><p>而网络的断开导致节点间无法同步数据，直到网络恢复后才能同步（<strong>违背了一致性</strong>）</p><br><p>再比如说此时选择的是<strong>CA</strong>，那么此时的方案就是每个数据节点都有单独的一份副本</p><p>数据更新的时候就需要通过网络进行同步</p><p>这可以保证一致性（都是从同一个节点读取数据）和可用性（每个节点都有数据）</p><p>但，因为数据不可以在节点间进行同步，导致系统不能够正常运行（<strong>违背了分区容错性</strong>）</p><br><br><h2 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h2><p>这里的一致性是<strong>强一致性</strong>（强调的是<strong>数据的正确性</strong>）</p><p><strong>一旦数据写入到了系统中，就能够立刻在任何一个节点上读到这个数据</strong>（强调操作的<strong>可线性化</strong>）</p><p>要么读到正确的数据，要么就返回读取错误（不存在读取错误数据的情况）</p><img src="consistency.png" style="zoom:150%;"><br><br><h2 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h2><p>高可用性（强调<strong>服务的可用性</strong>）</p><p>如果集群中的<strong>某个节点</strong>崩溃了，那么其他的应用节点依旧能够对外提供服务</p><p>DBMS一定会返回数据，但不保证数据的正确性和一致性</p><ul><li>服务不会出错</li><li>服务必定会返回数据，但不保证数据的正确性</li></ul><br><p>比如说这里的备用节点，在没崩溃之前都是访问备用节点的</p><p>备用节点崩溃后，应用可以访问主节点，使用上不受任何影响</p><img src="availability.png" style="zoom:150%;"><br><p>和网络分区容忍性相比，可用性更加侧重的是某个节点崩溃后，系统是否可以提供服务</p><p>而网络分区容忍性，更加注重的是网络崩溃后，系统是否可以正常运作</p><br><br><h2 id="Partition-tolerance"><a href="#Partition-tolerance" class="headerlink" title="Partition tolerance"></a>Partition tolerance</h2><p>网络分区容忍性（强调<strong>系统的正常运作</strong>）</p><p>如果发生了网络崩溃，节点之间不可通信（造成了网络分区）</p><p>在这种情况下，系统依然可以正常对外提供服务</p><br><p>比如以下这个例子，因为网络崩溃造成了网络分区</p><img src="partition tolerance_01.png" style="zoom:150%;"><br><p>那如果两个应用各自向主节点Primary提交修改相同数据的事务</p><p>因为都是主节点，所以修改是可以成功的，即可用性得到解决，但是一致性上却无法同步</p><img src="partition tolerance_02.png" style="zoom:150%;"><br><br><h2 id="CAP-for-OLTP-DBMS"><a href="#CAP-for-OLTP-DBMS" class="headerlink" title="CAP for OLTP DBMS"></a>CAP for OLTP DBMS</h2><p>对于传统型数据库，或者是NewSQL型数据库：</p><p>如果崩溃的节点数量达到一定的阈值，那么整个数据库就会直接下线，不对外提供服务</p><p>即<strong>牺牲可用性，以此保证一致性和分区容忍性</strong>（CP）</p><br><p>但是对于一些NoSQL型数据库来说，会在分区的集群重新连接以后</p><p>判断那些不一致的数据，选取其中一部分并保留下来</p><br><br><br><h1 id="Federated-databases"><a href="#Federated-databases" class="headerlink" title="Federated databases"></a>Federated databases</h1><p>背景：</p><p>此前都假设分布式系统中的节点运行的都是相同的DBMS</p><p>但实际中可能是多种不同的DBMS同时使用</p><p>因此需要引入联邦数据库</p><br><p>但是，将多个DBMS连接在同一个分布式架构中，是一件非常困难的事情：</p><ul><li>不同数据库的数据模型不同，同时也受查询语言的限制（SQL其实并不统一）</li><li>很难去实现查询的优化</li><li>大量的数据复制</li></ul><br><br><p>一种较为好的方案就是利用PostgreSQL（Pg可以存储不同的数据模型）</p><p>利用Pg作为中间件（服务端），连接各个不同类型的数据库</p><img src="federated database example.png" style="zoom:150%;"><br><br><p>还有一个在国内实践上比较多的办法：</p><p>因为国内很多企业用的都是MySQL</p><p>而很多数据库都可以识别MySQL的log（比如flink、spark）</p><p>那么可以让一些其他类型的数据库作为备节点</p><p>让MySQL的主节点源源不断的发送log给备节点，并在本地解析它</p><br><p>一个比较常用的场景：日常使用的是TP型数据库，而需要用AP型数据库对数据进行分析</p><p>那么就可以让AP型数据库作为备节点，让主节点的TP数据库不断的向它发送日志</p><br><p>还有一种场景：</p><p>就是需要检查某个数据是否发生了变化，那么就可以将数据同步到其他的DBMS中，实现监听</p><p>（或者使用数据库的触发器）</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>上述的很多方案都是基于数据库节点本身是友好的</p><p>而区块链数据库都假设每个节点都是恶意的、都是对抗性极大的</p><p>因此需要使用更加复杂的协议来提交事务，以此实现DBMS的正确运行</p><br><br><br><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p><a href="https://www.51cto.com/article/706373.html" target="_blank" rel="noopener">https://www.51cto.com/article/706373.html</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/528894934" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/528894934</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;OLTP-vs-OLAP&quot;&gt;&lt;a href=&quot;#OLTP-vs-OLAP&quot; class=&quot;headerlink&quot; title=&quot;OLTP vs OLAP&quot;&gt;&lt;/a&gt;OLTP vs OLAP&lt;/h1&gt;&lt;h2 id=&quot;On-line-transaction-proce
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 21-Introduction To Distributed Databases</title>
    <link href="https://dancsmshenry.github.io/2022/12/19/cmu-15-445-21-introduction-to-distributed-databases/"/>
    <id>https://dancsmshenry.github.io/2022/12/19/cmu-15-445-21-introduction-to-distributed-databases/</id>
    <published>2022-12-19T13:07:48.000Z</published>
    <updated>2024-09-17T06:10:19.581Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parallel-vs-Distributed"><a href="#Parallel-vs-Distributed" class="headerlink" title="Parallel vs Distributed"></a>Parallel vs Distributed</h1><p>并行数据库和分布式数据库的区别</p><br><h2 id="Parallel-DBMS"><a href="#Parallel-DBMS" class="headerlink" title="Parallel DBMS"></a>Parallel DBMS</h2><p>多个节点在物理上是放在一起的（比如说是放在同一个机房中）</p><p>物理节点之间是通过高速的局域网连接的</p><p>节点之间的通信消耗是很小的，可以忽略不计的（光纤连接的）</p><p>比如说Oracle数据库集群之类的并行数据库集群</p><br><br><h2 id="Distributed-DBMS"><a href="#Distributed-DBMS" class="headerlink" title="Distributed DBMS"></a>Distributed DBMS</h2><p>多个节点在物理上不是放在一起的（存在一定距离，比如说一个在亚洲，另一个在欧洲）</p><p>节点之间是通过公网连接的</p><p>节点之间的通信的消耗是不可忽略的</p><br><p>针对单节点DBMS中的一些组件，是可以复用到distributed DBMS中的</p><p>比如说SQL的优化查询，分布式事务的并发控制，以及分布式数据库的日志及恢复</p><br><br><p>因此，当说到分布式数据库的时候，要分清到底是哪一种类型的DBMS</p><br><br><br><h1 id="System-architecture"><a href="#System-architecture" class="headerlink" title="System architecture"></a>System architecture</h1><p>在分布式DBMS中，可以指定CPU可以直接访问哪些共享资源</p><p>而指定的共享资源的范围，则直接影响CPU之间的协调、以及如何在DBMS中检索数据</p><br><h2 id="Shared-memory"><a href="#Shared-memory" class="headerlink" title="Shared memory"></a>Shared memory</h2><img src="shared memory.png" style="zoom:150%;"><br><p>CPU之间的分布式，即CPU之间通过network进行通信</p><p>而各个CPU都共享同一块内存和磁盘</p><p>每一个DBMS都知道对方的存在</p><p>如果CPU需要通过网络才能够操作内存的话，那么内存的优点就没有了</p><p>分布式数据库用的少，几乎没有</p><p>主要用在服务器上，即多路服务器（比如四路服务器，总共就有四个CPU，中间通过高速总线相连）</p><p>或超级计算器，多个核通过高速网络连接</p><br><br><h2 id="Shared-disk"><a href="#Shared-disk" class="headerlink" title="Shared disk"></a>Shared disk</h2><img src="shared disk.png" style="zoom:150%;"><br><img src="shared disk_02.png" style="zoom:150%;"><p>CPU和内存打包，单体之间用网络通信</p><p>节点间共享磁盘资源</p><br><p>优点：存算分离，计算能力和存储能力解耦（计算能力差加CPU，存储能力差加磁盘），无论存储还是计算都可以单独扩容</p><p>缺点：缓存一致性（即内存的同步）</p><ul><li>A节点更新了数据，但是没有实时刷盘，只是在本地的内存更新了，而B节点此时需要访问数据，那么就出现问题了</li><li>或者说，A节点将数据更新到了磁盘上，但是其他节点的缓存并没有更新，就会造成数据的不一致</li></ul><br><p>运用的非常广泛（主要是现在的数据库都开始走向云化，存算分离有利于扩容）</p><img src="shared disk_01.png" style="zoom:150%;"><br><br><h2 id="Shared-nothing"><a href="#Shared-nothing" class="headerlink" title="Shared nothing"></a>Shared nothing</h2><img src="shared nothing.png" style="zoom:150%;"><br><img src="shared nothing_01.png" style="zoom:150%;"><p>每一个DBMS都有自己的CPU、内存、硬盘</p><p>DBMS的节点之间只通过网络进行通信</p><br><p>优点：能够获得更好的性能（因为硬盘也是在本地，所以访问性能更快）</p><p>缺点：</p><ul><li><p>数据的一致性更难处理</p></li><li><p>没有办法独立的扩容（因为数据的存储和计算都是在同一个节点上；比如说新加一个硬盘，会导致数据重新分布）</p></li></ul><br><p>也有不少的平台使用这种架构</p><img src="shared nothing_02.png" style="zoom:150%;"><br><br><br><h1 id="Design-issues"><a href="#Design-issues" class="headerlink" title="Design issues"></a>Design issues</h1><p>一些设计上的问题：</p><p>应用应该如何查找数据？（应用应该向哪一个节点请求数据）</p><p>分布式DBMS如何执行查询？（如何执行SQL）</p><ul><li>Push query to data</li><li>Pull data to query</li></ul><p>分布式DBMS如何保证数据的一致性和正确性？</p><br><br><h2 id="Homogenous-Nodes"><a href="#Homogenous-Nodes" class="headerlink" title="Homogenous Nodes"></a>Homogenous Nodes</h2><p>均匀、一致的节点</p><p>集群中的每个节点的设计、职责、任务、运行逻辑、角色都是一样的（只是负责的数据不同）</p><br><br><h2 id="Heterogenous-Nodes"><a href="#Heterogenous-Nodes" class="headerlink" title="Heterogenous Nodes"></a>Heterogenous Nodes</h2><p>每个节点的角色是不一样的</p><p>节点之间不是平等关系，允许一个节点管理多个其他节点</p><br><p>比如mongodb</p><p>当查询到Router节点的时候，Router节点会向Config Server节点获取具体数据的信息，然后再到指定的区域进行查询</p><img src="heterogenous architecture.png" style="zoom:150%;"><br><br><h2 id="Data-transparency"><a href="#Data-transparency" class="headerlink" title="Data transparency"></a>Data transparency</h2><p>数据透明，即用户是不需要了解数据具体的物理位置，或是数据是如何分区的（或是数据副本的情况）</p><p>理想情况下，用户使用分布式DBMS和单节点DBMS应该是一样的</p><br><br><br><h1 id="Partitioning-schemes"><a href="#Partitioning-schemes" class="headerlink" title="Partitioning schemes"></a>Partitioning schemes</h1><p>因为数据都是分布在不同的数据节点上的</p><p>因此DBMS需要在每个分区上执行查询操作，将结果组合在一起才是最终答案</p><br><br><h2 id="Naive-table-partitioning"><a href="#Naive-table-partitioning" class="headerlink" title="Naive table partitioning"></a>Naive table partitioning</h2><p>理想情况下，每个节点都有足够的空间来存放整张数据表</p><p>因此可以将整张数据表分配给单个节点</p><p>而比较理想的查询是，对数据的查询不跨节点，并且访问模式是统一的</p><img src="naive table partitioning.png" style="zoom:150%;"><br><p>这种方法的缺点是，如果某个表实在是太大了，可能一个节点的容量装不下</p><p>而如果某个表又太小了，单独存在一个节点中又有点浪费</p><br><br><h2 id="Horizontal-partitioning"><a href="#Horizontal-partitioning" class="headerlink" title="Horizontal partitioning"></a>Horizontal partitioning</h2><p>水平分区</p><p>将一个表的数据水平分开，分配到不同的节点上</p><p>比如说可以以某一列作为水平分区的标准（比如下图便是对某一列的值进行hash，取hash值进行分区）</p><img src="horizontal partitioning.png" style="zoom:150%;"><br><br><p>水平分区下，最友好的查询便是查询谓词中包含分区的那一列数据</p><p>垂直分区（竖着切分数据，将数据切分为两张表）的情况在分布式数据库中是用的比较少的</p><br><p>水平分区面临的问题：</p><ul><li>如果查询不是按照分区来的列进行查找的话，就会造成每个节点的数据都要遍历一遍（比如分区是按照age列分的，但是查找却是按照name进行查找的）</li><li>或者说，想要添加一个新的数据节点，扩容上复杂度会很高</li></ul><p>所以基于上述的扩容问题，提出了一致性hash算法（consistent hashing）</p><br><br><h3 id="Consistent-hashing"><a href="#Consistent-hashing" class="headerlink" title="Consistent hashing"></a>Consistent hashing</h3><p>一致性hash算法</p><p>比如说hash值在0-P1之间的数据，就会存储在P1节点，以此类推</p><img src="consistene hashing_01.png" style="zoom:150%;"><br><br><p>如果此时需要新添加一个数据节点，比如P4</p><p>那么就需要将P3中，归属于P2-P4范围的数据移动到P4中（这种扩容后的代价小于此前扩容的代价）</p><img src="consistene hashing_02.png" style="zoom:150%;"><br><br><p>同时，在这种算法下，还可以指定数据的副本数量</p><p>比如说这里执行数据的副本数量要为3，那么P1上的数据就需要复制到P6和P2上面</p><img src="consistene hashing_03.png" style="zoom: 150%;"><br><br><h2 id="Logical-partitioning"><a href="#Logical-partitioning" class="headerlink" title="Logical partitioning"></a>Logical partitioning</h2><p>逻辑分区，一般是<code>shared disk</code>架构</p><p>数据都存储在一个统一的Storage中</p><p>每个节点本身不存储数据，而是指定需要处理的数据分区</p><p>比如下图中的上面节点，处理的就是id=1和id=2的数据</p><p>下面的节点处理的就是id=3和id=4的数据</p><img src="logical partitioning.png" style="zoom:150%;"><br><br><h2 id="Physical-partitioning"><a href="#Physical-partitioning" class="headerlink" title="Physical partitioning"></a>Physical partitioning</h2><p>物理分区，一般是<code>shared nothing</code>架构</p><p>数据的存储和计算查询都是在同一个节点上</p><img src="physical partitioning.png" style="zoom:150%;"><br><br><br><h1 id="Single-node-vs-distributed"><a href="#Single-node-vs-distributed" class="headerlink" title="Single-node vs distributed"></a>Single-node vs distributed</h1><p>在单节点的情况下，数据都是在本地操作的，并发控制的处理都是在本节点上，方便处理</p><p>而分布式DBMS的情况下，事务的处理需要跨多个节点（对一个节点上的数据进行操作，别的节点是不知道的；需要非常昂贵的代价去处理）</p><p>因此，如果我们的系统需要在多节点上处理分布式事务，就需要一种多节点并发控制协议去协调</p><br><p>而在分布式的情况下，有以下两种处理的方式：集中式的和非集中式的</p><br><h2 id="Centralized-coordinator"><a href="#Centralized-coordinator" class="headerlink" title="Centralized coordinator"></a>Centralized coordinator</h2><p>用Coordinator来管理数据是否可以读取</p><p>应用的每次commit request都是向Coordinator请求，同时Coordinator上会记录数据的状态（比如读锁写锁等）</p><p>这种方案用的比较少（因为它本质上还是一个单节点的DBMS，存在性能上的缺陷）</p><img src="centralized coordinator.png" style="zoom:150%;"><br><p>后续演化为了中间件模式</p><img src="centralized coordinator_01.png" style="zoom:150%;"><br><br><h2 id="Decentralized-coordinator"><a href="#Decentralized-coordinator" class="headerlink" title="Decentralized coordinator"></a>Decentralized coordinator</h2><p>分散式的布局</p><p>应用会向分区中的其中某个节点发出请求，首先接收到该节点请求的节点会变为此次事务的<code>Master Node</code></p><img src="coordinator_01.png" style="zoom:150%;"><br><p>然后<code>Master Node</code>会给予应用反馈，应用就可以去其他节点的位置对数据进行操作</p><img src="coordinator_02.png" style="zoom:150%;"><br><p>操作完毕后就会去Master Node上进行commit</p><p>Master Node会检查事务数据是否可以提交</p><img src="decentralized coordinator.png" style="zoom:150%;"><br><br><br><h1 id="Distributed-concurrency-control"><a href="#Distributed-concurrency-control" class="headerlink" title="Distributed concurrency control"></a>Distributed concurrency control</h1><p>分布式的并发控制是需要多个事务在多个节点上同时并发</p><p>当然，单节点的并发控制也是可以移植到分布式系统中的</p><br><p>但是，这在分布式中会有以下几个挑战：</p><p>副本数据节点的同步</p><p>网络通信上的开销</p><p>节点的容错（事务执行到一半时，节点崩溃该如何处理）</p><p>时钟偏移（系统时钟在不同的节点中是不同步的）</p><br><br><h2 id="Distributed-2PL"><a href="#Distributed-2PL" class="headerlink" title="Distributed 2PL"></a>Distributed 2PL</h2><p>在分布式的情况下，因为不能够实时同步事务管理的信息（比如锁的情况），导致管理上出现问题</p><p>比如说这里的2PL，事务的锁的信息是不能够实时同步的</p><p>可能会导致各自一方都认为自己是正确的，但是最后数据汇总的时候又会出现问题</p><img src="distributed 2PL.png" style="zoom:150%;">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Parallel-vs-Distributed&quot;&gt;&lt;a href=&quot;#Parallel-vs-Distributed&quot; class=&quot;headerlink&quot; title=&quot;Parallel vs Distributed&quot;&gt;&lt;/a&gt;Parallel vs Distr
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 20-Database Recovery</title>
    <link href="https://dancsmshenry.github.io/2022/12/15/cmu-15-445-20-database-recovery/"/>
    <id>https://dancsmshenry.github.io/2022/12/15/cmu-15-445-20-database-recovery/</id>
    <published>2022-12-14T17:56:07.000Z</published>
    <updated>2024-09-17T06:10:19.576Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Crash-Recovery"><a href="#Crash-Recovery" class="headerlink" title="Crash Recovery"></a>Crash Recovery</h1><p>故障恢复算法是为了确保<strong>数据库一致性</strong>，<strong>事务的原子性</strong>和面对故障时<strong>数据的持久性</strong>的一种技术</p><br><p>故障恢复算法主要分为两部分：</p><p>第一部分：在正常的事务处理阶段添加一些操作，使得DBMS可以在故障发生时对数据进行恢复（防患于未然）</p><ul><li>通过上一章的学习，发现添加的操作主要就是WAL</li></ul><p>第二部分：在数据库故障发生时执行一些操作，以此维护数据库的原子性、一致性和持久性（利用上一个部分所添加的操作，维护DBMS的ACID特性；<strong>本章的重点</strong>）</p><br><br><br><br><h1 id="Checkpoints"><a href="#Checkpoints" class="headerlink" title="Checkpoints"></a>Checkpoints</h1><p>崩溃恢复时，可以直接从checkpoint的位置开始读取数据，而不用将所有的log都读取一遍</p><p>checkpoint会周期性执行</p><br><br><p>checkpoint会将内存中的数据（脏页）和日志全部都写入磁盘</p><p>然后，会在日志中会写入一个checkpoint的标志</p><br><br><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><img src="checkpoint_example.png" style="zoom:150%;"><br><p>checkpoint之上的日志和数据页，都已经被写入磁盘中了</p><p>checkpoint之下的日志和数据页，还在内存中</p><p>此时发生了crash，便有如下分析过程：</p><p><strong>事务T1</strong>的开始和结束都是在checkpoint之上的（表示其中的数据都写入了磁盘中），因此DBMS不需要对其进行恢复</p><p><strong>事务T2</strong>的开始是在checkpoint之前，结束是在checkpoint之后（但是T2的commit的日志已经在磁盘上了，表明该事务已经提交了），因此，T2需要进行redo操作，将checkpoint到T2 commit之间的，属于T2的操作全部重现一次，从而实现事务的原子性</p><p><strong>事务T3</strong>的开始是在checkpoint之前，但在磁盘上的log中没有发现T3 commit的日志，因此需要undo操作，将此前T3的相关操作全部都给回滚</p><br><br><br><h1 id="ARIES"><a href="#ARIES" class="headerlink" title="ARIES"></a>ARIES</h1><p>全称是<strong>Algorithms for Recovery and Isolation Exploiting Semantics</strong></p><p>从字面的意思理解就是数据库恢复原型算法</p><p>这种算法的理念各大厂商都有去实现和遵守</p><p>但是工程细节上面又会有所不同，并且不同厂商也会有所创新</p><br><br><h2 id="Main-ideas"><a href="#Main-ideas" class="headerlink" title="Main ideas"></a>Main ideas</h2><p><strong>WAL</strong>：使用的是<code>steal + no-force</code>策略，数据页可以不立刻写入磁盘，但是日志页必须立即写入磁盘</p><p><strong>Repeating History During Redo</strong>：在DBMS崩溃的时候，要使用WAL的日志对数据进行恢复</p><p><strong>Logging Changes During Undo</strong>：日志中虽然记录了一些操作，但是直到DBMS崩溃的时候该事务还没有提交，那么这些执行了一半的事务，操作过的数据都需要撤销回滚</p><img src="ARIES.png" style="zoom:150%;"><br><br><br><h1 id="Log-Sequence-Numbers"><a href="#Log-Sequence-Numbers" class="headerlink" title="Log Sequence Numbers"></a>Log Sequence Numbers</h1><p>背景：</p><p>需要给每一条日志一个单调递增的，全局的序列号</p><p>序列号的作用是表明系统当前运行的状态</p><img src="LSN_01.png" style="zoom:150%;"><br><br><h2 id="flushedLSN"><a href="#flushedLSN" class="headerlink" title="flushedLSN"></a>flushedLSN</h2><p>该LSN是存放在内存中</p><p>记录的是上一次刷到磁盘上的log的编号</p><p>换言之，现在有哪些日志是已经被写入到磁盘上了的</p><p>比如说，如果此时的LSN是100的话，就代表前100号日志都已经落到了磁盘上</p><p>而在100之后的日志就还没有写入到磁盘中，即还在内存中</p><br><br><h2 id="pageLSN"><a href="#pageLSN" class="headerlink" title="pageLSN"></a>pageLSN</h2><p>该LSN是存放在数据页上的，每一个数据页都有一个pageLSN</p><p>记录的是最近一次，修改当前数据页的日志的编号（LSN）</p><p>也可以认为是当前数据页在内存中时，最新修改该page的日志的编号</p><br><br><h2 id="recLSN"><a href="#recLSN" class="headerlink" title="recLSN"></a>recLSN</h2><p>该LSN是存放在数据页上的，每一个数据页都有一个recLSN</p><p>记录的是，当前的page在上一次写入磁盘后，第一个对该page进行修改的日志编号（LSN）</p><p>可以理解为，比当前磁盘上的page还要新的第一个版本</p><p>或者说，记录的是内存中当前page最早的修改（在此前，更早的修改都已经落盘了）</p><p>因此，关于当前在内存中的page，recLSN到pageLSN之间的日志修改，都存储在了内存中</p><p>recLSN和pageLSN在内存中，对于当前page的修改的上限和下限</p><br><br><h2 id="lastLSN"><a href="#lastLSN" class="headerlink" title="lastLSN"></a>lastLSN</h2><p>该LSN是针对单个事务的，每个事务都有一个lastLSN</p><p>记录的是，当前事务最后一条操作日志</p><br><br><h2 id="MasterRecord"><a href="#MasterRecord" class="headerlink" title="MasterRecord"></a>MasterRecord</h2><p>该MasterRecord是针对全体存储介质的，每个存储介质（例如磁盘）都有一个MasterRecord</p><p>记录的是上一次标记，带有checkpoint点的日志的LSN</p><br><br><h2 id="Writing-log-records"><a href="#Writing-log-records" class="headerlink" title="Writing log records"></a>Writing log records</h2><p>始终遵守的一个原则：当一个脏页X被刷到磁盘的时候，必须要保证pageLSN<del>X</del>小于等于flushedLSN</p><p>这就意味着，写入脏页X的前提是与脏页有关的日志及当前日志之前的所有日志都得写入磁盘中</p><br><p>所以，如果我们想要将脏页X写入到磁盘中，至少需要将脏页X的pageLSN<del>X</del>前面，已经操作过的数据写入磁盘</p><p>然后才能将脏页X写入磁盘</p><br><p>每一个log都有其对应的LSN</p><p>每当事务修改page上的数据的时候，都要更新pageLSN</p><p>每一次将内存上的日志写入到磁盘时，都需要更新flushedLSN</p><br><br><br><h1 id="Normal-commit-amp-Abort-operations"><a href="#Normal-commit-amp-Abort-operations" class="headerlink" title="Normal commit &amp; Abort operations"></a>Normal commit &amp; Abort operations</h1><h2 id="Normal-execution"><a href="#Normal-execution" class="headerlink" title="Normal execution"></a>Normal execution</h2><p>事务的组成：对数据的读写操作、事务的开始标记、事务的commit以及abort</p><p>并且，对于事务的操作简化为以下模型：</p><ul><li>所有的日志记录都保存在同一个page中</li><li>磁盘的写入都是原子操作</li><li>以SS2PL为背景，研究事务的恢复机制</li><li>steal + no-force的方式管理缓冲池</li></ul><br><br><h2 id="Transaction-commit"><a href="#Transaction-commit" class="headerlink" title="Transaction commit"></a>Transaction commit</h2><p>commit时需要执行的操作：</p><p>需要在log中添加commit的标记</p><p>要保证在commit的时候，当前事务的所有日志都要被写入到磁盘中</p><ul><li>日志的写入磁盘的过程，是顺序IO、同步IO（IO线程会卡在IO的步骤，当IO完成了以后才会返回）</li><li>一个日志的文件中，含有多条日志</li></ul><br><p>当事务真正提交的时候，会再添加一条TXN-END的日志</p><ul><li>但这一条log并不需要立刻写入磁盘中</li><li>这条日志表示当前事务，所修改的数据都已经写入到磁盘中了</li><li>这条日志对于用户来说，是无感知的，用户是不知道这条日志的</li></ul><br><p>也就是说，commit日志只代表操作的日志被写入了磁盘</p><p>而TXN-END日志才代表修改的数据被写入磁盘了</p><p>PS：当内存中的日志被flush到了磁盘中时，在内存中的日志就可以被删除了</p><img src="transaction commit.png" style="zoom:150%;"><br><br><h2 id="Transaction-abort"><a href="#Transaction-abort" class="headerlink" title="Transaction abort"></a>Transaction abort</h2><p>事务发生回滚是一种非常特殊的情况，因此ARIES算法需要进行一些额外的操作，以达到Undo的目的</p><br><p>在每一条日志的后面，加上<strong>prevLSN</strong></p><ul><li><p>记录在当前日志所在的事务中，上一个操作日志的LSN</p></li><li><p>因为LSN是所有的事务共同使用的，所以有可能当前LSN是15号，但14号LSN日志不是当前事务的日志，是其他事务的LSN</p></li><li><p>prevLSN是为了找到，在当前日志所在的事务中，前一条日志是多少号</p></li><li><p>这样在abort的时候就可以像一个链表一样将数据进行回滚</p></li><li><p>PS：事务开始的日志（即begin）的prevLSN是nil</p></li></ul><img src="transaction abort.png" style="zoom:150%;"><br><br><h2 id="Compensation-log-records"><a href="#Compensation-log-records" class="headerlink" title="Compensation log records"></a>Compensation log records</h2><p>背景：可以利用prevLSN对事务的操作进行回滚，但是仍然需<strong>要用日志记录当前的事务是如何回滚</strong>的，因此引入CLR</p><p>定义：CLR是记录事务的数据是如何被回滚的<strong>日志</strong>（如何撤销此前更新的操作）</p><p>CLR日志包含了被回滚日志操作的所有字段，同时还有undoNext指针（记录下一步要回滚的日志LSN）</p><p>CLR日志也是被写入到日志文件中，但并不会被要求强制刷盘（因为本身DBMS就在回滚，所以即使此时的日志又发生了崩溃，下次恢复的时候在回滚即可）</p><br><br><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><img src="transaction abort_example.png" style="zoom:150%;"><p>此时需要回滚T1事务，那么就要添加一条新的日志，即CLR-00x，00x表示需要撤销的操作的LSN（例子中需要回滚LSN为002的数据，因此这里是CLR-002）</p><p>这条日志的prevLSN就被设为011，因为这条撤销的日志依然属于这个事务</p><p>UndoNext就被设为001，因为此时回滚完002号日志后，就需要回滚002的上一条日志，即001</p><br><p>当回滚结束后，就需要添加TXN-END日志，表示该事务的回滚操作都结束了（此时的undoNext是nil）</p><p>PS：因此，TXN-END既可以表示事务正常运行的结束；也可以表示事务回滚过程后，事务的结束（即commit和abort）</p><img src="transaction abort_example_01.png" style="zoom:150%;"><br><br><h2 id="Abort-algorithm"><a href="#Abort-algorithm" class="headerlink" title="Abort algorithm"></a>Abort algorithm</h2><p>回滚算法的具体操作：</p><ul><li><p>首先，在日志中写下当前事务的abort log</p></li><li><p>接着，需要撤销当前事务对数据的修改</p><ul><li><p>先加上一条清理日志（<strong>CLR</strong>）</p></li><li><p>然后再恢复旧版本的数据</p></li></ul></li><li><p>最后，将事务的操作全都回滚了以后，再加上一条TXN-END的日志</p></li></ul><p>PS：清理日志（CLR）是不需要被回滚的（清理日志本身就是用来回滚其他的日志的，所以不应该被回滚）</p><br><br><br><h1 id="Fuzzy-checkpointing"><a href="#Fuzzy-checkpointing" class="headerlink" title="Fuzzy checkpointing"></a>Fuzzy checkpointing</h1><h2 id="Non-Fuzzy-Checkpoints"><a href="#Non-Fuzzy-Checkpoints" class="headerlink" title="Non-Fuzzy Checkpoints"></a>Non-Fuzzy Checkpoints</h2><p>一般的checkpoint要生成一个一致性的快照，就需要执行以下操作：</p><ul><li>任何新的事务都不可以开始</li><li>需要把正在运行的事务全部都做完</li><li>将内存上的脏页都写入磁盘</li></ul><br><p>这种方式对于正在运行的DBMS不利</p><ul><li>因为需要停下来专门处理checkpoint</li><li>并且，有些正在运行的事务可能需要非常久的时间才能做完，那么就需要非常久的等待，并且在这期间不能做其他事</li></ul><p>但是对DBMS的恢复有利</p><br><br><h2 id="Slightly-Better-Checkpoints"><a href="#Slightly-Better-Checkpoints" class="headerlink" title="Slightly Better Checkpoints"></a>Slightly Better Checkpoints</h2><p>一个很自然的想法：不一定要等待所有正在执行的事务都结束后，再进行checkpoint</p><p>换个角度说，只要给内存中活跃事务的脏页加锁，让checkpoint机制无法将这类脏页写入磁盘</p><p>那么就不用等到所有的事务都结束后，再进行checkpoint了</p><br><p>而为了实现这种效果，需要维护以下两个表：</p><p>Active transaction table（ATT，记录当前活跃事务的列表）</p><p>Dirty page table（DPT，脏页表，记录当前系统中有哪些脏页）</p><br><br><h3 id="Active-transaction-table"><a href="#Active-transaction-table" class="headerlink" title="Active transaction table"></a>Active transaction table</h3><p>活动事务表：记录的是做checkpoint时，内存中活跃的事务</p><br><p>每条事务记录的组成：</p><ul><li>txnID（事务ID）</li><li>txn status（事务的状态）<ul><li>R：running</li><li>C：committing</li><li>U：还没提交，可以理解为undo候选人，如果崩溃的时候，事务的状态依然是U，那么就要执行Undo操作了</li></ul></li><li>lastLSN（事务最近的一条操作日志）</li></ul><br><p>只有当事务结束了（写入TXN-END）的时候，才可以把事务从当前的表中移除</p><img src="active transaction table.png" style="zoom:150%;"><br><br><h3 id="Dirty-page-table"><a href="#Dirty-page-table" class="headerlink" title="Dirty page table"></a>Dirty page table</h3><p>脏页表：记录的是内存中，还没有写入磁盘的脏页</p><p>表中的每一个脏页，都会记录recLSN</p><ul><li>recLSN是指第一次使得当前page变为脏页的日志，也就是自上一次刷盘后开始的第一个日志</li></ul><br><br><h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example"></a>Example</h3><img src="slightly better checkpoints.png" style="zoom:150%;"><p>对于slightly better checkpoints来说，</p><p>会在每个checkpoint点的位置，额外的记录一下此时的ATT和DPT</p><br><br><h3 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h3><p>slightly better checkpoint的做法，其实是让正在运行的事务先暂停</p><p>并给这些事务的脏页上锁，以此保证checkpoint的时候不会把这些没完成的脏页写入磁盘</p><br><p>换言之，相比原来的checkpoint方法</p><p>slightly better checkpoint的优点是不需要等到所有的事务全部做完</p><p>允许其留下还没执行完的活跃事务及其脏页</p><br><p>但是缺点是，尽管没有清空事务，但还是暂停了事务（失去了并发性）</p><br><p>思考：之所以造成checkpoint会有性能问题，是因为我们一直要求要有一个一致性的快照</p><p>要求此时（具体的某个时间点），所有的数据页都被刷入到了磁盘中</p><p>由此引发的一个思路就是，由具体某个时间点的快照，变为某个时间段的快照，即fuzzy checkpoints</p><br><br><h2 id="Fuzzy-checkpoints"><a href="#Fuzzy-checkpoints" class="headerlink" title="Fuzzy checkpoints"></a>Fuzzy checkpoints</h2><p>主要思路：</p><p>将checkpoint的一致性快照，由时间点变为了时间段</p><p>那些还在活跃事务下的脏页，checkpoint就不需要对其进行强制刷盘</p><br><p>将checkpoint的时间点变为时间段，即分别写入checkpoint-begin、checkpoint-end两条日志</p><ul><li>checkpoint-begin表示checkpoint的开始</li><li>checkpoint-end表示checkpoint的结束，同时附上ATT和DPT这两个表</li><li>对于ATT和DPT，这两个表都表示是在checkpoint-begin之前活跃的事务，和未刷入磁盘的脏页</li><li>而checkpoint-end则表示，记录在checkpoint-begin以前提交的事务的日志及数据都已经刷盘</li><li>在checkpoint-begin之后的，checkpoint-end之前的任何事务，都不会被记录到ATT中</li></ul><br><br><br><h1 id="ARIES-Recovery-phases"><a href="#ARIES-Recovery-phases" class="headerlink" title="ARIES - Recovery phases"></a>ARIES - Recovery phases</h1><p><strong>Phase I：Analysis</strong></p><p>数据库发生崩溃后，先读入WAL文件</p><p>找到MasterRecord（即上一次checkpoint的位置，如果是fuzzy checkpoint，那就是checkpoint-begin）</p><p>并对其上下的日志进行分析</p><br><p><strong>Phase II：Redo</strong></p><p>把应该写入到磁盘中，但是还没有写入磁盘的数据，对其进行恢复</p><br><p><strong>Phase III：Undo</strong></p><p>把应该回滚，但是还没有回滚的数据进行回滚</p><img src="ARIES - Recovery phases.png" style="zoom:150%;"><br><br><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>当DBMS发生崩溃之后，首先要找到上一次checkpoint的位置，也就是<strong>MasterRecord</strong>，也是<strong>last checkpoint</strong></p><p>接着就需要去找哪些日志的操作需要redo，也就是要找DPT（脏页表）里面最小的<strong>recLSN</strong></p><ul><li>为什么要去脏页表里面找，因为此时脏页表里面的数据并没有写入到磁盘里面</li><li>no-fuzzy checkpoint之前所有的日志和数据都已经写入到磁盘中了，但是这里使用的是fuzzy checkpoint，那么就会导致有部分脏页数据是还没有写入磁盘的（为了性能，使用了fuzzy checkpoint）</li><li>因此就要找对应脏页的recLSN，然后从这一点开始做数据的Redo操作</li></ul><p>最后，就是Undo操作</p><ul><li>从DBMS崩溃时的位置往前进行分析，分析有哪些事务到最后依然是活跃的，那么这些事务的操作就需要回滚</li></ul><img src="ARIES overview.png" style="zoom:150%;"><br><br><h2 id="Analysis-phase"><a href="#Analysis-phase" class="headerlink" title="Analysis phase"></a>Analysis phase</h2><p>首先先找到上一次checkpoint的位置，然后从这个位置往前扫描（即往最新的方向扫描；如果是fuzzy checkpoint，那么就要从checkpoint-begin的位置开始扫描）</p><p>如果发现了TXN-END的日志，就表明这个事务是已经完成了的，不需要对其进行redo或是undo的操作</p><p>就可以把这个事务从ADT（活跃事务表）中移除</p><br><p>对于接下来读到的每一条日志记录：</p><ul><li>把当前记录的事务放到ADT中，并且标记为<strong>UNDO状态</strong></li><li>如果找到了读到了某个事务的commit，就把该事务在ADT中的状态改为<strong>COMMIT状态</strong></li><li>特别的，针对<strong>UPDATE</strong>的记录，就把发生了数据修改的page添加到DPT（脏页表）中，然后把该脏页的recLSN改为该日志的LSN</li></ul><br><p>上述的分析阶段其实就是不断地构建ATT和DPT的过程：</p><ul><li>ATT记录的是在系统崩溃的时候，还有哪些事务是<strong>活跃</strong>的</li><li>DPT记录的是在系统崩溃时，系统还没有写入到磁盘的<strong>脏页</strong></li></ul><br><br><h3 id="Example-3"><a href="#Example-3" class="headerlink" title="Example"></a>Example</h3><img src="analysis phase example.png" style="zoom:150%;"><p>当DBMS发生了崩溃之后，就需要找到最近的checkpoint-begin点，分析从这个点到Crash的时候，中间的日志：</p><p>020号日志：先将该日志添加到ATT和DPT中，并将该事务的状态标记为U（因为此时还没有提交）；而在DPT中，就把脏页给记录下来</p><p>030号日志：发现是checkpoint-end，那么就把此时的ATT和DPT的数据覆盖到已有的ATT和DPT上</p><p>040号日志：发现是事务T96的commit日志，于是就可以把事务T96在ATT中的状态修改为C（commit）</p><p>050号日志：发现是事务T96的TXN-END日志，就代表与这个事务有关的操作全部都完成了，被刷入盘中，那么就可以把T96事务相关的数据和页从DPT和ATT中移除</p><br><br><h2 id="Redo-phase"><a href="#Redo-phase" class="headerlink" title="Redo phase"></a>Redo phase</h2><p>Redo阶段的主要目的是重现DBMS在发生了崩溃时的状态</p><p>因此，需要Redo已经commit的事务记录，</p><p>需要Redo直到Crash时还依然没有提交的事务记录，</p><p>同时还要CLR（回滚清理日志）</p><br><p>一些优化的思路：对于那些未提交事务的操作记录，是不需要回滚（因为它们属于未提交事务）</p><p>但基本的ARIES是不这样做的，可能有些工程实践中有这些操作</p><br><p><strong>Redo</strong>的具体流程：</p><p>针对DPT中的每一个页，都找到这个页的recLSN，然后从recLSN的日志位置开始对数据进行Redo操作，恢复至Crash发生时的状态</p><p>对于其中每一条日志记录或是CLR记录，都需要进行Redo操作，<strong>除了以下两个情况</strong>（即以下两种情况不需要Redo）：</p><ul><li>DPT中没有当前页（比如说发现一个日志修改了某一页的数据，但是脏页表DPT中没有这一页，那么就不需要Redo这条日志）<ul><li>代表这个页早已经被写入到磁盘中了</li></ul></li><li>DPT有当前修改的页，但是当前日志的LSN小于这一页的recLSN<ul><li>这代表着当前日志的修改，是在recLSN之前的，那么这个修改必然是已经被写入磁盘了的</li></ul></li></ul><br><p><strong>Redo一条日志</strong>的具体流程：</p><ul><li>将数据读入内存，在内存中重新执行一遍这条语句</li><li>把当前数据页的pageLSN修改为<strong>这条日志的LSN</strong></li><li>在重新执行日志的操作中，是不需要额外写入日志的，也不强制将数据写入磁盘</li></ul><br><p>最后，将ATT中所有的状态是C的事务，添加上TXN-END的日志，并把这个事务从ATT中移除</p><br><br><h2 id="Undo-phase"><a href="#Undo-phase" class="headerlink" title="Undo phase"></a>Undo phase</h2><p>背景：一方面，Redo阶段可能会重做一些未提交事务的日志；另一方面，有些未提交事务的数据可能已经被写入磁盘中了</p><br><p>因此，需要在ADT中找到所有状态为U的事务（U代表事务未提交）</p><p>然后根据ADT中事务的lastLSN，对事务的操作一条一条的回滚（回滚过程中利用UndoNext来记录下一条需要回滚的日志）</p><br><p>PS：在Undo阶段，需要为每一个Undo操作的日志写入CLR（清理日志）</p><br><br><h2 id="Full-example"><a href="#Full-example" class="headerlink" title="Full example"></a>Full example</h2><p>举个例子，利用ARIES算法对DBMS的崩溃进行一次分析：</p><img src="full example_01.png" style="zoom:150%;"><br><p>首先是<strong>Analysis</strong>阶段，从Log中分析出此时的ATT和DPT</p><img src="full example_02.png" style="zoom:150%;"><br><p>接着是<strong>Redo</strong>阶段，针对DPT中的数据脏页，将数据进行刷盘</p><p>比如说此时脏页有P1，那么就先将脏页P1从磁盘中读取到内存中，然后从recLSN的位置，直到Crash这个区间进行分析，将数据页按照log上的操作进行修改</p><p>PS：此时的Redo操作是没有日志的</p><img src="full example_02.png" style="zoom:150%;"><br><p>最后是<strong>Undo</strong>阶段，对ATT中尚未提交的事务（状态是<strong>U</strong>的事务）操作进行回滚</p><p>事务的回滚便是利用每个事务的lastLSN，逐条逐条的往上回滚（事务的语句是利用UndoNext进行连接的）</p><p>比如这里需要回滚事务T2，那么就需要lastLSN对事务的操作进行回滚，同时UndoNext就会记录下一条需要回滚的日志操作</p><img src="full example_03.png" style="zoom:150%;"><br><p>再比如说这里回滚事务T3，而T3只有一条语句，那么这里UndoNext就为空，并且在该事务回滚完毕后（即所有的与该事务的脏页都被写入了磁盘中），会再添加一条<code>TXN-END</code>的log</p><img src="full example_04.png" style="zoom:150%;"><br><p>一个小插曲：如果在崩溃后的恢复过程中，又发生了一次崩溃，那么此时的恢复也是和之前是一样的（再次恢复的时候，重复ARIES的几个步骤即可）</p><img src="full example_05.png" style="zoom:150%;"><br><br><br><h1 id="Additional-crash-issues"><a href="#Additional-crash-issues" class="headerlink" title="Additional crash issues"></a>Additional crash issues</h1><p>问题一：如果DBMS在分析阶段又发生了崩溃，是否有问题？</p><p>答：没问题，下次恢复的时候再分析即可</p><br><p>问题二：如果DBMS在Redo阶段又发生了崩溃，是否有问题？</p><p>答：没问题，因为Redo阶段是不计入日志的，如果是在Redo的过程中崩溃了，那么此时的数据还是在内存上，并没有写入磁盘，所以没有影响；而如果说是在事务TXN-END之后发生崩溃了，也不会有问题，因为TXB-END日志写入就代表数据已经落盘了</p><br><p>问题三：在Redo阶段，有什么能够提高性能的方案？</p><p>答：在Redo的时候，同时在后台将数据异步刷盘</p><br><p>问题四：在Undo阶段，有什么能够提高性能的方案？</p><p>答：懒加载，即先不要立刻执行Undo操作；因为可能某个数据页一直都没有人访问，那么做不做Undo操作都不影响性能</p><p>所以可以选择当有新的事务要对其进行操作的时候，再对数据页进行Undo的操作（<strong>Lazily rollback</strong>）</p><p>好处就是能让DBMS快速的对外提供服务</p><p>但缺点就是会间接的影响后续事务的性能</p><br><p>另一方面，从应用的使用者的角度来说，尽量不要写太长的事务（这会导致Undo阶段非常的影响性能）</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>ARIES的几个实现细节：</p><ul><li><p>需要使用WAL，<code>steal + no-force</code>的策略</p></li><li><p>需要使用<code>fuzzy checkpoints</code></p></li><li><p>分析阶段过后，需要先进行Redo操作，再进行Undo操作</p></li><li><p>在Undo的时候需要写入CLR日志</p></li></ul><br><p>LSN（日志序列号），在整个ARIES中都非常重要的概念</p><ul><li>可以用LSN实现一个链表，利用prevLSN记录一整个日志的所有日志操作</li><li>也可以利用pageLSN，做数据页和日志记录的比较</li></ul><br><br><br><h1 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h1><p>使用WAL的主要目的应该不是为了提高性能（虽然顺序IO是快于随机IO的，但是写了日志后，还是要执行语句，还是要随机IO）</p><p>而是为了在崩溃恢复的时候，确保DBMS依旧能够保证提供ACID的特性</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Crash-Recovery&quot;&gt;&lt;a href=&quot;#Crash-Recovery&quot; class=&quot;headerlink&quot; title=&quot;Crash Recovery&quot;&gt;&lt;/a&gt;Crash Recovery&lt;/h1&gt;&lt;p&gt;故障恢复算法是为了确保&lt;strong&gt;数据库
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 19-Database Logging</title>
    <link href="https://dancsmshenry.github.io/2022/12/12/cmu-15-445-19-database-logging/"/>
    <id>https://dancsmshenry.github.io/2022/12/12/cmu-15-445-19-database-logging/</id>
    <published>2022-12-11T16:40:41.000Z</published>
    <updated>2024-09-17T06:10:19.573Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>从事务的角度来说，事务commit之后，使用者就会认为处理好的数据就被放到硬盘上了（并不管底层是如何实现的）</p><p>但实际上，出于对性能的考量（硬盘和磁盘的访问速度有明显差距）</p><p>实时修改的数据页是不会立刻写入到磁盘上的</p><p>而是优先放到内存中的（至于什么时候数据才能落盘，会根据不同的置换策略对内存上的数据进行写入）</p><img src="motivation_logging.png" style="zoom:150%;"><br><br><p>因此，如果修改好的数据只保存在了内存中，而并没有写入到磁盘上</p><p>那么当内存遭到破坏时（比如说断电、希特勒打仗等突发情况）</p><p>就会造成事务数据的丢失</p><p>因此需要DBMS的recovery机制</p><img src="motivation_logging_01.png" style="zoom:150%;"><br><br><br><h1 id="Crash-recovery"><a href="#Crash-recovery" class="headerlink" title="Crash recovery"></a>Crash recovery</h1><p>故障恢复算法是为了确保<strong>数据库一致性</strong>，<strong>事务的原子性</strong>和面对故障时<strong>数据的持久性</strong>的一种技术</p><br><p>故障恢复算法主要分为两部分：</p><p>第一部分：在正常的事务处理阶段添加一些操作，使得DBMS可以在故障发生时对数据进行恢复（防患于未然；<strong>本章的重点</strong>）</p><p>第二部分：在数据库故障发生时执行一些操作，以此维护数据库的原子性、一致性和持久性（利用上一个部分所添加的操作，维护DBMS的ACID特性）</p><br><br><p>思考：</p><p>DBMS的不同组件是依赖于在不同的存储器</p><p>比如说缓存是放到内存上的（易失性存储，但访问速度快），而数据一般是放在硬盘上的（非易失性存储，但能持久化数据）</p><p>因此，DBMS需要对不同类型的故障进行分类，从而针对不同故障给出应对处理</p><br><img src="storage types.png" style="zoom:150%;"><br><br><br><h1 id="Failure-classification"><a href="#Failure-classification" class="headerlink" title="Failure classification"></a>Failure classification</h1><br><h2 id="Transaction-failure"><a href="#Transaction-failure" class="headerlink" title="Transaction failure"></a>Transaction failure</h2><p>事务级别的故障，是正常运行的过程中不可避免的</p><p>是DBMS的开发者必须要考虑的</p><br><p><strong>逻辑错误</strong></p><ul><li><p>事务因为某些原因不能完整的执行下去</p></li><li><p>例如：用户发出rollback指令、事务执行的过程中违背了完整性约束、又或是说并发控制协议（比如OCC）发生了冲突，从而造成事务<strong>回滚</strong></p></li></ul><br><p><strong>内部状态错误</strong></p><ul><li>DBMS发现内部状态错误（比如事务间的<strong>死锁</strong>），必须终止某个活跃的事务</li></ul><br><br><h2 id="System-failure"><a href="#System-failure" class="headerlink" title="System failure"></a>System failure</h2><p>系统级别的故障，比如当数据还在内存的时候，就发生了硬件故障，导致内存中的数据消失了</p><p>也是DBMS的开发者需要考虑的</p><br><p><strong>软件故障</strong></p><ul><li>OS、DBMS本身的故障（例如：DBMS未捕获的除零异常）</li></ul><br><p><strong>硬件故障</strong></p><ul><li>存储数据库的电脑崩溃（例如：断电、CPU损坏）</li><li>硬件故障的前提是：非易失性存储（硬盘）上的数据不会因为系统崩溃而损坏</li><li>PS：硬盘故障属于Storage media failure</li></ul><br><br><h2 id="Storage-media-failure"><a href="#Storage-media-failure" class="headerlink" title="Storage media failure"></a>Storage media failure</h2><p>存储媒介的故障，比如说SSD、HHD等存储介质出现了问题</p><p>或是说磁盘的磁头崩溃，破坏了全部或部分非易失性存储</p><p>这种故障属于无法修复的硬件故障，是<strong>不可恢复</strong>的</p><br><p>但另一方面，这类故障是可以被检测出来的（例如：磁盘控制器可以使用校验和来检测故障）</p><br><p>因此这种故障在设计数据库的时候，不会考虑这类问题（当然可以在数据库运维的时候可以备份多份数据，实现容灾）</p><br><br><h2 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h2><p>DBMS的主要数据都存储在了非易失性存储器上</p><p>但是非易失性存储器（例如磁盘）的读取效率远慢于易失性存储器</p><br><p>因此，为了高效的利用易失性存储，实际的读取数据流程：</p><ul><li>首先将目标数据读取到内存中</li><li>然后在内存中对数据进行修改</li><li>最后将修改过的数据放回磁盘中</li></ul><br><p>但另一方面，DBMS还需要对使用者做出如下保证：</p><ul><li>一旦某个事务提交了，那么对这个事务的提交便已经持久化（维护<strong>持久性</strong>）</li><li>如果某个事务终止了，那么前面的部分修改是不能持久化的（维护<strong>原子性</strong>；好像这个事务没有发生一样）</li></ul><br><p>其实从上述二者的论述中，发现了设计DBMS的一个<strong>矛盾</strong>：</p><p>一方面，为了性能考虑，需要将数据先放到非易失性存储介质上，后续在写回磁盘</p><p>而另一方面，为了ACID，需要将数据实时落盘</p><br><br><h2 id="Undo-vs-Redo"><a href="#Undo-vs-Redo" class="headerlink" title="Undo vs Redo"></a>Undo vs Redo</h2><img src="undo vs redo.png" style="zoom:150%;"><br><br><h3 id="Undo"><a href="#Undo" class="headerlink" title="Undo"></a>Undo</h3><p>删除不完整的事务，或被终止的事务对数据的影响</p><p>也就是，对那些不完整的事务（或被终止的事务）中已经完成了操作的数据进行回滚</p><p>目的是为了在事务终止的时候，维护<strong>原子性</strong>（要么都执行，要么都不执行）</p><br><br><h3 id="Redo"><a href="#Redo" class="headerlink" title="Redo"></a>Redo</h3><p>恢复已commited的事务中，已经执行了的操作，以此维护事务的<strong>持久性</strong></p><p>比如操作日志已经落盘了，但是数据实际上还没有得到修改</p><p>那么就要将读取并执行日志中的相关操作</p><br><br><br><h1 id="Buffer-pool-policies"><a href="#Buffer-pool-policies" class="headerlink" title="Buffer pool policies"></a>Buffer pool policies</h1><p><strong>背景：</strong></p><p>假设有两个事务A、B，同时对同一个页中不同的数据进行操作</p><br><p>如果事务A要commit，那么此时是否要将数据页刷盘呢？</p><ul><li>如果刷盘的话，如果后续事务B又要使用该数据页，就得重新读数据了，浪费时间</li><li>但如果不刷盘的话，那该数据页就会一直放在内存中，浪费内存</li></ul><br><p>同时还会带来另一个问题：如果要将数据页刷盘，是只将事务B的数据刷盘，还是把整个数据页（包含事务A和事务B）刷盘？</p><ul><li>如果只刷事务B的数据，刷盘效率过低</li><li>如果是刷整个数据页，万一事务A发生了回滚，就有需要重新读取数据再修改</li></ul><img src="buffer pool 背景.png" style="zoom:150%;"><br><br><h2 id="Steal-policy"><a href="#Steal-policy" class="headerlink" title="Steal policy"></a>Steal policy</h2><p>DBMS是否允许未提交的事务的数据，覆盖原有的数据（即在修改数据的时候，到底应不应该覆盖原有磁盘上的数据）</p><p><code>steal</code>：允许覆盖（<strong>未提交的事务数据可以覆盖原有的数据</strong>；不管脏页的数据是否提交，全部都刷盘）</p><p><code>no steal</code>：不允许覆盖（<strong>未提交的事务数据不可以覆盖原有的数据</strong>；脏页上提交了的数据，才能刷盘）</p><br><br><h2 id="Force-policy"><a href="#Force-policy" class="headerlink" title="Force policy"></a>Force policy</h2><p>当用户发出commit的时候，是否应该立刻将数据全部都更新到磁盘上</p><p><code>force</code>：必须（提交的事务数据时，<strong>必须立刻刷盘</strong>）</p><p><code>no force</code>：非必要（提交的事务数据时，<strong>不需要立刻刷盘</strong>）</p><br><br><h2 id="No-steal-Force"><a href="#No-steal-Force" class="headerlink" title="No-steal + Force"></a>No-steal + Force</h2><img src="no-steal + force.png" style="zoom:150%;"><br><p>优点：</p><p>实现上简单方便</p><p>不需要撤销终止（回滚）事务的数据修改，因为此时对事务的修改都没有落盘（<strong>不需要undo的操作</strong>）</p><p>不需要恢复（重做）对已提交事务的数据修改，因为此时保证已提交的数据都落盘（<strong>不需要redo的操作</strong>）</p><br><br><p>缺点：</p><p>性能上不好（每个事务的提交都需要频繁的刷盘）</p><p>同时还会在内存中复制出多份快照（为了不将未提交的事务数据刷盘）</p><p>比如说要修改全表的数据，那么就需要将全表的数据都读到内存中（但显然内存大小是有限的）</p><p>因此，这种方法是不能支持写的数据量远大于内存容量的</p><br><br><br><h1 id="Shadow-paging"><a href="#Shadow-paging" class="headerlink" title="Shadow paging"></a>Shadow paging</h1><img src="shadow paging.png" style="zoom:150%;"><br><br><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>以树形结构组织数据页，其中根是单个磁盘页</p><p>分别维护两个独立的数据库副本：</p><p>master：只包含已提交的事务的数据（DB Root指向该版本的数据）</p><p>shadow：未提交事务的一个临时数据库</p><br><img src="shadow page example.png" style="zoom:150%;"><br><br><p>shadow paging的过程：</p><p>先将要操作的数据页进行拷贝，即在内存上拷贝一份新的数据</p><p>接着后续的写操作都是在这个备份上进行操作</p><p>事务commit之后将数据刷入盘中</p><p>然后调整DB root指针的指向，使其指向当前新更新的page</p><p>最后清理掉原来的page</p><br><br><h2 id="Undo-Redo"><a href="#Undo-Redo" class="headerlink" title="Undo/Redo"></a>Undo/Redo</h2><p>undo：移除shadow页</p><p>redo：不需要（因为所有数据都落盘了）</p><br><br><h2 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages"></a>Disadvantages</h2><p>相比一般的no-steal + force，shadow paging的优点是可以先将一部分数据刷到磁盘上（因为shadow paging是在磁盘上新建的页）</p><br><p><strong>数据页的复制</strong>是昂贵的</p><p>比如说我们可能只需要修改一个page中的一条数据，但却要将整个page都复制一份（复制成本高）</p><br><p><strong>复制整个页表</strong>是非常昂贵的</p><ul><li><p>可以使用B+树结构对页表进行优化</p></li><li><p>不要复制整棵树，只需要复制树中通往需要修改的叶子节点的路径</p></li></ul><br><p><strong>事务的提交开销</strong>是非常的昂贵</p><p>事务提交的时候需要做的事情有：将新数据刷盘，调整DB root中的指向，同时还要删除旧的page（垃圾回收）</p><p>数据存在碎片化</p><ul><li>一开始数据是连续存储的，但是后续不断的新生成page，接着又删除原有的page，导致数据的存储实际上并不连续，即碎片化</li></ul><p>每次只支持一个事务的写入</p><br><br><h2 id="SQLITE（PRE-2010）"><a href="#SQLITE（PRE-2010）" class="headerlink" title="SQLITE（PRE-2010）"></a>SQLITE（PRE-2010）</h2><p>Sqlite就是使用shadow paging（Sqlite主要用在一些嵌入式的设备上，或是一些安卓、苹果等系统上）</p><br><p>Sqlite的shadow paging的具体过程：</p><p>当事务开始的时候，Sqlite会将原来的数据页在本地复制一份（放到<code>Journal File</code>区域中）</p><p>然后对数据具体的修改都是在内存上进行</p><p>接着，如果事务commit的话，就会将内存中的数据刷盘到磁盘上</p><p>最后，在<code>Journal File</code>中将对应的page删除</p><br><p>如果刷盘的过程中发生了故障，那么就需要对事务进行回滚</p><p>回滚的方式，就是将Journal File中的文件读到内存中，然后再覆盖回原来的文件</p><img src="SQLITE.png" style="zoom:150%;"><br><br><h2 id="Observation-1"><a href="#Observation-1" class="headerlink" title="Observation"></a>Observation</h2><p>shadowing page依然存在大量对磁盘的随机IO（性能低下）</p><p>因此需要一种方法，能够将DBMS的随机IO修改为顺序IO，也就是WAL</p><br><br><br><h1 id="Write-ahead-log"><a href="#Write-ahead-log" class="headerlink" title="Write-ahead log"></a>Write-ahead log</h1><p>在磁盘中单独维护一个日志文件，与数据文件是分隔开的</p><ul><li><p>日志中记录的是事务对于DBMS中数据的修改操作</p></li><li><p>假定日志都存放在稳定的存储介质中</p></li><li><p>日志中有足够的信息来执行必要的redo和undo操作，以恢复数据库</p></li></ul><br><p>DBMS必须将对应的日志文件写入磁盘后，才能将对应的修改了的数据页写入磁盘中</p><br><p>策略：<strong>steal  + no force</strong></p><br><br><h2 id="WAL-protocol"><a href="#WAL-protocol" class="headerlink" title="WAL-protocol"></a>WAL-protocol</h2><p>DBMS先将事务操作的所有日志保存在内存中（一般会在内存中开辟一个空间，用于专门存储日志）</p><p>接着，将与更新页面相关的所有日志都保存到了非易失性存储（磁盘）后，才将数据页更新到磁盘上</p><ul><li>PS：这里对于数据的更新，都是先更新内存中的数据页上，后续才刷盘</li></ul><p>只有将事务对应的所有操作日志都写入了非易失性存储（磁盘）后，事务才会被认为是已提交了</p><ul><li>也就是说，当用户发送commit的时候，实际上是将日志写入到了磁盘中</li><li>而用户的数据页还在内存中</li><li>但只要用户的操作日志刷到了磁盘中，就可以保证事务是已提交了的</li></ul><br><br><p><strong>Log的过程</strong></p><p>当事务开始时，向日志中写入<code>&lt;begin&gt;</code>记录，以标记为起点</p><p>当事务结束（提交）时：</p><ul><li>在log中写入一条<code>&lt;commit&gt;</code>的记录</li><li>在写入<code>&lt;commit&gt;</code>的时候，必须要确保所有日志记录在向应用程序返回确认之前被落盘</li></ul><br><br><p><strong>Log的内容</strong></p><p>每个日志条目都包含了关于单个对象变更的信息：</p><ul><li>事务Id</li><li>对象Id（所操作的数据对象）</li><li>前值（修改之前是什么数据；UNDO，用来做undo操作）</li><li>后值（修改之后是什么数据；REDO，用来做redo操作）</li></ul><br><p>MySQL中的innodb引擎，就将日志分为的redo log和undo log两部分日志</p><br><br><h2 id="WAL-example"><a href="#WAL-example" class="headerlink" title="WAL-example"></a>WAL-example</h2><p>事务对数据的操作，首先是写入操作相关的日志，接着在将数据读入到内存中进行修改</p><img src="wal-example_01.png" style="zoom:150%;"><br><br><p>事务发出commit指令的时候，将buffer中的log写入磁盘中</p><img src="wal-example_02.png" style="zoom:150%;"><br><br><p>如果事务提交后，修改的数据页仍在内存中，但是因为断电导致内存中的数据消失了</p><p>那么，在后续重启DBMS的时候，可以重新读取log，对事务的数据进行恢复</p><img src="wal-example_03.png" style="zoom:150%;"><br><br><h2 id="WAL-implementation"><a href="#WAL-implementation" class="headerlink" title="WAL-implementation"></a>WAL-implementation</h2><p>什么时候要将log写入磁盘？</p><p>一般来说是用户发出commit指令的时候就将log写入磁盘</p><p>但是这样频繁的写入磁盘会导致DBMS的运行效率低下（可用户commit的时候是必须要将log刷盘的）</p><br><p>因此给出的一个优化方法是：<strong>组提交</strong></p><p>第一个事务commit的时候，不立刻返回，等累积了多个事务commit的时候，一并返回</p><p>借助组提交分摊写入磁盘的开销</p><br><p>有个问题：可能会出现相互等待的情况（比如此时只有T1、T2两个事务，但WAL非得等到事务足够多的时候才将日志写入磁盘）</p><ul><li>一般用定时器解决：当等待超过了一定的时间后，就直接将日志写入磁盘，不再继续等待</li></ul><br><p>另一个问题：log的page buffer满了该如何处理</p><ul><li>此时可以将一些log的page先写入到磁盘上</li></ul><img src="WAL flush time.png" style="zoom:150%;"><br><br><p>什么时候将修改好了的数据写入磁盘中？</p><p>每次事务数据发生修改的时候，或者当事务提交的时候</p><br><br><p>在运行时，no-force + steal的性能是最好的（因为steal可以将全部数据刷盘，no-force可以减少刷盘次数）</p><p>在恢复时，no-force + steal的性能是最坏的（因为是no-force，所以很多数据都没有立即刷盘，恢复时需要读取日志刷盘；而steal则可能会写入很多没有提交的数据，那么恢复的时候又要读取出来进行undo操作）</p><img src="buffer pool policy.png" style="zoom:150%;"><br><p>但，需要数据库恢复的情况占少数，因此<strong>大部分DBMS都选择no-force + steal</strong></p><br><br><br><h1 id="Logging-schemes"><a href="#Logging-schemes" class="headerlink" title="Logging schemes"></a>Logging schemes</h1><p>WAL日志的格式</p><h2 id="Physical-logging"><a href="#Physical-logging" class="headerlink" title="Physical logging"></a>Physical logging</h2><p>物理日志</p><p>记录每个数据页上，在二进制级别上的变化（例如：偏移多少个字节后，数据从什么变为了什么，即数据的变化）</p><p>比如：git diff</p><br><p>缺点：如果有个需求是让某一列的数据全部加一，那么物理日志就会变得非常的多，浪费空间（逻辑日志刚好可以解决这个问题）</p><br><br><h2 id="logical-logging"><a href="#logical-logging" class="headerlink" title="logical logging"></a>logical logging</h2><p>逻辑日志</p><p>记录每个事务执行的SQL语句</p><p>比如：update，delete和insert查询</p><br><p>优点：每次写入的日志记录的大小少于物理日志记录（比如某个SQL语句修改了大面积的数据集的时候）</p><br><p>缺点：</p><p>如果执行的SQL语句是记录当前的某个时间（now函数），但是redo的时候就会有问题（redo的时候重新执行一遍，那此时到底是记录原有的时间，还是现在的时间，无从下手）</p><br><p>再比如说，limit语句，这个语句是不指定到底要输出哪些数据的</p><p>因此在主备数据库的时候，可能主数据库有某个索引，备数据库没有这个索引</p><p>那么同样执行limit语句的时候就会导致结果不一致</p><br><p>而另一方面，如果有并发日志，很难用逻辑日志实现恢复</p><ul><li><p>难以确定数据库的哪些部分可能在崩溃前被查询修改过</p></li><li><p>redo的时候需要很长时间来恢复，因为需要执行每一个事务的SQL语句</p></li></ul><br><p>总的来说，就是逻辑日志在恢复的时候，即执行SQL语句的时候会有逻辑问题</p><br><br><h2 id="Physiological-logging"><a href="#Physiological-logging" class="headerlink" title="Physiological logging"></a>Physiological logging</h2><p>物理日志和逻辑日志的结合，记录的是数据页中，某个元组的数据前后变化</p><p>相比物理日志，Physiological记录了元组数据的具体位置，而不是偏移量</p><p>相比逻辑日志，Physiological记录了数据的前后变化，恢复上不再有逻辑问题</p><img src="logging schemes.png" style="zoom:150%;"><p>因为记录的是数据页上某个元组数据的变化，所以允许DBMS对数据页中数据的位置进行重新组织（将空间重新分配）</p><br><p>可这依然没有解决物理日志的问题（给某一列加一，日志如何记录）</p><p>而Physiological logging提供了一种mix的记录方式，即可以混合记录日志（实际使用在binlog中）</p><br><p>Physiological logging是<strong>目前最流行的日志记录方法</strong></p><p>PS：MySQL说自己是物理日志，但是实际上说的是Physiological logging日志</p><br><p>当然，Physiological的恢复成本是高于Physical的，因为它需要DBMS去找到对应位置的数据，而Physical不需要，它直接告诉了DBMS偏移量是多少</p><br><p>为什么MySQL要将redo log和undo log给分开，可以从MVCC的角度理解：</p><p>undo log既可以实现数据事务的回滚，页可以用于实现MVCC中，对数据的上一个版本的回推（查找过往数据）</p><p>MySQL的undo log和数据是放在一起的，而redo log是单独分开的</p><br><br><br><h1 id="Checkpoints"><a href="#Checkpoints" class="headerlink" title="Checkpoints"></a>Checkpoints</h1><p>背景：</p><p>1、WAL如果不做一些其他的操作，日志就会无限增长</p><p>2、日志的不断增长，会导致DBMS一旦崩溃，在恢复的时候就需要读取大量的日志，极其耗费时间</p><br><br><p>因此，DBMS会定期写下一个检查点（<strong>checkpoint</strong>）</p><p>在这个检查点之前的日志和内存中的数据页，全部都会被写入磁盘</p><p>那么当DBMS崩溃后，数据的恢复从checkpoint的位置开始恢复即可</p><br><br><h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><p>当写入检查点时，我们必须暂停所有事务以确保快照的一致性（所有的操作都会停止；而暂停会导致吞吐下降）</p><br><p>在崩溃恢复的时候，对于未提交的事务，要执行undo操作</p><p>需要扫描过往日志，可能需要花费很长的时间</p><br><p>DBMS执行检查点的频率应该控制在什么范围内？（或者说数据库多长时间存档一次）</p><ul><li>太频繁会损耗性能</li><li>太稀少又会导致恢复用的时间变长，同时日志太多也会浪费空间</li></ul><br><br><h2 id="Frequency"><a href="#Frequency" class="headerlink" title="Frequency"></a>Frequency</h2><p>检查点会太频繁会导致运行时性能下降（系统花费太多时间刷新缓冲区，给用户的体验就是非常的卡顿）</p><p>而checkpoint时间频率低也不行（会使得恢复时间变长，同时日志浪费空间）</p><br><p>发现存档并没有一个非常确定的方案，只有和具体的工程实践相结合才有最优解</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>WAL几乎是处理易失性存储丢失的最佳办法（并且WAL是连续写，性能上优于随机写）</p><p>使用带有checkpoint的增量更新（steal + no force）</p><p>在恢复时：使用undo logo对未提交事务进行回滚，使用redo log对提交事务进行恢复</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h1&gt;&lt;p&gt;从事务的角度来说，事务commit之后，使用者就会认为处理好的数据就被放到硬
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
  <entry>
    <title>CMU 15-445 18-Multi-Version Concurrency Control</title>
    <link href="https://dancsmshenry.github.io/2022/12/01/cmu-15-445-18-multi-version-concurrency-control/"/>
    <id>https://dancsmshenry.github.io/2022/12/01/cmu-15-445-18-multi-version-concurrency-control/</id>
    <published>2022-11-30T18:38:24.000Z</published>
    <updated>2024-09-17T06:10:19.567Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Multi-version-concurrency-control"><a href="#Multi-version-concurrency-control" class="headerlink" title="Multi-version concurrency control"></a>Multi-version concurrency control</h1><p>多版本并发控制协议（常常和2PL或TOO一起实现并发控制）</p><p>对于DBMS中的每一个数据，都会去记录数据的所有版本（包括历史版本和当前版本）</p><p>DBMS会维护当前所有数据对象的，所有历史版本和当前版本：</p><ul><li>当事务写入数据的时候，DBMS会创建该数据对象的一个新的版本</li><li>当事务读入数据的时候，DBMS会读取当前事务启动时，该数据存在的最新版本</li></ul><br><br><p>为什么会有MVCC的思路？</p><p>从写数据的角度考虑：</p><ul><li>在2PL中，写数据会加上写锁，这会导致其他的事务无法读取该数据</li><li>但，有可能其他的事务只是需要<strong>读取一个历史版本的数据</strong>，那么只要给该事务提供一个原数据的副本，就可以使得两个事务并发执行</li><li>从中发现，如果我们可以保留历史版本的数据，那么就可以提高并发度（因为不会阻塞读操作）</li></ul><br><p>从读数据的角度考虑：</p><ul><li>在2PL中，读取数据会上读锁，这会导致其他的事务无法写入该数据</li><li>但，其他的事务可能只是给原数据添加了一个新的版本，并没有覆盖原来的数据</li><li>这样的话，读取数据的一方，可以继续读取原有版本的数据；写入数据的一方，可以继续写入新的版本的数据</li></ul><br><br><p>总结：</p><p><strong>Writers do not block readers</strong>（留下当前数据的历史版本，从而事务的写操作就不会阻塞其他事务的读操作）</p><p><strong>Readers do not block writers</strong>（读取数据的历史版本，写入数据变成为数据添加新的版本，从而读取数据不阻塞写入数据）</p><p>Read-only txns can read a consistent <strong>snapshot</strong> without acquiring locks（只读的事务，相当于<strong>无锁</strong>的读取一个<strong>一致性</strong>的<strong>快照</strong>）</p><ul><li>可以理解为，当前事务对数据的读取，并不受数据库动态的影响</li><li>读到的都是事务开始时的那个版本</li></ul><p>使用时间戳来记录当前数据的版本号</p><p>同时方便DBMS的回滚（<code>time-travel</code>）</p><ul><li>比如说想要回滚到DBMS三分钟之前的时候的数据，直接指定版本号读取即可</li></ul><br><br><br><h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h1><p>版本链表中的begin表示该版本数据开始的时间，end表示该版本数据截止的时间（如果没有写的话，就代表是至今）</p><p>同时，全局会维护一个<code>txn table</code>，用于互相查明事务的状态</p><img src="txn status table.png" style="zoom:150%;"><br><br><h2 id="Example1"><a href="#Example1" class="headerlink" title="Example1"></a>Example1</h2><p>T1读数据会检查当前的版本，发现此时版本为T0，因此就直接读取</p><p>T2写数据，发现当前版本小于自身，因此在table中添加一条新的记录（该记录的begin为当前记录的版本号）</p><img src="mvcc-example_01.png" style="zoom:150%;"><br><br><p>此后，T1又要读数据A，就得找到当前事务对应的版本（即历史版本）读取数据</p><img src="mvcc-example_02.png" style="zoom:150%;"><br><br><h2 id="Example2"><a href="#Example2" class="headerlink" title="Example2"></a>Example2</h2><p>T1对数据A的读写、T2对数据A的写入，参考Example1（读历史版本，写入新版本）</p><br><p>T2对数据A的读取：</p><p>此时T1的数据还没有提交，T2不能读取T1还未提交的数据（避免脏读）</p><p>因此T2读取的是A0时刻的数据</p><p>PS：可以看出来单单MVCC是无法实现可串行化的（因为可串行化中，T2读取到的应该是T1时刻修改后的数据，但MVCC读到的却是更早的数据）</p><img src="mvcc-example_03.png" style="zoom:150%;"><br><p>T2对数据A的写入：</p><p>此时T2要修改数据，发现T1有一个未提交的事务数据（即发现了一个未提交的新版本），所以会wait到T1结束，才能继续修改</p><p>T1发生在T2之前，那么T2对数据写的版本必然是最终版本</p><p>如果T2不阻塞，直接写了新版本的数据</p><p>后续T1又重新写了一遍，逻辑上就会出现错误了</p><p>所以T2必须要等到T1commit，才能给数据添加上新的版本</p><br><p>T1对数据A的读取：读取当前事务中上一次添加的版本A1时的数据</p><img src="mvcc-example_04.png" style="zoom:150%;"><br><p>当T1事务commit以后，T2事务才可以继续往下写数据</p><img src="mvcc-example_05.png" style="zoom:150%;"><br><br><p><strong>Oracle的最高隔离级别快照隔离（snapshot隔离）</strong>，依靠的就是<strong>MVCC</strong></p><p>只有<code>MVCC</code>的话，是无法实现可串行化的，所以一般都是结合其他方法实现并发的，比如说TO，OCC，2PL</p><p>MVCC不仅仅是并发控制的手段，更是DBMS管理事务的手段</p><p>几乎所有的DBMS都实现了MVCC</p><img src="mvcc-example_06.png" style="zoom:150%;"><br><br><br><h1 id="Concurrenct-control-protocol"><a href="#Concurrenct-control-protocol" class="headerlink" title="Concurrenct control protocol"></a>Concurrenct control protocol</h1><p>MVCC常常和其他的并发控制协议结合在一起</p><img src="concurrency control protocol.png" style="zoom:150%;"><br><br><br><h1 id="Version-storage"><a href="#Version-storage" class="headerlink" title="Version storage"></a>Version storage</h1><p>新老版本（不同版本）的数据是如何存储的</p><p>DBMS会使用一个指针，接着建立一个链表记录每个版本的版本号</p><br><br><h2 id="Append-only-storage"><a href="#Append-only-storage" class="headerlink" title="Append only storage"></a>Append only storage</h2><p>简单追加</p><p>每次向DBMS中给数据追加新的版本，都相当于给数据表中追加了一条新的记录，通过指针将不同的版本记录链接起来，组成版本链</p><p>所有数据的所有版本，都存放在同一个表（<code>Main Table</code>）里面</p><img src="append-only storage.png" style="zoom:150%;"><br><p>追加一个新的数据记录：</p><p>首先要插入最新的数据记录</p><p>接着找到此时除去当前记录外最新的版本，将该版本的指针指向这个新的数据记录</p><br><br><p><code>Main table</code>中链表的两种实现思路</p><img src="version chain ordering.png" style="zoom:150%;"><br><p>第一种是将新的数据追加到链表后面（<code>Oldest-to-Newest</code>）</p><ul><li>生成新版本时，将老版本的指针指向新版本</li><li>所以访问最新记录时，需要遍历老记录（造成读放大）</li></ul><p>第二种是将新的数据追加到链表前面（<code>Newest-to-Oldest</code>）</p><ul><li>生成新版本时，将新版本的指针指向老版本</li><li>所以访问某个版本的记录时，需要从新记录开始遍历到指定版本</li></ul><img src="O2N and N2O.png" style="zoom:150%;"><br><br><h2 id="Time-travel-storage"><a href="#Time-travel-storage" class="headerlink" title="Time-travel storage"></a>Time-travel storage</h2><img src="time-travel storage.png" style="zoom:150%;"><p>main table存储的是当前最新的数据，time-travel table存储的是历史的数据</p><ul><li>main table中的value是最新版本的数据，pointer则指向time-travel table上的历史数据，version是版本号</li></ul><br><p>数据的写入：将老版本的数据复制到time-travel table中，将新版本数据写入main table中，同时调整指针指向（新版本的指针指向老版本）</p><p>数据的回滚：通过main table中最新版本的指针，找到对应的历史版本</p><br><p>比如说，总共有十行记录</p><p>那么main table就只有十行记录的最新版本，而time-travle table中就可能会存放很多的历史版本（这些历史版本都用链表连在一起）</p><br><p>time-travel也是append-only的存储方式，只是新老版本在不同的表空间中。这种方式有利于回收老版本记录，但同时产生了写放大</p><br><img src="time travel storage.png" style="zoom:150%;"><br><br><h2 id="Delta-storage"><a href="#Delta-storage" class="headerlink" title="Delta storage"></a>Delta storage</h2><p>如果每次只修改了一点点数据，就要把整份数据都放到time-travel table中，那么无疑是一种浪费</p><p>因此一种改进方案就是只存储增量，即存储数据的变化</p><br><p>main table存储原数据，delta storage segment存储每次修改的增量（具体修改了哪些部分）</p><img src="delta storage.png" style="zoom:150%;"><br><br><p>如果想读取历史版本，就要调用delta storage segment中的记录逐条回滚</p><p>优点：可以节约历史版本大小</p><p>缺点：查看历史版本（或回滚）复杂度高，即恢复（回滚）的时候需要逐步读delat storage segment（可以理解为用时间换取空间）</p><img src="delta storage.jpg" style="zoom:150%;"><br><p>PS：MySQL使用的就是这种方法，不过MySQL存储的是undo段</p><br><br><br><h1 id="Garbage-collection"><a href="#Garbage-collection" class="headerlink" title="Garbage collection"></a>Garbage collection</h1><p>背景：DBMS不可能无限存储历史的版本，所以要删除掉一些历史版本</p><br><p>垃圾回收的宗旨：</p><ul><li><p>如果任何活跃的事务都看不到这个版本（或是说不需要这个版本），那么这个版本就直接删掉了</p><ul><li><p>例如：有个事务的版本是1，但当前活跃事务的版本都是10以上的，那么事务1的版本就可以删除了</p></li><li><p>或者说，在快照隔离中，如果所有的事务都不需要它了，就要把它删掉</p></li></ul></li><li><p>如果一个事务发生了abort，就需要删除该版本</p></li></ul><br><p>需要考量的问题：</p><ul><li><p>如何发现这些版本</p></li><li><p>什么时候删掉历史版本</p></li></ul><br><br><h2 id="Tuple-level"><a href="#Tuple-level" class="headerlink" title="Tuple level"></a>Tuple level</h2><p>以元组（行记录）为粒度（范围），清理过期记录</p><p>遍历行记录，寻找哪些没有用的行记录</p><br><h3 id="background-vacuuming"><a href="#background-vacuuming" class="headerlink" title="background vacuuming"></a>background vacuuming</h3><p>开启一个后台线程对当前发生的事务和历史版本进行扫描对比，如果有数据的版本是小于当前所有的活跃事务的版本，就要清理掉</p><img src="tuple-level gc.png" style="zoom:150%;"><br><p>优化技巧：</p><ul><li>后台线程会对所有的数据进行扫描，浪费时间</li><li>而如果当前的数据页被更新过了就标记一下，后续就扫描那些被标记过的数据页即可，而不是全表扫描</li></ul><br><br><h3 id="cooperative-cleaning"><a href="#cooperative-cleaning" class="headerlink" title="cooperative cleaning"></a>cooperative cleaning</h3><p>合作清理</p><p>执行事务的语句在检索版本的时候</p><p>同时查看一下有哪些版本是没有用的</p><p>发现没有用的版本，就删除</p><img src="tuple-level gc(cooperative cleaning).png" style="zoom:150%;"><br><br><h2 id="Transaction-level"><a href="#Transaction-level" class="headerlink" title="Transaction-level"></a>Transaction-level</h2><p>以事务为单位进行回收，清理旧事务的数据版本</p><br><img src="transaction-level gc.png" style="zoom:150%;"><p>每次修改数据时，同时记录修改数据之前的旧版本</p><p>过一段时间后，DBMS决定多少版本号之前的事务都可以干掉了，那么就可以遍历事务，然后把数据的老版本给干掉</p><br><br><br><h1 id="Index-management"><a href="#Index-management" class="headerlink" title="Index management"></a>Index management</h1><p>研究在MVCC（多版本）下，如何对索引进行管理</p><p>主键索引指向的是版本链表的第一个，并且一般是物理地址（比如说某个数据具体在哪一个page的哪一个slot）</p><p>如果一个事务修改了主键的值，就要把数据先删除，后插入</p><br><p>比较麻烦的是辅助索引的处理，下图是辅助索引管理的两大流派：</p><img src="index management.jpg" style="zoom:150%;"><br><br><h2 id="Logical-pointers"><a href="#Logical-pointers" class="headerlink" title="Logical pointers"></a>Logical pointers</h2><p>键（<code>key</code>）存储的是被索引的那一列的数据</p><p>值（<code>value</code>）记录的是逻辑地址（比如说记录的是主键的值，或者行id的值），即逻辑索引</p><p>索引指向一个”中间指针”，即逻辑指针，这个中间指针再指向主表存储的元组的位置（某个页面的某个位置）</p><br><p>优点：</p><ul><li><p>如果数据发生了更新，那么只需要修改主键索引的地址（因为辅助索引指向的是主键索引的位置，不用批量修改辅助索引）</p></li><li><p>对于数据的写入比较友好：如果更新某条记录，则这条记录相关的所有索引都不需要更新，只需要更新”中间指针”指向新的元组的位置即可</p></li></ul><br><p>缺点：</p><ul><li>存在读放大问题，所有索引访问数据都需要先访问”中间指针”，再跳转到实际数据存储位置，即存在<strong>回表</strong>的过程</li></ul><img src="index pointers_02.png" style="zoom:150%;"><br><p>PS：MySQL InnoDB就是使用逻辑指针的方式，所有索引都指向主键，通过主键再去访问真实的数据</p><br><br><h2 id="Physical-pointers"><a href="#Physical-pointers" class="headerlink" title="Physical pointers"></a>Physical pointers</h2><p>键（<code>key</code>）存储的是被索引的那一列的数据</p><p>值（<code>value</code>）记录的是物理索引（比如说某个数据具体在哪一个page的哪一个slot）</p><br><p>优点：</p><ul><li>对于读比较友好，索引指向元组的实际位置，直接就可以访问到元组，无需通过中间指针进行跳转（不需要回表）</li></ul><br><p>缺点：</p><ul><li>如果辅助索引记录的是数据记录的物理地址，那么当有新的版本数据到来的时候，所有的辅助索引上数据记录都要修改（特别是在辅助索引数量很多的情况下，复杂度<code>upup</code>）</li><li>因此不利于写，如果更新了某条记录的位置，则相关的索引都需要更新，造成写放大</li></ul><img src="index pointers_01.png" style="zoom:150%;"><br><p>PS：PostgreSQL使用这种方式，所以更新记录时成本较高</p><br><br><br><h1 id="MVCC-index"><a href="#MVCC-index" class="headerlink" title="MVCC index"></a>MVCC index</h1><p>DBMS的索引一般是不会保存数据的版本号的</p><p>但MVCC有快照，因此索引需要保存冗余的数据（即冗余的键）</p><p>即一个键，可能会指向多个值（多个版本）</p><br><p>为什么要存储冗余的数据？</p><p>T1第一次读数据A</p><p>T2修改了数据A后又删除了数据A</p><p>T3在原来的位置插入了新的数据A</p><p>问题是：T3插入数据的时候，形成了新的版本</p><p>而因为T3认为此时没有数据，此时产生的新版本号是A1</p><p>导致版本号出现了重复的情况，那么此时T1重复读取数据的时候，就会出现问题</p><p>所以就需要存储冗余的键值，以此实现隔离级别（比如此时的数据A，需要维护T1指向的A1的版本和T3指向A1的版本）</p><img src="mvcc duplicate key problem.png" style="zoom:150%;"><br><p>因此每个索引上需要维护多个版本的数据，更需要额外的逻辑去维护唯一约束等问题</p><br><br><br><h1 id="MVCC-deletes"><a href="#MVCC-deletes" class="headerlink" title="MVCC deletes"></a>MVCC deletes</h1><p>DBMS一般不会在物理上将数据从数据库中删除</p><p>只有当该数据的所有版本在逻辑上被删除（即逻辑上该数据的所有版本都没有用的时候），才会将数据真正删除</p><p>因此，一般数据的删除都是指逻辑上的删除，而不是物理内存上的删除（需要保存历史版本，进行一些处理）</p><p>所以，需要一些方法来查看数据是否在逻辑上被删除</p><br><br><h2 id="Deleted-flag"><a href="#Deleted-flag" class="headerlink" title="Deleted flag"></a>Deleted flag</h2><p>在行记录上加上一个列，用于判断数据是否被删除</p><br><br><h2 id="Tombstone-tuple"><a href="#Tombstone-tuple" class="headerlink" title="Tombstone tuple"></a>Tombstone tuple</h2><p>给这个行记录添加一个新的版本（是没有数据的），相当于是一个墓碑</p><p>代表这个版本之前所有的版本，都是被删掉的</p><p>而在这个墓碑之后新的版本，是正常添加的</p><br><br><br><h1 id="MVCC-implementations"><a href="#MVCC-implementations" class="headerlink" title="MVCC implementations"></a>MVCC implementations</h1><img src="mvcc implementations.png" style="zoom:150%;"><p>比较core的部分：</p><p>protocol（MVCC和什么手段结合）</p><p>version storage（版本管理，版本存储的方案）</p><p>garbage collection（垃圾回收）</p><p>辅助索引（是logical还是physical的）</p><br><br><br><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>几乎所有的关系型数据库都实现了MVCC，但一般是搭配着其他的并发控制协议使用（比如2PL，OCC等）</p><p>当然，也有部分NoSQL也在使用，比如RocksDB</p><br><br><br><h1 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h1><p>关于读写冲突（写读冲突，同理）</p><ul><li>普通2PL，因为有事务A先拿了读锁，以至于另一个事务B拿不了写锁，另一个事务B必须等到事务A放锁了以后，才能继续往下走拿到写锁</li><li>而MVCC，事务A读不加锁，直接读，然后事务B写一个新的版本放入storage，接着如果事务A继续读的话，读历史版本即可</li><li>由此可见2PL和MVCC都可以解决读写冲突，但MVCC没有锁，没有阻塞，提高了效率和并发度</li></ul><br><p>而因为是用了类似TO的时间戳，MVCC也解决了写写冲突的问题</p><br><br><p>现有的2PL、严格2PL + 间隙锁就可以实现很多的隔离级别，为什么还需要MVCC？</p><ul><li>我觉得使用MVCC可以提高并发度，一定程度的不阻塞读（依靠的是历史版本数据）</li><li>2PL其实是可以实现的，但是会减损一些并发度，所以要使用MVCC（使得原本的范围变得宽松而合理一些）</li><li>从另一个角度说，MVCC需要2PL，因为单靠MVCC无法实现可串行化（参考Example2）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Multi-version-concurrency-control&quot;&gt;&lt;a href=&quot;#Multi-version-concurrency-control&quot; class=&quot;headerlink&quot; title=&quot;Multi-version concurrency 
      
    
    </summary>
    
    
      <category term="Database" scheme="https://dancsmshenry.github.io/tags/Database/"/>
    
      <category term="CMU 15-445" scheme="https://dancsmshenry.github.io/tags/CMU-15-445/"/>
    
  </entry>
  
</feed>
